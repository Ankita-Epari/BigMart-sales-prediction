{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_v9rqX0R.csv')\n",
    "test_data = pd.read_csv('test_AbJTz2l.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>20.750</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>8.300</td>\n",
       "      <td>reg</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>14.600</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>Others</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>7.315</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>1985</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility    Item_Type  \\\n",
       "0           FDW58       20.750          Low Fat         0.007565  Snack Foods   \n",
       "1           FDW14        8.300              reg         0.038428        Dairy   \n",
       "2           NCN55       14.600          Low Fat         0.099575       Others   \n",
       "3           FDQ58        7.315          Low Fat         0.015388  Snack Foods   \n",
       "4           FDY38          NaN          Regular         0.118599        Dairy   \n",
       "\n",
       "   Item_MRP Outlet_Identifier  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0  107.8622            OUT049                       1999      Medium   \n",
       "1   87.3198            OUT017                       2007         NaN   \n",
       "2  241.7538            OUT010                       1998         NaN   \n",
       "3  155.0340            OUT017                       2007         NaN   \n",
       "4  234.2300            OUT027                       1985      Medium   \n",
       "\n",
       "  Outlet_Location_Type        Outlet_Type  \n",
       "0               Tier 1  Supermarket Type1  \n",
       "1               Tier 2  Supermarket Type1  \n",
       "2               Tier 3      Grocery Store  \n",
       "3               Tier 2  Supermarket Type1  \n",
       "4               Tier 3  Supermarket Type3  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Item_Outlet_Sales'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['data'] = 'Test'\n",
    "train_data['data'] = 'Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 13)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_data,test_data],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14204, 13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               object\n",
       "Item_Weight                  float64\n",
       "Item_Fat_Content              object\n",
       "Item_Visibility              float64\n",
       "Item_Type                     object\n",
       "Item_MRP                     float64\n",
       "Outlet_Identifier             object\n",
       "Outlet_Establishment_Year      int64\n",
       "Outlet_Size                   object\n",
       "Outlet_Location_Type          object\n",
       "Outlet_Type                   object\n",
       "Item_Outlet_Sales            float64\n",
       "data                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales   data  \n",
       "0  Supermarket Type1          3735.1380  Train  \n",
       "1  Supermarket Type2           443.4228  Train  \n",
       "2  Supermarket Type1          2097.2700  Train  \n",
       "3      Grocery Store           732.3800  Train  \n",
       "4  Supermarket Type1           994.7052  Train  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  2439\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  4016\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "data                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  1463\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "data                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   976\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1606\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "data                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Medium\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outlet_Size'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Item_Weight'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Item_Weight'] = df['Item_Weight'].replace(np.nan,12.6)\n",
    "\n",
    "#df.loc[df['Item_Weight'].isnull(),'Item_Weight']= df['Item_Weight'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outlet_Size'] = df['Outlet_Size'].replace(np.nan,'Medium')\n",
    "\n",
    "#df.loc[df['Outlet_Size'].isnull(),'Outlet_Size']= 'Medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                     0\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                     0\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "data                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               object\n",
       "Item_Weight                  float64\n",
       "Item_Fat_Content              object\n",
       "Item_Visibility              float64\n",
       "Item_Type                     object\n",
       "Item_MRP                     float64\n",
       "Outlet_Identifier             object\n",
       "Outlet_Establishment_Year      int64\n",
       "Outlet_Size                   object\n",
       "Outlet_Location_Type          object\n",
       "Outlet_Type                   object\n",
       "Item_Outlet_Sales            float64\n",
       "data                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking catg columns\n",
    "cat_cols = df.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',\n",
       "       'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = cat_cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',\n",
       "       'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Identifier\n",
      "Item_Fat_Content\n",
      "Item_Type\n",
      "Outlet_Identifier\n",
      "Outlet_Size\n",
      "Outlet_Location_Type\n",
      "Outlet_Type\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    freqs = df[col].value_counts()\n",
    "    k = freqs.index[freqs>20][:-1]\n",
    "    for cat in k:\n",
    "        name = col+'_'+cat\n",
    "        df[name]=(df[col]==cat).astype(int)\n",
    "    del df[col]\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Weight                           0\n",
       "Item_Visibility                       0\n",
       "Item_MRP                              0\n",
       "Outlet_Establishment_Year             0\n",
       "Item_Outlet_Sales                  5681\n",
       "data                                  0\n",
       "Item_Fat_Content_Low Fat              0\n",
       "Item_Fat_Content_Regular              0\n",
       "Item_Fat_Content_LF                   0\n",
       "Item_Fat_Content_reg                  0\n",
       "Item_Type_Fruits and Vegetables       0\n",
       "Item_Type_Snack Foods                 0\n",
       "Item_Type_Household                   0\n",
       "Item_Type_Frozen Foods                0\n",
       "Item_Type_Dairy                       0\n",
       "Item_Type_Baking Goods                0\n",
       "Item_Type_Canned                      0\n",
       "Item_Type_Health and Hygiene          0\n",
       "Item_Type_Meat                        0\n",
       "Item_Type_Soft Drinks                 0\n",
       "Item_Type_Breads                      0\n",
       "Item_Type_Hard Drinks                 0\n",
       "Item_Type_Others                      0\n",
       "Item_Type_Starchy Foods               0\n",
       "Item_Type_Breakfast                   0\n",
       "Outlet_Identifier_OUT027              0\n",
       "Outlet_Identifier_OUT013              0\n",
       "Outlet_Identifier_OUT046              0\n",
       "Outlet_Identifier_OUT035              0\n",
       "Outlet_Identifier_OUT049              0\n",
       "Outlet_Identifier_OUT045              0\n",
       "Outlet_Identifier_OUT018              0\n",
       "Outlet_Identifier_OUT017              0\n",
       "Outlet_Identifier_OUT010              0\n",
       "Outlet_Size_Medium                    0\n",
       "Outlet_Size_Small                     0\n",
       "Outlet_Location_Type_Tier 3           0\n",
       "Outlet_Location_Type_Tier 2           0\n",
       "Outlet_Type_Supermarket Type1         0\n",
       "Outlet_Type_Grocery Store             0\n",
       "Outlet_Type_Supermarket Type3         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train = df[df['data']=='Train']\n",
    "del train['data']\n",
    "test = df[df['data']=='Test']\n",
    "test.drop(['Item_Outlet_Sales','data'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 40)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 39)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop('Item_Outlet_Sales',axis=1)\n",
    "y = train['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 39)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final features trough backward eliminations are : Index(['Item_MRP', 'Outlet_Establishment_Year', 'Outlet_Identifier_OUT027',\n",
      "       'Outlet_Identifier_OUT046', 'Outlet_Identifier_OUT035',\n",
      "       'Outlet_Identifier_OUT049', 'Outlet_Identifier_OUT045',\n",
      "       'Outlet_Identifier_OUT018', 'Outlet_Identifier_OUT010',\n",
      "       'Outlet_Size_Medium', 'Outlet_Size_Small',\n",
      "       'Outlet_Location_Type_Tier 3', 'Outlet_Location_Type_Tier 2',\n",
      "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Grocery Store',\n",
      "       'Outlet_Type_Supermarket Type3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "while(len(x.columns)>0):\n",
    "    inp_c=sm.add_constant(x)\n",
    "    ols_pf=sm.OLS(np.asarray(y),inp_c)\n",
    "    mod_pf=ols_pf.fit()\n",
    "    f=mod_pf.pvalues[1:].idxmax()\n",
    "    if mod_pf.pvalues[1:].max()>0.05:\n",
    "        x = x.drop(f,1)\n",
    "    else:\n",
    "        break\n",
    "print('The final features trough backward eliminations are :',x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, minmax_scale\n",
    "sc = StandardScaler()\n",
    "x_train_sc = sc.fit_transform(x_train)\n",
    "x_test_sc = sc.fit_transform(x_test)\n",
    "x_train_mm = minmax_scale(x_train)\n",
    "x_test_mm = minmax_scale(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5966"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5966, 16)\n",
      "(2557, 16)\n",
      "(5966,)\n",
      "(2557,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score  0.5624038094447097\n",
      "test score  0.5633483269397874\n",
      "mean squared error  1161.9668024372397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "predicted_sales_lr = lr.predict(x_test)\n",
    "print('train score ',lr.score(x_train, y_train))\n",
    "print('test score ',lr.score(x_test, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_lr)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score  0.5624038094447097\n",
      "test score  0.5628007548778904\n",
      "mean squared error  1162.6951418098336\n"
     ]
    }
   ],
   "source": [
    "# after standard scaling\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_sc,y_train)\n",
    "predicted_sales_lr = lr.predict(x_test_sc)\n",
    "print('train score ',lr.score(x_train_sc, y_train))\n",
    "print('test score ',lr.score(x_test_sc, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_lr)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score  0.5624038094447097\n",
      "test score  0.5635160194919484\n",
      "mean squared error  1161.7436590231744\n"
     ]
    }
   ],
   "source": [
    "# after minmax scaling\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_mm,y_train)\n",
    "predicted_sales_lr = lr.predict(x_test_mm)\n",
    "print('train score ',lr.score(x_train_mm, y_train))\n",
    "print('test score ',lr.score(x_test_mm, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_lr)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score  0.9176695256303632\n",
      "test score  0.4825329191527069\n",
      "mean squared error  1264.932990812642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train,y_train)\n",
    "predicted_sales_rf = rf.predict(x_test)\n",
    "print('train score ',rf.score(x_train, y_train))\n",
    "print('test score ',rf.score(x_test, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_rf)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score  0.9177659759405119\n",
      "test score  0.4832821771473944\n",
      "mean squared error  1264.0168895632905\n"
     ]
    }
   ],
   "source": [
    "# after standard scaling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train_sc,y_train)\n",
    "predicted_sales_rf = rf.predict(x_test_sc)\n",
    "print('train score ',rf.score(x_train_sc, y_train))\n",
    "print('test score ',rf.score(x_test_sc, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_rf)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-c343b1e45c1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Fit the grid search to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "    'criterion': [\"entropy\", \"gini\"],\n",
    "    'oob_score':[True,False],\n",
    "    'bootstrap':[True,False]\n",
    "}\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree =RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n",
    "                          cv = n_folds, verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 50,\n",
       " 'min_samples_split': 50,\n",
       " 'oob_score': True}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gini'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-ceea2853a356>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpredicted_sales_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train score '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1224\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    326\u001b[0m                                                          self.n_classes_)\n\u001b[0;32m    327\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                 criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n\u001b[0m\u001b[0;32m    329\u001b[0m                                                          n_samples)\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gini'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(bootstrap=True,criterion='gini',max_depth=5,min_samples_leaf=50,min_samples_split=50,oob_score=True)\n",
    "rf.fit(x_train,y_train)\n",
    "predicted_sales_rf = rf.predict(x_test)\n",
    "print('train score ',rf.score(x_train, y_train))\n",
    "print('test score ',rf.score(x_test, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_rf)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:23] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "train score  0.6154070626563433\n",
      "test score  0.6058650229527994\n",
      "mean squared error  1103.9480708306917\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgbr = XGBRegressor(n_estimators=100,max_depth=2)\n",
    "xgbr.fit(x_train,y_train)\n",
    "predicted_sales_xgbr = xgbr.predict(x_test)\n",
    "print('train score ',xgbr.score(x_train, y_train))\n",
    "print('test score ',xgbr.score(x_test, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_xgbr)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:14:27] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "train score  0.6751811227267932\n",
      "test score  0.5911314092758724\n",
      "mean squared error  1124.3927348196999\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgbr = XGBRegressor(n_estimators=100,learning_rate=0.1,max_depth=5)\n",
    "xgbr.fit(x_train_sc,y_train)\n",
    "predicted_sales_xgbr = xgbr.predict(x_test_sc)\n",
    "print('train score ',xgbr.score(x_train_sc, y_train))\n",
    "print('test score ',xgbr.score(x_test_sc, y_test))\n",
    "print('mean squared error ', mean_squared_error(y_test,predicted_sales_xgbr)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_8RXa3c6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0           FDW58            OUT049               1000\n",
       "1           FDW14            OUT017               1000\n",
       "2           NCN55            OUT010               1000\n",
       "3           FDQ58            OUT017               1000\n",
       "4           FDY38            OUT027               1000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2557, 16)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 39)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = test[x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Identifier_OUT027</th>\n",
       "      <th>Outlet_Identifier_OUT046</th>\n",
       "      <th>Outlet_Identifier_OUT035</th>\n",
       "      <th>Outlet_Identifier_OUT049</th>\n",
       "      <th>Outlet_Identifier_OUT045</th>\n",
       "      <th>Outlet_Identifier_OUT018</th>\n",
       "      <th>Outlet_Identifier_OUT010</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>1985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_MRP  Outlet_Establishment_Year  Outlet_Identifier_OUT027  \\\n",
       "0  107.8622                       1999                         0   \n",
       "1   87.3198                       2007                         0   \n",
       "2  241.7538                       1998                         0   \n",
       "3  155.0340                       2007                         0   \n",
       "4  234.2300                       1985                         1   \n",
       "\n",
       "   Outlet_Identifier_OUT046  Outlet_Identifier_OUT035  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   Outlet_Identifier_OUT049  Outlet_Identifier_OUT045  \\\n",
       "0                         1                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   Outlet_Identifier_OUT018  Outlet_Identifier_OUT010  Outlet_Size_Medium  \\\n",
       "0                         0                         0                   1   \n",
       "1                         0                         0                   1   \n",
       "2                         0                         1                   1   \n",
       "3                         0                         0                   1   \n",
       "4                         0                         0                   1   \n",
       "\n",
       "   Outlet_Size_Small  Outlet_Location_Type_Tier 3  \\\n",
       "0                  0                            0   \n",
       "1                  0                            0   \n",
       "2                  0                            1   \n",
       "3                  0                            0   \n",
       "4                  0                            1   \n",
       "\n",
       "   Outlet_Location_Type_Tier 2  Outlet_Type_Supermarket Type1  \\\n",
       "0                            0                              1   \n",
       "1                            1                              1   \n",
       "2                            0                              0   \n",
       "3                            1                              1   \n",
       "4                            0                              0   \n",
       "\n",
       "   Outlet_Type_Grocery Store  Outlet_Type_Supermarket Type3  \n",
       "0                          0                              0  \n",
       "1                          0                              0  \n",
       "2                          1                              0  \n",
       "3                          0                              0  \n",
       "4                          0                              1  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1646.343 , 1461.6285,  659.0464, ..., 1850.0334, 3547.0361,\n",
       "       1309.6566], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr.predict(to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Item_Outlet_Sales'] = np.abs(xgbr.predict(to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1646.343018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1461.628540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>659.046387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2485.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5807.171875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0           FDW58            OUT049        1646.343018\n",
       "1           FDW14            OUT017        1461.628540\n",
       "2           NCN55            OUT010         659.046387\n",
       "3           FDQ58            OUT017        2485.125000\n",
       "4           FDY38            OUT027        5807.171875"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('xgb_submission_depth2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1,train2 = train_test_split(train,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = train1.drop('Item_Outlet_Sales',axis=1)\n",
    "y_train1 = train1['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6818, 39)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4753.63914686211"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = train2.drop('Item_Outlet_Sales',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ir = lm.predict(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875.3441144326692"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(train2['Item_Outlet_Sales'],predicted_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = train2['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185.466592383839"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train2,predicted_ir)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp=data_ref.iloc[:,1:]\n",
    "#out=data_ref['Price']\n",
    "\n",
    "inp = train1.drop('Item_Outlet_Sales',axis=1)\n",
    "out = train1['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Item_Outlet_Sales</td> <th>  R-squared:         </th> <td>   0.568</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.566</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   288.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 May 2020</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:43:37</td>      <th>  Log-Likelihood:    </th> <td> -57498.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6818</td>       <th>  AIC:               </th> <td>1.151e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6786</td>       <th>  BIC:               </th> <td>1.153e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                           <td>    0.5435</td> <td>    0.462</td> <td>    1.177</td> <td> 0.239</td> <td>   -0.362</td> <td>    1.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Weight</th>                     <td>   -2.8447</td> <td>    3.215</td> <td>   -0.885</td> <td> 0.376</td> <td>   -9.147</td> <td>    3.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Visibility</th>                 <td> -257.1164</td> <td>  275.148</td> <td>   -0.934</td> <td> 0.350</td> <td> -796.492</td> <td>  282.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_MRP</th>                        <td>   15.5672</td> <td>    0.219</td> <td>   71.242</td> <td> 0.000</td> <td>   15.139</td> <td>   15.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Establishment_Year</th>       <td>   -0.0791</td> <td>    0.102</td> <td>   -0.772</td> <td> 0.440</td> <td>   -0.280</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Fat_Content_Low Fat</th>        <td>  -29.5969</td> <td>  114.819</td> <td>   -0.258</td> <td> 0.797</td> <td> -254.679</td> <td>  195.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Fat_Content_Regular</th>        <td>   -9.2942</td> <td>  116.448</td> <td>   -0.080</td> <td> 0.936</td> <td> -237.569</td> <td>  218.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Fat_Content_LF</th>             <td>  -58.3849</td> <td>  133.463</td> <td>   -0.437</td> <td> 0.662</td> <td> -320.015</td> <td>  203.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Fat_Content_reg</th>            <td> -116.4699</td> <td>  167.119</td> <td>   -0.697</td> <td> 0.486</td> <td> -444.076</td> <td>  211.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Fruits and Vegetables</th> <td> -238.4303</td> <td>  163.381</td> <td>   -1.459</td> <td> 0.145</td> <td> -558.709</td> <td>   81.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Snack Foods</th>           <td> -296.8908</td> <td>  163.349</td> <td>   -1.818</td> <td> 0.069</td> <td> -617.106</td> <td>   23.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Household</th>             <td> -313.5261</td> <td>  165.216</td> <td>   -1.898</td> <td> 0.058</td> <td> -637.400</td> <td>   10.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Frozen Foods</th>          <td> -307.3899</td> <td>  164.958</td> <td>   -1.863</td> <td> 0.062</td> <td> -630.760</td> <td>   15.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Dairy</th>                 <td> -346.7893</td> <td>  166.517</td> <td>   -2.083</td> <td> 0.037</td> <td> -673.215</td> <td>  -20.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Baking Goods</th>          <td> -300.1905</td> <td>  166.860</td> <td>   -1.799</td> <td> 0.072</td> <td> -627.289</td> <td>   26.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Canned</th>                <td> -252.1306</td> <td>  166.721</td> <td>   -1.512</td> <td> 0.131</td> <td> -578.956</td> <td>   74.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Health and Hygiene</th>    <td> -342.3675</td> <td>  168.999</td> <td>   -2.026</td> <td> 0.043</td> <td> -673.659</td> <td>  -11.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Meat</th>                  <td> -327.5764</td> <td>  170.640</td> <td>   -1.920</td> <td> 0.055</td> <td> -662.085</td> <td>    6.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Soft Drinks</th>           <td> -292.2847</td> <td>  170.220</td> <td>   -1.717</td> <td> 0.086</td> <td> -625.970</td> <td>   41.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Breads</th>                <td> -274.4234</td> <td>  177.385</td> <td>   -1.547</td> <td> 0.122</td> <td> -622.154</td> <td>   73.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Hard Drinks</th>           <td> -287.3117</td> <td>  181.810</td> <td>   -1.580</td> <td> 0.114</td> <td> -643.716</td> <td>   69.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Others</th>                <td> -249.6945</td> <td>  185.837</td> <td>   -1.344</td> <td> 0.179</td> <td> -613.993</td> <td>  114.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Starchy Foods</th>         <td> -305.7127</td> <td>  191.456</td> <td>   -1.597</td> <td> 0.110</td> <td> -681.026</td> <td>   69.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_Type_Breakfast</th>             <td> -239.0798</td> <td>  196.358</td> <td>   -1.218</td> <td> 0.223</td> <td> -624.004</td> <td>  145.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT027</th>        <td>  815.9837</td> <td>   19.354</td> <td>   42.161</td> <td> 0.000</td> <td>  778.043</td> <td>  853.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT013</th>        <td>  -43.1670</td> <td>   22.114</td> <td>   -1.952</td> <td> 0.051</td> <td>  -86.517</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT046</th>        <td>  261.0956</td> <td>   35.900</td> <td>    7.273</td> <td> 0.000</td> <td>  190.720</td> <td>  331.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT049</th>        <td>   84.6188</td> <td>   27.670</td> <td>    3.058</td> <td> 0.002</td> <td>   30.378</td> <td>  138.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT035</th>        <td>  300.2762</td> <td>   31.529</td> <td>    9.524</td> <td> 0.000</td> <td>  238.469</td> <td>  362.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT045</th>        <td> -180.8449</td> <td>   32.634</td> <td>   -5.542</td> <td> 0.000</td> <td> -244.818</td> <td> -116.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT018</th>        <td>  -61.8534</td> <td>   28.772</td> <td>   -2.150</td> <td> 0.032</td> <td> -118.255</td> <td>   -5.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT017</th>        <td>    1.8260</td> <td>   32.339</td> <td>    0.056</td> <td> 0.955</td> <td>  -61.569</td> <td>   65.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT010</th>        <td> -499.7679</td> <td>   39.383</td> <td>  -12.690</td> <td> 0.000</td> <td> -576.971</td> <td> -422.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Size_Medium</th>              <td>  159.9622</td> <td>   20.136</td> <td>    7.944</td> <td> 0.000</td> <td>  120.490</td> <td>  199.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Size_Small</th>               <td> -116.2517</td> <td>   15.321</td> <td>   -7.588</td> <td> 0.000</td> <td> -146.286</td> <td>  -86.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Location_Type_Tier 3</th>     <td>  211.1954</td> <td>   24.420</td> <td>    8.649</td> <td> 0.000</td> <td>  163.325</td> <td>  259.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Location_Type_Tier 2</th>     <td>  121.2573</td> <td>   19.368</td> <td>    6.261</td> <td> 0.000</td> <td>   83.290</td> <td>  159.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Type_Supermarket Type1</th>   <td>  423.8047</td> <td>   23.127</td> <td>   18.325</td> <td> 0.000</td> <td>  378.468</td> <td>  469.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Type_Grocery Store</th>       <td>-1177.3914</td> <td>   26.546</td> <td>  -44.352</td> <td> 0.000</td> <td>-1229.431</td> <td>-1125.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Type_Supermarket Type3</th>   <td>  815.9837</td> <td>   19.354</td> <td>   42.161</td> <td> 0.000</td> <td>  778.043</td> <td>  853.924</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>798.472</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2003.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.674</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.288</td>  <th>  Cond. No.          </th> <td>1.66e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.9e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      Item_Outlet_Sales   R-squared:                       0.568\n",
       "Model:                            OLS   Adj. R-squared:                  0.566\n",
       "Method:                 Least Squares   F-statistic:                     288.2\n",
       "Date:                Fri, 29 May 2020   Prob (F-statistic):               0.00\n",
       "Time:                        12:43:37   Log-Likelihood:                -57498.\n",
       "No. Observations:                6818   AIC:                         1.151e+05\n",
       "Df Residuals:                    6786   BIC:                         1.153e+05\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "const                               0.5435      0.462      1.177      0.239      -0.362       1.449\n",
       "Item_Weight                        -2.8447      3.215     -0.885      0.376      -9.147       3.458\n",
       "Item_Visibility                  -257.1164    275.148     -0.934      0.350    -796.492     282.259\n",
       "Item_MRP                           15.5672      0.219     71.242      0.000      15.139      15.996\n",
       "Outlet_Establishment_Year          -0.0791      0.102     -0.772      0.440      -0.280       0.122\n",
       "Item_Fat_Content_Low Fat          -29.5969    114.819     -0.258      0.797    -254.679     195.485\n",
       "Item_Fat_Content_Regular           -9.2942    116.448     -0.080      0.936    -237.569     218.981\n",
       "Item_Fat_Content_LF               -58.3849    133.463     -0.437      0.662    -320.015     203.245\n",
       "Item_Fat_Content_reg             -116.4699    167.119     -0.697      0.486    -444.076     211.136\n",
       "Item_Type_Fruits and Vegetables  -238.4303    163.381     -1.459      0.145    -558.709      81.848\n",
       "Item_Type_Snack Foods            -296.8908    163.349     -1.818      0.069    -617.106      23.325\n",
       "Item_Type_Household              -313.5261    165.216     -1.898      0.058    -637.400      10.348\n",
       "Item_Type_Frozen Foods           -307.3899    164.958     -1.863      0.062    -630.760      15.980\n",
       "Item_Type_Dairy                  -346.7893    166.517     -2.083      0.037    -673.215     -20.364\n",
       "Item_Type_Baking Goods           -300.1905    166.860     -1.799      0.072    -627.289      26.908\n",
       "Item_Type_Canned                 -252.1306    166.721     -1.512      0.131    -578.956      74.695\n",
       "Item_Type_Health and Hygiene     -342.3675    168.999     -2.026      0.043    -673.659     -11.076\n",
       "Item_Type_Meat                   -327.5764    170.640     -1.920      0.055    -662.085       6.932\n",
       "Item_Type_Soft Drinks            -292.2847    170.220     -1.717      0.086    -625.970      41.401\n",
       "Item_Type_Breads                 -274.4234    177.385     -1.547      0.122    -622.154      73.307\n",
       "Item_Type_Hard Drinks            -287.3117    181.810     -1.580      0.114    -643.716      69.092\n",
       "Item_Type_Others                 -249.6945    185.837     -1.344      0.179    -613.993     114.604\n",
       "Item_Type_Starchy Foods          -305.7127    191.456     -1.597      0.110    -681.026      69.601\n",
       "Item_Type_Breakfast              -239.0798    196.358     -1.218      0.223    -624.004     145.844\n",
       "Outlet_Identifier_OUT027          815.9837     19.354     42.161      0.000     778.043     853.924\n",
       "Outlet_Identifier_OUT013          -43.1670     22.114     -1.952      0.051     -86.517       0.183\n",
       "Outlet_Identifier_OUT046          261.0956     35.900      7.273      0.000     190.720     331.471\n",
       "Outlet_Identifier_OUT049           84.6188     27.670      3.058      0.002      30.378     138.860\n",
       "Outlet_Identifier_OUT035          300.2762     31.529      9.524      0.000     238.469     362.083\n",
       "Outlet_Identifier_OUT045         -180.8449     32.634     -5.542      0.000    -244.818    -116.872\n",
       "Outlet_Identifier_OUT018          -61.8534     28.772     -2.150      0.032    -118.255      -5.452\n",
       "Outlet_Identifier_OUT017            1.8260     32.339      0.056      0.955     -61.569      65.221\n",
       "Outlet_Identifier_OUT010         -499.7679     39.383    -12.690      0.000    -576.971    -422.565\n",
       "Outlet_Size_Medium                159.9622     20.136      7.944      0.000     120.490     199.434\n",
       "Outlet_Size_Small                -116.2517     15.321     -7.588      0.000    -146.286     -86.217\n",
       "Outlet_Location_Type_Tier 3       211.1954     24.420      8.649      0.000     163.325     259.066\n",
       "Outlet_Location_Type_Tier 2       121.2573     19.368      6.261      0.000      83.290     159.225\n",
       "Outlet_Type_Supermarket Type1     423.8047     23.127     18.325      0.000     378.468     469.141\n",
       "Outlet_Type_Grocery Store       -1177.3914     26.546    -44.352      0.000   -1229.431   -1125.352\n",
       "Outlet_Type_Supermarket Type3     815.9837     19.354     42.161      0.000     778.043     853.924\n",
       "==============================================================================\n",
       "Omnibus:                      798.472   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2003.121\n",
       "Skew:                           0.674   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.288   Cond. No.                     1.66e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.9e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_c=sm.add_constant(inp)\n",
    "ols1=sm.OLS(out,inp_c)\n",
    "mod1=ols1.fit()\n",
    "mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6818, 40)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1705, 40)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check rmse on test data\n",
    "x_train_c=sm.add_constant(x_train2)\n",
    "x_train_c.shape\n",
    "ypred = mod1.predict(x_train_c)\n",
    "mean_squared_error(y_train2,ypred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = mod1.predict(x_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185.466592383839"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train2,ypred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_pf = inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Fat_Content_LF</th>\n",
       "      <th>Item_Fat_Content_reg</th>\n",
       "      <th>Item_Type_Fruits and Vegetables</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Identifier_OUT018</th>\n",
       "      <th>Outlet_Identifier_OUT017</th>\n",
       "      <th>Outlet_Identifier_OUT010</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7173</td>\n",
       "      <td>11.800</td>\n",
       "      <td>0.057422</td>\n",
       "      <td>149.9366</td>\n",
       "      <td>1997</td>\n",
       "      <td>1662.5026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3315</td>\n",
       "      <td>12.600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.1384</td>\n",
       "      <td>1985</td>\n",
       "      <td>2956.1520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5932</td>\n",
       "      <td>7.725</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>249.1092</td>\n",
       "      <td>1997</td>\n",
       "      <td>2490.0920</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7872</td>\n",
       "      <td>10.500</td>\n",
       "      <td>0.052555</td>\n",
       "      <td>89.6830</td>\n",
       "      <td>1997</td>\n",
       "      <td>988.7130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5946</td>\n",
       "      <td>12.600</td>\n",
       "      <td>0.235859</td>\n",
       "      <td>46.1402</td>\n",
       "      <td>1985</td>\n",
       "      <td>45.9402</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
       "7173       11.800         0.057422  149.9366                       1997   \n",
       "3315       12.600         0.000000  100.1384                       1985   \n",
       "5932        7.725         0.047783  249.1092                       1997   \n",
       "7872       10.500         0.052555   89.6830                       1997   \n",
       "5946       12.600         0.235859   46.1402                       1985   \n",
       "\n",
       "      Item_Outlet_Sales  Item_Fat_Content_Low Fat  Item_Fat_Content_Regular  \\\n",
       "7173          1662.5026                         0                         1   \n",
       "3315          2956.1520                         1                         0   \n",
       "5932          2490.0920                         1                         0   \n",
       "7872           988.7130                         1                         0   \n",
       "5946            45.9402                         0                         1   \n",
       "\n",
       "      Item_Fat_Content_LF  Item_Fat_Content_reg  \\\n",
       "7173                    0                     0   \n",
       "3315                    0                     0   \n",
       "5932                    0                     0   \n",
       "7872                    0                     0   \n",
       "5946                    0                     0   \n",
       "\n",
       "      Item_Type_Fruits and Vegetables  ...  Outlet_Identifier_OUT018  \\\n",
       "7173                                0  ...                         0   \n",
       "3315                                0  ...                         0   \n",
       "5932                                0  ...                         0   \n",
       "7872                                0  ...                         0   \n",
       "5946                                0  ...                         0   \n",
       "\n",
       "      Outlet_Identifier_OUT017  Outlet_Identifier_OUT010  Outlet_Size_Medium  \\\n",
       "7173                         0                         0                   0   \n",
       "3315                         0                         0                   1   \n",
       "5932                         0                         0                   0   \n",
       "7872                         0                         0                   0   \n",
       "5946                         0                         0                   0   \n",
       "\n",
       "      Outlet_Size_Small  Outlet_Location_Type_Tier 3  \\\n",
       "7173                  1                            0   \n",
       "3315                  0                            1   \n",
       "5932                  1                            0   \n",
       "7872                  1                            0   \n",
       "5946                  1                            0   \n",
       "\n",
       "      Outlet_Location_Type_Tier 2  Outlet_Type_Supermarket Type1  \\\n",
       "7173                            0                              1   \n",
       "3315                            0                              0   \n",
       "5932                            0                              1   \n",
       "7872                            0                              1   \n",
       "5946                            0                              0   \n",
       "\n",
       "      Outlet_Type_Grocery Store  Outlet_Type_Supermarket Type3  \n",
       "7173                          0                              0  \n",
       "3315                          0                              1  \n",
       "5932                          0                              0  \n",
       "7872                          0                              0  \n",
       "5946                          1                              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final features trough backward eliminations are : Index(['Item_MRP', 'Outlet_Establishment_Year', 'Outlet_Identifier_OUT027',\n",
      "       'Outlet_Identifier_OUT013', 'Outlet_Identifier_OUT046',\n",
      "       'Outlet_Identifier_OUT049', 'Outlet_Identifier_OUT035',\n",
      "       'Outlet_Identifier_OUT045', 'Outlet_Identifier_OUT018',\n",
      "       'Outlet_Identifier_OUT010', 'Outlet_Size_Medium', 'Outlet_Size_Small',\n",
      "       'Outlet_Location_Type_Tier 3', 'Outlet_Location_Type_Tier 2',\n",
      "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Grocery Store',\n",
      "       'Outlet_Type_Supermarket Type3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "while(len(inp_pf.columns)>0):\n",
    "    inp_c=sm.add_constant(inp_pf)\n",
    "    ols_pf=sm.OLS(out,inp_c)\n",
    "    mod_pf=ols_pf.fit()\n",
    "    f=mod_pf.pvalues[1:].idxmax()\n",
    "    if mod_pf.pvalues[1:].max()>0.05:\n",
    "        inp_pf=inp_pf.drop(f,1)\n",
    "    else:\n",
    "        break\n",
    "print('The final features trough backward eliminations are :',inp_pf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>Item_Outlet_Sales</td> <th>  R-squared:         </th> <td>   0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   893.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 May 2020</td>  <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:09:37</td>      <th>  Log-Likelihood:    </th> <td> -57505.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6818</td>       <th>  AIC:               </th> <td>1.150e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6807</td>       <th>  BIC:               </th> <td>1.151e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                         <td>    0.4775</td> <td>    0.465</td> <td>    1.026</td> <td> 0.305</td> <td>   -0.434</td> <td>    1.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Item_MRP</th>                      <td>   15.5680</td> <td>    0.217</td> <td>   71.731</td> <td> 0.000</td> <td>   15.143</td> <td>   15.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Establishment_Year</th>     <td>   -0.2659</td> <td>    0.023</td> <td>  -11.679</td> <td> 0.000</td> <td>   -0.311</td> <td>   -0.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT027</th>      <td>  816.5472</td> <td>   19.341</td> <td>   42.219</td> <td> 0.000</td> <td>  778.633</td> <td>  854.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT013</th>      <td>  -44.7744</td> <td>   22.286</td> <td>   -2.009</td> <td> 0.045</td> <td>  -88.462</td> <td>   -1.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT046</th>      <td>  263.7091</td> <td>   35.734</td> <td>    7.380</td> <td> 0.000</td> <td>  193.659</td> <td>  333.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT049</th>      <td>   84.2842</td> <td>   35.357</td> <td>    2.384</td> <td> 0.017</td> <td>   14.974</td> <td>  153.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT035</th>      <td>  302.0422</td> <td>   40.683</td> <td>    7.424</td> <td> 0.000</td> <td>  222.290</td> <td>  381.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT045</th>      <td> -179.4444</td> <td>   57.622</td> <td>   -3.114</td> <td> 0.002</td> <td> -292.402</td> <td>  -66.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT018</th>      <td>  -57.5713</td> <td>   28.891</td> <td>   -1.993</td> <td> 0.046</td> <td> -114.208</td> <td>   -0.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Identifier_OUT010</th>      <td> -502.3118</td> <td>   40.805</td> <td>  -12.310</td> <td> 0.000</td> <td> -582.302</td> <td> -422.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Size_Medium</th>            <td>  162.4352</td> <td>   20.545</td> <td>    7.906</td> <td> 0.000</td> <td>  122.160</td> <td>  202.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Size_Small</th>             <td> -117.1834</td> <td>   17.965</td> <td>   -6.523</td> <td> 0.000</td> <td> -152.400</td> <td>  -81.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Location_Type_Tier 3</th>   <td>  211.8896</td> <td>   27.752</td> <td>    7.635</td> <td> 0.000</td> <td>  157.488</td> <td>  266.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Location_Type_Tier 2</th>   <td>  123.5292</td> <td>   26.831</td> <td>    4.604</td> <td> 0.000</td> <td>   70.932</td> <td>  176.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Type_Supermarket Type1</th> <td>  426.7482</td> <td>   22.573</td> <td>   18.905</td> <td> 0.000</td> <td>  382.498</td> <td>  470.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Type_Grocery Store</th>     <td>-1185.2465</td> <td>   26.009</td> <td>  -45.571</td> <td> 0.000</td> <td>-1236.232</td> <td>-1134.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outlet_Type_Supermarket Type3</th> <td>  816.5472</td> <td>   19.341</td> <td>   42.219</td> <td> 0.000</td> <td>  778.633</td> <td>  854.461</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>807.028</td> <th>  Durbin-Watson:     </th> <td>   1.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2027.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.680</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.300</td>  <th>  Cond. No.          </th> <td>5.90e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.86e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      Item_Outlet_Sales   R-squared:                       0.567\n",
       "Model:                            OLS   Adj. R-squared:                  0.567\n",
       "Method:                 Least Squares   F-statistic:                     893.1\n",
       "Date:                Fri, 29 May 2020   Prob (F-statistic):               0.00\n",
       "Time:                        13:09:37   Log-Likelihood:                -57505.\n",
       "No. Observations:                6818   AIC:                         1.150e+05\n",
       "Df Residuals:                    6807   BIC:                         1.151e+05\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================\n",
       "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "const                             0.4775      0.465      1.026      0.305      -0.434       1.389\n",
       "Item_MRP                         15.5680      0.217     71.731      0.000      15.143      15.993\n",
       "Outlet_Establishment_Year        -0.2659      0.023    -11.679      0.000      -0.311      -0.221\n",
       "Outlet_Identifier_OUT027        816.5472     19.341     42.219      0.000     778.633     854.461\n",
       "Outlet_Identifier_OUT013        -44.7744     22.286     -2.009      0.045     -88.462      -1.087\n",
       "Outlet_Identifier_OUT046        263.7091     35.734      7.380      0.000     193.659     333.760\n",
       "Outlet_Identifier_OUT049         84.2842     35.357      2.384      0.017      14.974     153.595\n",
       "Outlet_Identifier_OUT035        302.0422     40.683      7.424      0.000     222.290     381.794\n",
       "Outlet_Identifier_OUT045       -179.4444     57.622     -3.114      0.002    -292.402     -66.487\n",
       "Outlet_Identifier_OUT018        -57.5713     28.891     -1.993      0.046    -114.208      -0.935\n",
       "Outlet_Identifier_OUT010       -502.3118     40.805    -12.310      0.000    -582.302    -422.321\n",
       "Outlet_Size_Medium              162.4352     20.545      7.906      0.000     122.160     202.710\n",
       "Outlet_Size_Small              -117.1834     17.965     -6.523      0.000    -152.400     -81.967\n",
       "Outlet_Location_Type_Tier 3     211.8896     27.752      7.635      0.000     157.488     266.292\n",
       "Outlet_Location_Type_Tier 2     123.5292     26.831      4.604      0.000      70.932     176.126\n",
       "Outlet_Type_Supermarket Type1   426.7482     22.573     18.905      0.000     382.498     470.999\n",
       "Outlet_Type_Grocery Store     -1185.2465     26.009    -45.571      0.000   -1236.232   -1134.261\n",
       "Outlet_Type_Supermarket Type3   816.5472     19.341     42.219      0.000     778.633     854.461\n",
       "==============================================================================\n",
       "Omnibus:                      807.028   Durbin-Watson:                   1.988\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2027.732\n",
       "Skew:                           0.680   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.300   Cond. No.                     5.90e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.86e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183.6617566884825"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check rmse on test data\n",
    "x_train_c=sm.add_constant(x_train2[inp_pf.columns])\n",
    "ypred = mod_pf.predict(x_train_c)\n",
    "mean_squared_error(y_train2,ypred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x34 x35</th>\n",
       "      <th>x34 x36</th>\n",
       "      <th>x34 x37</th>\n",
       "      <th>x34 x38</th>\n",
       "      <th>x35 x36</th>\n",
       "      <th>x35 x37</th>\n",
       "      <th>x35 x38</th>\n",
       "      <th>x36 x37</th>\n",
       "      <th>x36 x38</th>\n",
       "      <th>x37 x38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.800</td>\n",
       "      <td>0.057422</td>\n",
       "      <td>149.9366</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.1384</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.725</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>249.1092</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.500</td>\n",
       "      <td>0.052555</td>\n",
       "      <td>89.6830</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.600</td>\n",
       "      <td>0.235859</td>\n",
       "      <td>46.1402</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0        x1        x2      x3   x4   x5   x6   x7   x8   x9  ...  \\\n",
       "0  11.800  0.057422  149.9366  1997.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \n",
       "1  12.600  0.000000  100.1384  1985.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2   7.725  0.047783  249.1092  1997.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3  10.500  0.052555   89.6830  1997.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4  12.600  0.235859   46.1402  1985.0  0.0  1.0  0.0  0.0  0.0  1.0  ...   \n",
       "\n",
       "   x34 x35  x34 x36  x34 x37  x34 x38  x35 x36  x35 x37  x35 x38  x36 x37  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   x36 x38  x37 x38  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "2      0.0      0.0  \n",
       "3      0.0      0.0  \n",
       "4      0.0      0.0  \n",
       "\n",
       "[5 rows x 780 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf=PolynomialFeatures(degree=2,include_bias=False, interaction_only=True)\n",
    "inp_pf=pf.fit_transform(inp)\n",
    "inp_pf=pd.DataFrame(inp_pf)\n",
    "inp_pf.columns=pf.get_feature_names()\n",
    "inp_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1294: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.628</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.609</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.61</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 May 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:19:01</td>     <th>  Log-Likelihood:    </th> <td> -56988.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6818</td>      <th>  AIC:               </th> <td>1.146e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6481</td>      <th>  BIC:               </th> <td>1.170e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   336</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    0.0002</td> <td>    0.000</td> <td>    0.426</td> <td> 0.670</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0</th>      <td>   -0.0102</td> <td>    0.046</td> <td>   -0.220</td> <td> 0.826</td> <td>   -0.101</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>      <td>   -1.9517</td> <td>    8.470</td> <td>   -0.230</td> <td> 0.818</td> <td>  -18.556</td> <td>   14.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>      <td>   -0.0018</td> <td>    0.007</td> <td>   -0.244</td> <td> 0.807</td> <td>   -0.016</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>      <td>    0.0124</td> <td>    0.472</td> <td>    0.026</td> <td> 0.979</td> <td>   -0.912</td> <td>    0.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>      <td>   -0.2229</td> <td>    4.120</td> <td>   -0.054</td> <td> 0.957</td> <td>   -8.299</td> <td>    7.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>      <td>   -0.4894</td> <td>    4.176</td> <td>   -0.117</td> <td> 0.907</td> <td>   -8.677</td> <td>    7.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>      <td>   -2.1798</td> <td>    4.691</td> <td>   -0.465</td> <td> 0.642</td> <td>  -11.377</td> <td>    7.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>      <td>   -5.1187</td> <td>    6.515</td> <td>   -0.786</td> <td> 0.432</td> <td>  -17.890</td> <td>    7.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>      <td>   17.0606</td> <td>    6.179</td> <td>    2.761</td> <td> 0.006</td> <td>    4.948</td> <td>   29.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>      <td>   15.6961</td> <td>    6.179</td> <td>    2.540</td> <td> 0.011</td> <td>    3.583</td> <td>   27.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>     <td>   16.7878</td> <td>    6.238</td> <td>    2.691</td> <td> 0.007</td> <td>    4.558</td> <td>   29.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>     <td>   16.3624</td> <td>    6.228</td> <td>    2.627</td> <td> 0.009</td> <td>    4.153</td> <td>   28.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>     <td>   16.4933</td> <td>    6.253</td> <td>    2.638</td> <td> 0.008</td> <td>    4.235</td> <td>   28.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>     <td>   16.5507</td> <td>    6.271</td> <td>    2.639</td> <td> 0.008</td> <td>    4.258</td> <td>   28.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>     <td>   16.2217</td> <td>    6.281</td> <td>    2.583</td> <td> 0.010</td> <td>    3.910</td> <td>   28.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>     <td>   13.5650</td> <td>    6.341</td> <td>    2.139</td> <td> 0.032</td> <td>    1.135</td> <td>   25.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>     <td>   17.0070</td> <td>    6.353</td> <td>    2.677</td> <td> 0.007</td> <td>    4.553</td> <td>   29.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>     <td>   16.5893</td> <td>    6.398</td> <td>    2.593</td> <td> 0.010</td> <td>    4.047</td> <td>   29.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>     <td>   12.3376</td> <td>    6.558</td> <td>    1.881</td> <td> 0.060</td> <td>   -0.518</td> <td>   25.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>     <td>   17.1061</td> <td>    6.893</td> <td>    2.482</td> <td> 0.013</td> <td>    3.594</td> <td>   30.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>     <td>   14.6402</td> <td>    6.742</td> <td>    2.171</td> <td> 0.030</td> <td>    1.423</td> <td>   27.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>     <td>   14.4674</td> <td>    7.547</td> <td>    1.917</td> <td> 0.055</td> <td>   -0.328</td> <td>   29.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>     <td>   14.8383</td> <td>    7.103</td> <td>    2.089</td> <td> 0.037</td> <td>    0.915</td> <td>   28.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>     <td>-2.761e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>     <td>   -0.0002</td> <td>    0.000</td> <td>   -1.965</td> <td> 0.050</td> <td>   -0.000</td> <td>-4.46e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>     <td>    0.0005</td> <td>    0.000</td> <td>    3.687</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>     <td>   -0.0002</td> <td>    0.000</td> <td>   -1.255</td> <td> 0.210</td> <td>   -0.000</td> <td> 8.85e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>     <td> 7.988e-05</td> <td>    0.000</td> <td>    0.675</td> <td> 0.500</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>     <td>-2.742e-05</td> <td>    0.000</td> <td>   -0.219</td> <td> 0.826</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>     <td> 9.149e-05</td> <td>    0.000</td> <td>    0.602</td> <td> 0.547</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>     <td>   -0.0001</td> <td>    0.000</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>     <td>    0.0002</td> <td>    0.000</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>     <td>-1.248e-05</td> <td>    0.000</td> <td>   -0.112</td> <td> 0.911</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>     <td>    0.0002</td> <td>    0.000</td> <td>    1.653</td> <td> 0.098</td> <td>-4.13e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>     <td> 7.457e-05</td> <td>    0.000</td> <td>    0.653</td> <td> 0.514</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>     <td>-5.692e-05</td> <td>  7.4e-05</td> <td>   -0.769</td> <td> 0.442</td> <td>   -0.000</td> <td> 8.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>     <td>  9.11e-05</td> <td>    0.000</td> <td>    0.869</td> <td> 0.385</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>     <td>   -0.0002</td> <td>    0.000</td> <td>   -1.177</td> <td> 0.239</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>     <td> -2.76e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x1</th>   <td>  -74.9030</td> <td>   68.059</td> <td>   -1.101</td> <td> 0.271</td> <td> -208.321</td> <td>   58.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x2</th>   <td>   -0.0359</td> <td>    0.052</td> <td>   -0.686</td> <td> 0.492</td> <td>   -0.138</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x3</th>   <td>    0.0122</td> <td>    0.027</td> <td>    0.450</td> <td> 0.653</td> <td>   -0.041</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x4</th>   <td>    5.9784</td> <td>   34.830</td> <td>    0.172</td> <td> 0.864</td> <td>  -62.300</td> <td>   74.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x5</th>   <td>   10.9082</td> <td>   35.234</td> <td>    0.310</td> <td> 0.757</td> <td>  -58.162</td> <td>   79.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x6</th>   <td>   11.1929</td> <td>   38.358</td> <td>    0.292</td> <td> 0.770</td> <td>  -64.002</td> <td>   86.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x7</th>   <td>    9.9093</td> <td>   46.299</td> <td>    0.214</td> <td> 0.831</td> <td>  -80.851</td> <td>  100.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x8</th>   <td>  -19.5457</td> <td>   40.615</td> <td>   -0.481</td> <td> 0.630</td> <td>  -99.165</td> <td>   60.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x9</th>   <td>  -22.1785</td> <td>   40.651</td> <td>   -0.546</td> <td> 0.585</td> <td> -101.867</td> <td>   57.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x10</th>  <td>  -25.7740</td> <td>   40.993</td> <td>   -0.629</td> <td> 0.530</td> <td> -106.134</td> <td>   54.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x11</th>  <td>  -28.1223</td> <td>   40.974</td> <td>   -0.686</td> <td> 0.493</td> <td> -108.445</td> <td>   52.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x12</th>  <td>  -31.2814</td> <td>   41.311</td> <td>   -0.757</td> <td> 0.449</td> <td> -112.264</td> <td>   49.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x13</th>  <td>  -47.3909</td> <td>   41.291</td> <td>   -1.148</td> <td> 0.251</td> <td> -128.335</td> <td>   33.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x14</th>  <td>  -24.8104</td> <td>   41.263</td> <td>   -0.601</td> <td> 0.548</td> <td> -105.699</td> <td>   56.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x15</th>  <td>  -28.1669</td> <td>   42.108</td> <td>   -0.669</td> <td> 0.504</td> <td> -110.713</td> <td>   54.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x16</th>  <td>  -49.4119</td> <td>   42.212</td> <td>   -1.171</td> <td> 0.242</td> <td> -132.161</td> <td>   33.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x17</th>  <td>  -25.6995</td> <td>   42.247</td> <td>   -0.608</td> <td> 0.543</td> <td> -108.517</td> <td>   57.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x18</th>  <td>  -21.0954</td> <td>   44.293</td> <td>   -0.476</td> <td> 0.634</td> <td> -107.925</td> <td>   65.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x19</th>  <td>  -12.2303</td> <td>   45.396</td> <td>   -0.269</td> <td> 0.788</td> <td> -101.221</td> <td>   76.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x20</th>  <td>  -54.8174</td> <td>   47.219</td> <td>   -1.161</td> <td> 0.246</td> <td> -147.381</td> <td>   37.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x21</th>  <td>  -36.3092</td> <td>   49.278</td> <td>   -0.737</td> <td> 0.461</td> <td> -132.911</td> <td>   60.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x22</th>  <td>   18.9482</td> <td>   48.002</td> <td>    0.395</td> <td> 0.693</td> <td>  -75.152</td> <td>  113.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x23</th>  <td>   -0.0003</td> <td>    0.001</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x24</th>  <td>    1.0525</td> <td>    4.182</td> <td>    0.252</td> <td> 0.801</td> <td>   -7.146</td> <td>    9.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x25</th>  <td>   -3.8102</td> <td>    5.238</td> <td>   -0.727</td> <td> 0.467</td> <td>  -14.079</td> <td>    6.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x26</th>  <td>   -4.3864</td> <td>    5.875</td> <td>   -0.747</td> <td> 0.455</td> <td>  -15.903</td> <td>    7.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x27</th>  <td>    1.3298</td> <td>    5.219</td> <td>    0.255</td> <td> 0.799</td> <td>   -8.901</td> <td>   11.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x28</th>  <td>   -1.4689</td> <td>    6.691</td> <td>   -0.220</td> <td> 0.826</td> <td>  -14.585</td> <td>   11.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x29</th>  <td>   -2.2691</td> <td>    5.413</td> <td>   -0.419</td> <td> 0.675</td> <td>  -12.881</td> <td>    8.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x30</th>  <td>    6.1461</td> <td>    6.660</td> <td>    0.923</td> <td> 0.356</td> <td>   -6.910</td> <td>   19.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x31</th>  <td>    3.4009</td> <td>    4.896</td> <td>    0.695</td> <td> 0.487</td> <td>   -6.197</td> <td>   12.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x32</th>  <td>    1.4223</td> <td>    3.339</td> <td>    0.426</td> <td> 0.670</td> <td>   -5.123</td> <td>    7.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x33</th>  <td>   -2.4850</td> <td>    3.384</td> <td>   -0.734</td> <td> 0.463</td> <td>   -9.118</td> <td>    4.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x34</th>  <td>    2.1840</td> <td>    3.376</td> <td>    0.647</td> <td> 0.518</td> <td>   -4.434</td> <td>    8.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x35</th>  <td>    6.0071</td> <td>    4.018</td> <td>    1.495</td> <td> 0.135</td> <td>   -1.869</td> <td>   13.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x36</th>  <td>   -1.1370</td> <td>    3.500</td> <td>   -0.325</td> <td> 0.745</td> <td>   -7.999</td> <td>    5.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x37</th>  <td>    3.3962</td> <td>    4.896</td> <td>    0.694</td> <td> 0.488</td> <td>   -6.201</td> <td>   12.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x38</th>  <td>   -0.0003</td> <td>    0.001</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x2</th>   <td>   -4.9901</td> <td>    4.450</td> <td>   -1.121</td> <td> 0.262</td> <td>  -13.714</td> <td>    3.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x3</th>   <td>   -1.1436</td> <td>    2.505</td> <td>   -0.457</td> <td> 0.648</td> <td>   -6.054</td> <td>    3.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x4</th>   <td> -714.5455</td> <td> 2314.058</td> <td>   -0.309</td> <td> 0.757</td> <td>-5250.863</td> <td> 3821.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x5</th>   <td>-1692.6360</td> <td> 2338.753</td> <td>   -0.724</td> <td> 0.469</td> <td>-6277.363</td> <td> 2892.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x6</th>   <td> -377.4756</td> <td> 2579.616</td> <td>   -0.146</td> <td> 0.884</td> <td>-5434.375</td> <td> 4679.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x7</th>   <td> 5632.6797</td> <td> 4052.966</td> <td>    1.390</td> <td> 0.165</td> <td>-2312.471</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x8</th>   <td> 5692.7091</td> <td> 4354.494</td> <td>    1.307</td> <td> 0.191</td> <td>-2843.537</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x9</th>   <td> 5122.5571</td> <td> 4356.726</td> <td>    1.176</td> <td> 0.240</td> <td>-3418.063</td> <td> 1.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x10</th>  <td> 3997.6939</td> <td> 4399.923</td> <td>    0.909</td> <td> 0.364</td> <td>-4627.607</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x11</th>  <td> 4275.6296</td> <td> 4382.346</td> <td>    0.976</td> <td> 0.329</td> <td>-4315.214</td> <td> 1.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x12</th>  <td> 4728.9001</td> <td> 4396.906</td> <td>    1.076</td> <td> 0.282</td> <td>-3890.486</td> <td> 1.33e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x13</th>  <td> 5208.1116</td> <td> 4420.892</td> <td>    1.178</td> <td> 0.239</td> <td>-3458.295</td> <td> 1.39e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x14</th>  <td> 4527.4955</td> <td> 4395.656</td> <td>    1.030</td> <td> 0.303</td> <td>-4089.441</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x15</th>  <td> 4186.3614</td> <td> 4515.533</td> <td>    0.927</td> <td> 0.354</td> <td>-4665.574</td> <td>  1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x16</th>  <td> 5656.8845</td> <td> 4439.743</td> <td>    1.274</td> <td> 0.203</td> <td>-3046.477</td> <td> 1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x17</th>  <td> 4387.3428</td> <td> 4481.893</td> <td>    0.979</td> <td> 0.328</td> <td>-4398.647</td> <td> 1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x18</th>  <td> 3607.6941</td> <td> 4587.607</td> <td>    0.786</td> <td> 0.432</td> <td>-5385.531</td> <td> 1.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x19</th>  <td> 4929.3000</td> <td> 4704.930</td> <td>    1.048</td> <td> 0.295</td> <td>-4293.916</td> <td> 1.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x20</th>  <td> 5334.7011</td> <td> 4711.768</td> <td>    1.132</td> <td> 0.258</td> <td>-3901.919</td> <td> 1.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x21</th>  <td> 4642.1774</td> <td> 4901.392</td> <td>    0.947</td> <td> 0.344</td> <td>-4966.169</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x22</th>  <td> 1.106e+04</td> <td> 4989.919</td> <td>    2.216</td> <td> 0.027</td> <td> 1274.752</td> <td> 2.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x23</th>  <td> -169.2660</td> <td>  418.641</td> <td>   -0.404</td> <td> 0.686</td> <td> -989.940</td> <td>  651.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x24</th>  <td> -145.7273</td> <td>  476.239</td> <td>   -0.306</td> <td> 0.760</td> <td>-1079.312</td> <td>  787.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x25</th>  <td>  402.6318</td> <td>  697.300</td> <td>    0.577</td> <td> 0.564</td> <td> -964.306</td> <td> 1769.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x26</th>  <td>  -43.7494</td> <td>  594.641</td> <td>   -0.074</td> <td> 0.941</td> <td>-1209.443</td> <td> 1121.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x27</th>  <td> -372.5389</td> <td>  629.259</td> <td>   -0.592</td> <td> 0.554</td> <td>-1606.094</td> <td>  861.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x28</th>  <td>  437.3160</td> <td>  694.044</td> <td>    0.630</td> <td> 0.529</td> <td> -923.240</td> <td> 1797.872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x29</th>  <td>  511.2789</td> <td>  599.547</td> <td>    0.853</td> <td> 0.394</td> <td> -664.032</td> <td> 1686.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x30</th>  <td> -558.3147</td> <td>  694.231</td> <td>   -0.804</td> <td> 0.421</td> <td>-1919.236</td> <td>  802.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x31</th>  <td>  -30.6531</td> <td>  578.141</td> <td>   -0.053</td> <td> 0.958</td> <td>-1164.000</td> <td> 1102.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x32</th>  <td>  146.6116</td> <td>  368.593</td> <td>    0.398</td> <td> 0.691</td> <td> -575.952</td> <td>  869.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x33</th>  <td>   -2.8361</td> <td>  309.138</td> <td>   -0.009</td> <td> 0.993</td> <td> -608.850</td> <td>  603.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x34</th>  <td>  165.6325</td> <td>  410.980</td> <td>    0.403</td> <td> 0.687</td> <td> -640.024</td> <td>  971.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x35</th>  <td> -493.5376</td> <td>  412.279</td> <td>   -1.197</td> <td> 0.231</td> <td>-1301.740</td> <td>  314.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x36</th>  <td> -280.3825</td> <td>  395.083</td> <td>   -0.710</td> <td> 0.478</td> <td>-1054.876</td> <td>  494.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x37</th>  <td>  -63.5821</td> <td>  401.883</td> <td>   -0.158</td> <td> 0.874</td> <td> -851.405</td> <td>  724.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x38</th>  <td> -169.2660</td> <td>  418.641</td> <td>   -0.404</td> <td> 0.686</td> <td> -989.940</td> <td>  651.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x3</th>   <td>    0.0074</td> <td>    0.002</td> <td>    3.510</td> <td> 0.000</td> <td>    0.003</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x4</th>   <td>   -1.6828</td> <td>    1.916</td> <td>   -0.878</td> <td> 0.380</td> <td>   -5.440</td> <td>    2.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x5</th>   <td>   -2.1254</td> <td>    1.945</td> <td>   -1.093</td> <td> 0.275</td> <td>   -5.939</td> <td>    1.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x6</th>   <td>   -4.5859</td> <td>    2.245</td> <td>   -2.042</td> <td> 0.041</td> <td>   -8.987</td> <td>   -0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x7</th>   <td>   -1.5126</td> <td>    2.846</td> <td>   -0.531</td> <td> 0.595</td> <td>   -7.092</td> <td>    4.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x8</th>   <td>    0.8951</td> <td>    3.662</td> <td>    0.244</td> <td> 0.807</td> <td>   -6.283</td> <td>    8.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x9</th>   <td>   -0.4435</td> <td>    3.666</td> <td>   -0.121</td> <td> 0.904</td> <td>   -7.630</td> <td>    6.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x10</th>  <td>   -1.1536</td> <td>    3.669</td> <td>   -0.314</td> <td> 0.753</td> <td>   -8.347</td> <td>    6.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x11</th>  <td>    0.1745</td> <td>    3.666</td> <td>    0.048</td> <td> 0.962</td> <td>   -7.013</td> <td>    7.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x12</th>  <td>    0.3918</td> <td>    3.673</td> <td>    0.107</td> <td> 0.915</td> <td>   -6.809</td> <td>    7.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x13</th>  <td>   -0.2009</td> <td>    3.716</td> <td>   -0.054</td> <td> 0.957</td> <td>   -7.486</td> <td>    7.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x14</th>  <td>    0.3103</td> <td>    3.702</td> <td>    0.084</td> <td> 0.933</td> <td>   -6.947</td> <td>    7.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x15</th>  <td>   -1.4772</td> <td>    3.724</td> <td>   -0.397</td> <td> 0.692</td> <td>   -8.778</td> <td>    5.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x16</th>  <td>   -0.0537</td> <td>    3.766</td> <td>   -0.014</td> <td> 0.989</td> <td>   -7.436</td> <td>    7.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x17</th>  <td>    1.0089</td> <td>    3.742</td> <td>    0.270</td> <td> 0.787</td> <td>   -6.328</td> <td>    8.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x18</th>  <td>   -0.9906</td> <td>    3.818</td> <td>   -0.259</td> <td> 0.795</td> <td>   -8.476</td> <td>    6.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x19</th>  <td>   -0.7903</td> <td>    3.862</td> <td>   -0.205</td> <td> 0.838</td> <td>   -8.361</td> <td>    6.780</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x20</th>  <td>   -0.3798</td> <td>    3.958</td> <td>   -0.096</td> <td> 0.924</td> <td>   -8.138</td> <td>    7.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x21</th>  <td>   -1.4123</td> <td>    3.932</td> <td>   -0.359</td> <td> 0.719</td> <td>   -9.120</td> <td>    6.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x22</th>  <td>    5.7702</td> <td>    4.230</td> <td>    1.364</td> <td> 0.173</td> <td>   -2.522</td> <td>   14.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x23</th>  <td>    4.9266</td> <td>    0.299</td> <td>   16.496</td> <td> 0.000</td> <td>    4.341</td> <td>    5.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x24</th>  <td>    0.4197</td> <td>    0.345</td> <td>    1.217</td> <td> 0.224</td> <td>   -0.256</td> <td>    1.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x25</th>  <td>    1.1376</td> <td>    0.561</td> <td>    2.028</td> <td> 0.043</td> <td>    0.038</td> <td>    2.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x26</th>  <td>    0.9126</td> <td>    0.436</td> <td>    2.091</td> <td> 0.037</td> <td>    0.057</td> <td>    1.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x27</th>  <td>    2.4170</td> <td>    0.497</td> <td>    4.862</td> <td> 0.000</td> <td>    1.442</td> <td>    3.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x28</th>  <td>   -1.5185</td> <td>    0.512</td> <td>   -2.965</td> <td> 0.003</td> <td>   -2.523</td> <td>   -0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x29</th>  <td>    0.1141</td> <td>    0.448</td> <td>    0.255</td> <td> 0.799</td> <td>   -0.763</td> <td>    0.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x30</th>  <td>   -0.0098</td> <td>    0.504</td> <td>   -0.019</td> <td> 0.985</td> <td>   -0.999</td> <td>    0.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x31</th>  <td>   -3.5666</td> <td>    0.625</td> <td>   -5.706</td> <td> 0.000</td> <td>   -4.792</td> <td>   -2.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x32</th>  <td>    0.8585</td> <td>    0.318</td> <td>    2.698</td> <td> 0.007</td> <td>    0.235</td> <td>    1.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x33</th>  <td>   -1.2800</td> <td>    0.240</td> <td>   -5.326</td> <td> 0.000</td> <td>   -1.751</td> <td>   -0.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x34</th>  <td>    1.8939</td> <td>    0.388</td> <td>    4.887</td> <td> 0.000</td> <td>    1.134</td> <td>    2.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x35</th>  <td>    0.8887</td> <td>    0.305</td> <td>    2.917</td> <td> 0.004</td> <td>    0.291</td> <td>    1.486</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x36</th>  <td>    3.3587</td> <td>    0.366</td> <td>    9.188</td> <td> 0.000</td> <td>    2.642</td> <td>    4.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x37</th>  <td>   -8.4012</td> <td>    0.421</td> <td>  -19.944</td> <td> 0.000</td> <td>   -9.227</td> <td>   -7.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x38</th>  <td>    4.9266</td> <td>    0.299</td> <td>   16.496</td> <td> 0.000</td> <td>    4.341</td> <td>    5.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x4</th>   <td>   -0.2539</td> <td>    0.745</td> <td>   -0.341</td> <td> 0.733</td> <td>   -1.714</td> <td>    1.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x5</th>   <td>   -0.0963</td> <td>    0.785</td> <td>   -0.123</td> <td> 0.902</td> <td>   -1.635</td> <td>    1.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x6</th>   <td>   -0.4062</td> <td>    0.844</td> <td>   -0.482</td> <td> 0.630</td> <td>   -2.060</td> <td>    1.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x7</th>   <td>   -0.1489</td> <td>    0.470</td> <td>   -0.317</td> <td> 0.751</td> <td>   -1.070</td> <td>    0.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x8</th>   <td>   -0.3283</td> <td>    0.812</td> <td>   -0.405</td> <td> 0.686</td> <td>   -1.919</td> <td>    1.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x9</th>   <td>   -0.2791</td> <td>    0.823</td> <td>   -0.339</td> <td> 0.735</td> <td>   -1.893</td> <td>    1.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x10</th>  <td>   -0.2044</td> <td>    0.818</td> <td>   -0.250</td> <td> 0.803</td> <td>   -1.807</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x11</th>  <td>   -0.4896</td> <td>    0.859</td> <td>   -0.570</td> <td> 0.569</td> <td>   -2.173</td> <td>    1.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x12</th>  <td>   -0.2974</td> <td>    0.824</td> <td>   -0.361</td> <td> 0.718</td> <td>   -1.912</td> <td>    1.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x13</th>  <td>   -0.1856</td> <td>    0.833</td> <td>   -0.223</td> <td> 0.824</td> <td>   -1.818</td> <td>    1.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x14</th>  <td>   -0.1640</td> <td>    0.833</td> <td>   -0.197</td> <td> 0.844</td> <td>   -1.798</td> <td>    1.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x15</th>  <td>   -0.3898</td> <td>    0.836</td> <td>   -0.466</td> <td> 0.641</td> <td>   -2.028</td> <td>    1.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x16</th>  <td>    0.3455</td> <td>    0.970</td> <td>    0.356</td> <td> 0.722</td> <td>   -1.556</td> <td>    2.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x17</th>  <td>   -0.3265</td> <td>    0.864</td> <td>   -0.378</td> <td> 0.706</td> <td>   -2.020</td> <td>    1.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x18</th>  <td>   -0.3039</td> <td>    0.839</td> <td>   -0.362</td> <td> 0.717</td> <td>   -1.949</td> <td>    1.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x19</th>  <td>   -0.3760</td> <td>    0.868</td> <td>   -0.433</td> <td> 0.665</td> <td>   -2.078</td> <td>    1.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x20</th>  <td>    0.0903</td> <td>    0.924</td> <td>    0.098</td> <td> 0.922</td> <td>   -1.722</td> <td>    1.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x21</th>  <td>   -0.5579</td> <td>    1.023</td> <td>   -0.545</td> <td> 0.586</td> <td>   -2.563</td> <td>    1.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x22</th>  <td>   -0.8306</td> <td>    0.520</td> <td>   -1.598</td> <td> 0.110</td> <td>   -1.849</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x23</th>  <td>   -0.0548</td> <td>    0.152</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.353</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x24</th>  <td>   -0.4116</td> <td>    0.210</td> <td>   -1.965</td> <td> 0.050</td> <td>   -0.822</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x25</th>  <td>    1.0236</td> <td>    0.278</td> <td>    3.687</td> <td> 0.000</td> <td>    0.479</td> <td>    1.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x26</th>  <td>   -0.3146</td> <td>    0.251</td> <td>   -1.255</td> <td> 0.210</td> <td>   -0.806</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x27</th>  <td>    0.1601</td> <td>    0.237</td> <td>    0.674</td> <td> 0.500</td> <td>   -0.305</td> <td>    0.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x28</th>  <td>   -0.0549</td> <td>    0.250</td> <td>   -0.219</td> <td> 0.826</td> <td>   -0.546</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x29</th>  <td>    0.1839</td> <td>    0.305</td> <td>    0.602</td> <td> 0.547</td> <td>   -0.415</td> <td>    0.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x30</th>  <td>   -0.2195</td> <td>    0.262</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.734</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x31</th>  <td>    0.4352</td> <td>    0.367</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.284</td> <td>    1.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x32</th>  <td>   -0.0248</td> <td>    0.223</td> <td>   -0.111</td> <td> 0.911</td> <td>   -0.462</td> <td>    0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x33</th>  <td>    0.4488</td> <td>    0.267</td> <td>    1.682</td> <td> 0.093</td> <td>   -0.074</td> <td>    0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x34</th>  <td>    0.1526</td> <td>    0.228</td> <td>    0.668</td> <td> 0.504</td> <td>   -0.295</td> <td>    0.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x35</th>  <td>   -0.1144</td> <td>    0.148</td> <td>   -0.771</td> <td> 0.441</td> <td>   -0.405</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x36</th>  <td>    0.1830</td> <td>    0.209</td> <td>    0.875</td> <td> 0.381</td> <td>   -0.227</td> <td>    0.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x37</th>  <td>   -0.2997</td> <td>    0.257</td> <td>   -1.165</td> <td> 0.244</td> <td>   -0.804</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x38</th>  <td>   -0.0548</td> <td>    0.152</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.353</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x5</th>   <td>-3.683e-11</td> <td> 2.99e-11</td> <td>   -1.230</td> <td> 0.219</td> <td>-9.55e-11</td> <td> 2.19e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x6</th>   <td>-1.331e-11</td> <td> 1.02e-11</td> <td>   -1.306</td> <td> 0.192</td> <td>-3.33e-11</td> <td> 6.67e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x7</th>   <td>-5.106e-11</td> <td> 3.77e-11</td> <td>   -1.355</td> <td> 0.176</td> <td>-1.25e-10</td> <td> 2.28e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x8</th>   <td>  675.7900</td> <td> 1365.800</td> <td>    0.495</td> <td> 0.621</td> <td>-2001.630</td> <td> 3353.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x9</th>   <td>  790.0492</td> <td> 1390.862</td> <td>    0.568</td> <td> 0.570</td> <td>-1936.500</td> <td> 3516.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x10</th>  <td>  883.0607</td> <td> 1373.556</td> <td>    0.643</td> <td> 0.520</td> <td>-1809.563</td> <td> 3575.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x11</th>  <td> 1235.8337</td> <td> 1474.487</td> <td>    0.838</td> <td> 0.402</td> <td>-1654.647</td> <td> 4126.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x12</th>  <td>  836.6824</td> <td> 1390.273</td> <td>    0.602</td> <td> 0.547</td> <td>-1888.712</td> <td> 3562.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x13</th>  <td>  878.7741</td> <td> 1414.626</td> <td>    0.621</td> <td> 0.534</td> <td>-1894.359</td> <td> 3651.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x14</th>  <td>  581.8373</td> <td> 1413.647</td> <td>    0.412</td> <td> 0.681</td> <td>-2189.378</td> <td> 3353.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x15</th>  <td> 1203.7921</td> <td> 1410.379</td> <td>    0.854</td> <td> 0.393</td> <td>-1561.016</td> <td> 3968.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x16</th>  <td> -145.7449</td> <td> 1708.641</td> <td>   -0.085</td> <td> 0.932</td> <td>-3495.245</td> <td> 3203.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x17</th>  <td>  878.3658</td> <td> 1465.434</td> <td>    0.599</td> <td> 0.549</td> <td>-1994.369</td> <td> 3751.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x18</th>  <td> 1140.7606</td> <td> 1419.388</td> <td>    0.804</td> <td> 0.422</td> <td>-1641.708</td> <td> 3923.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x19</th>  <td>  944.5852</td> <td> 1454.255</td> <td>    0.650</td> <td> 0.516</td> <td>-1906.236</td> <td> 3795.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x20</th>  <td>  449.6460</td> <td> 1589.511</td> <td>    0.283</td> <td> 0.777</td> <td>-2666.321</td> <td> 3565.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x21</th>  <td> 1464.0109</td> <td> 1769.997</td> <td>    0.827</td> <td> 0.408</td> <td>-2005.767</td> <td> 4933.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x22</th>  <td>  168.8212</td> <td>  515.355</td> <td>    0.328</td> <td> 0.743</td> <td> -841.444</td> <td> 1179.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x23</th>  <td>  -88.4169</td> <td>  173.784</td> <td>   -0.509</td> <td> 0.611</td> <td> -429.090</td> <td>  252.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x24</th>  <td>  -57.9089</td> <td>  185.353</td> <td>   -0.312</td> <td> 0.755</td> <td> -421.262</td> <td>  305.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x25</th>  <td> -590.9026</td> <td>  340.505</td> <td>   -1.735</td> <td> 0.083</td> <td>-1258.406</td> <td>   76.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x26</th>  <td>  -45.1385</td> <td>  267.486</td> <td>   -0.169</td> <td> 0.866</td> <td> -569.499</td> <td>  479.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x27</th>  <td>  -55.3437</td> <td>  306.780</td> <td>   -0.180</td> <td> 0.857</td> <td> -656.734</td> <td>  546.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x28</th>  <td>  691.0469</td> <td>  332.414</td> <td>    2.079</td> <td> 0.038</td> <td>   39.406</td> <td> 1342.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x29</th>  <td>  349.6586</td> <td>  325.442</td> <td>    1.074</td> <td> 0.283</td> <td> -288.315</td> <td>  987.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x30</th>  <td> -307.1614</td> <td>  290.377</td> <td>   -1.058</td> <td> 0.290</td> <td> -876.396</td> <td>  262.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x31</th>  <td> -311.5204</td> <td>  406.966</td> <td>   -0.765</td> <td> 0.444</td> <td>-1109.308</td> <td>  486.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x32</th>  <td>  288.4684</td> <td>  167.159</td> <td>    1.726</td> <td> 0.084</td> <td>  -39.219</td> <td>  616.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x33</th>  <td> -230.7824</td> <td>  135.645</td> <td>   -1.701</td> <td> 0.089</td> <td> -496.691</td> <td>   35.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x34</th>  <td> -108.1875</td> <td>  213.226</td> <td>   -0.507</td> <td> 0.612</td> <td> -526.180</td> <td>  309.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x35</th>  <td>  328.5418</td> <td>  190.031</td> <td>    1.729</td> <td> 0.084</td> <td>  -43.982</td> <td>  701.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x36</th>  <td> -365.4081</td> <td>  184.198</td> <td>   -1.984</td> <td> 0.047</td> <td> -726.498</td> <td>   -4.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x37</th>  <td>  103.9435</td> <td>  241.823</td> <td>    0.430</td> <td> 0.667</td> <td> -370.109</td> <td>  577.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x38</th>  <td>  -88.4169</td> <td>  173.784</td> <td>   -0.509</td> <td> 0.611</td> <td> -429.090</td> <td>  252.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x6</th>   <td>-4.595e-11</td> <td> 3.47e-11</td> <td>   -1.324</td> <td> 0.185</td> <td>-1.14e-10</td> <td> 2.21e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x7</th>   <td>-3.333e-11</td> <td> 2.89e-11</td> <td>   -1.153</td> <td> 0.249</td> <td>   -9e-11</td> <td> 2.33e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x8</th>   <td>  360.6412</td> <td> 1446.380</td> <td>    0.249</td> <td> 0.803</td> <td>-2474.741</td> <td> 3196.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x9</th>   <td>  559.3092</td> <td> 1470.533</td> <td>    0.380</td> <td> 0.704</td> <td>-2323.420</td> <td> 3442.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x10</th>  <td> 1.789e-11</td> <td> 1.09e-11</td> <td>    1.641</td> <td> 0.101</td> <td>-3.49e-12</td> <td> 3.93e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x11</th>  <td>  987.1139</td> <td> 1549.591</td> <td>    0.637</td> <td> 0.524</td> <td>-2050.596</td> <td> 4024.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x12</th>  <td>  671.8208</td> <td> 1470.005</td> <td>    0.457</td> <td> 0.648</td> <td>-2209.874</td> <td> 3553.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x13</th>  <td>  744.5291</td> <td> 1492.766</td> <td>    0.499</td> <td> 0.618</td> <td>-2181.784</td> <td> 3670.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x14</th>  <td>  267.0731</td> <td> 1492.053</td> <td>    0.179</td> <td> 0.858</td> <td>-2657.843</td> <td> 3191.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x15</th>  <td>-1.058e-12</td> <td> 9.99e-12</td> <td>   -0.106</td> <td> 0.916</td> <td>-2.06e-11</td> <td> 1.85e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x16</th>  <td> -403.4995</td> <td> 1772.153</td> <td>   -0.228</td> <td> 0.820</td> <td>-3877.504</td> <td> 3070.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x17</th>  <td>  652.2994</td> <td> 1546.692</td> <td>    0.422</td> <td> 0.673</td> <td>-2379.727</td> <td> 3684.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x18</th>  <td>  619.4016</td> <td> 1497.047</td> <td>    0.414</td> <td> 0.679</td> <td>-2315.305</td> <td> 3554.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x19</th>  <td>-3.022e-11</td> <td> 2.13e-11</td> <td>   -1.422</td> <td> 0.155</td> <td>-7.19e-11</td> <td> 1.14e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x20</th>  <td> 8.895e-11</td> <td> 6.89e-11</td> <td>    1.292</td> <td> 0.196</td> <td> -4.6e-11</td> <td> 2.24e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x21</th>  <td> 1323.6751</td> <td> 1836.452</td> <td>    0.721</td> <td> 0.471</td> <td>-2276.377</td> <td> 4923.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x22</th>  <td> -215.5788</td> <td>  601.390</td> <td>   -0.358</td> <td> 0.720</td> <td>-1394.501</td> <td>  963.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x23</th>  <td>  -98.2874</td> <td>  175.574</td> <td>   -0.560</td> <td> 0.576</td> <td> -442.470</td> <td>  245.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x24</th>  <td>  -98.8199</td> <td>  187.934</td> <td>   -0.526</td> <td> 0.599</td> <td> -467.232</td> <td>  269.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x25</th>  <td> -488.6764</td> <td>  344.396</td> <td>   -1.419</td> <td> 0.156</td> <td>-1163.807</td> <td>  186.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x26</th>  <td> -143.7574</td> <td>  271.155</td> <td>   -0.530</td> <td> 0.596</td> <td> -675.310</td> <td>  387.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x27</th>  <td> -152.6385</td> <td>  311.381</td> <td>   -0.490</td> <td> 0.624</td> <td> -763.048</td> <td>  457.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x28</th>  <td>  708.5112</td> <td>  335.912</td> <td>    2.109</td> <td> 0.035</td> <td>   50.012</td> <td> 1367.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x29</th>  <td>  330.3825</td> <td>  328.412</td> <td>    1.006</td> <td> 0.314</td> <td> -313.414</td> <td>  974.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x30</th>  <td> -197.3877</td> <td>  293.350</td> <td>   -0.673</td> <td> 0.501</td> <td> -772.450</td> <td>  377.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x31</th>  <td> -283.4977</td> <td>  410.995</td> <td>   -0.690</td> <td> 0.490</td> <td>-1089.183</td> <td>  522.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x32</th>  <td>  315.9634</td> <td>  169.615</td> <td>    1.863</td> <td> 0.063</td> <td>  -16.538</td> <td>  648.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x33</th>  <td> -217.6329</td> <td>  137.472</td> <td>   -1.583</td> <td> 0.113</td> <td> -487.123</td> <td>   51.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x34</th>  <td> -150.2225</td> <td>  215.863</td> <td>   -0.696</td> <td> 0.487</td> <td> -573.385</td> <td>  272.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x35</th>  <td>  358.4849</td> <td>  192.493</td> <td>    1.862</td> <td> 0.063</td> <td>  -18.864</td> <td>  735.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x36</th>  <td> -372.7689</td> <td>  187.183</td> <td>   -1.991</td> <td> 0.046</td> <td> -739.710</td> <td>   -5.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x37</th>  <td>  140.1844</td> <td>  244.232</td> <td>    0.574</td> <td> 0.566</td> <td> -338.590</td> <td>  618.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x38</th>  <td>  -98.2874</td> <td>  175.574</td> <td>   -0.560</td> <td> 0.576</td> <td> -442.470</td> <td>  245.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x7</th>   <td> 6.854e-12</td> <td> 9.74e-12</td> <td>    0.704</td> <td> 0.482</td> <td>-1.22e-11</td> <td> 2.59e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x8</th>   <td> 1230.4936</td> <td> 1562.275</td> <td>    0.788</td> <td> 0.431</td> <td>-1832.080</td> <td> 4293.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x9</th>   <td> 1273.2990</td> <td> 1589.030</td> <td>    0.801</td> <td> 0.423</td> <td>-1841.725</td> <td> 4388.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x10</th>  <td> 1947.0731</td> <td> 1566.281</td> <td>    1.243</td> <td> 0.214</td> <td>-1123.354</td> <td> 5017.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x11</th>  <td> 2362.7951</td> <td> 1666.725</td> <td>    1.418</td> <td> 0.156</td> <td> -904.535</td> <td> 5630.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x12</th>  <td> 1208.4026</td> <td> 1591.331</td> <td>    0.759</td> <td> 0.448</td> <td>-1911.131</td> <td> 4327.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x13</th>  <td> 1314.7808</td> <td> 1612.863</td> <td>    0.815</td> <td> 0.415</td> <td>-1846.963</td> <td> 4476.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x14</th>  <td> 1012.2367</td> <td> 1618.363</td> <td>    0.625</td> <td> 0.532</td> <td>-2160.289</td> <td> 4184.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x15</th>  <td> 1813.7381</td> <td> 1606.000</td> <td>    1.129</td> <td> 0.259</td> <td>-1334.551</td> <td> 4962.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x16</th>  <td>  683.4545</td> <td> 1900.943</td> <td>    0.360</td> <td> 0.719</td> <td>-3043.020</td> <td> 4409.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x17</th>  <td> 1552.2205</td> <td> 1653.341</td> <td>    0.939</td> <td> 0.348</td> <td>-1688.873</td> <td> 4793.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x18</th>  <td> 1315.7333</td> <td> 1661.983</td> <td>    0.792</td> <td> 0.429</td> <td>-1942.301</td> <td> 4573.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x19</th>  <td> 2239.4629</td> <td> 1690.387</td> <td>    1.325</td> <td> 0.185</td> <td>-1074.253</td> <td> 5553.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x20</th>  <td> 1464.1010</td> <td> 1788.486</td> <td>    0.819</td> <td> 0.413</td> <td>-2041.922</td> <td> 4970.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x21</th>  <td> 2138.4033</td> <td> 1957.383</td> <td>    1.092</td> <td> 0.275</td> <td>-1698.713</td> <td> 5975.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x22</th>  <td>-1038.3982</td> <td>  910.362</td> <td>   -1.141</td> <td> 0.254</td> <td>-2823.009</td> <td>  746.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x23</th>  <td> -254.8304</td> <td>  197.468</td> <td>   -1.290</td> <td> 0.197</td> <td> -641.932</td> <td>  132.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x24</th>  <td> -111.0048</td> <td>  216.643</td> <td>   -0.512</td> <td> 0.608</td> <td> -535.696</td> <td>  313.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x25</th>  <td> -629.9375</td> <td>  380.907</td> <td>   -1.654</td> <td> 0.098</td> <td>-1376.641</td> <td>  116.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x26</th>  <td>  135.8814</td> <td>  310.561</td> <td>    0.438</td> <td> 0.662</td> <td> -472.922</td> <td>  744.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x27</th>  <td> -171.4240</td> <td>  341.276</td> <td>   -0.502</td> <td> 0.615</td> <td> -840.437</td> <td>  497.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x28</th>  <td>  535.9523</td> <td>  381.436</td> <td>    1.405</td> <td> 0.160</td> <td> -211.789</td> <td> 1283.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x29</th>  <td>  542.7481</td> <td>  354.782</td> <td>    1.530</td> <td> 0.126</td> <td> -152.742</td> <td> 1238.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x30</th>  <td> -163.6655</td> <td>  341.036</td> <td>   -0.480</td> <td> 0.631</td> <td> -832.208</td> <td>  504.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x31</th>  <td> -390.3099</td> <td>  448.200</td> <td>   -0.871</td> <td> 0.384</td> <td>-1268.931</td> <td>  488.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x32</th>  <td>  405.7759</td> <td>  195.468</td> <td>    2.076</td> <td> 0.038</td> <td>   22.594</td> <td>  788.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x33</th>  <td> -296.9509</td> <td>  155.538</td> <td>   -1.909</td> <td> 0.056</td> <td> -601.856</td> <td>    7.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x34</th>  <td> -213.3970</td> <td>  246.426</td> <td>   -0.866</td> <td> 0.387</td> <td> -696.473</td> <td>  269.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x35</th>  <td>  200.8627</td> <td>  218.172</td> <td>    0.921</td> <td> 0.357</td> <td> -226.827</td> <td>  628.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x36</th>  <td> -404.1982</td> <td>  217.531</td> <td>   -1.858</td> <td> 0.063</td> <td> -830.631</td> <td>   22.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x37</th>  <td>  114.1007</td> <td>  276.099</td> <td>    0.413</td> <td> 0.679</td> <td> -427.145</td> <td>  655.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x38</th>  <td> -254.8304</td> <td>  197.468</td> <td>   -1.290</td> <td> 0.197</td> <td> -641.932</td> <td>  132.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x8</th>   <td> -488.4796</td> <td>  491.273</td> <td>   -0.994</td> <td> 0.320</td> <td>-1451.537</td> <td>  474.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x9</th>   <td> -292.0720</td> <td>  488.206</td> <td>   -0.598</td> <td> 0.550</td> <td>-1249.117</td> <td>  664.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x10</th>  <td> -7.61e-12</td> <td> 4.34e-12</td> <td>   -1.755</td> <td> 0.079</td> <td>-1.61e-11</td> <td>  8.9e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x11</th>  <td>  695.8052</td> <td>  640.771</td> <td>    1.086</td> <td> 0.278</td> <td> -560.318</td> <td> 1951.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x12</th>  <td> -446.6573</td> <td>  692.522</td> <td>   -0.645</td> <td> 0.519</td> <td>-1804.230</td> <td>  910.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x13</th>  <td>  184.7067</td> <td>  599.307</td> <td>    0.308</td> <td> 0.758</td> <td> -990.133</td> <td> 1359.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x14</th>  <td>  -77.2879</td> <td>  577.712</td> <td>   -0.134</td> <td> 0.894</td> <td>-1209.795</td> <td> 1055.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x15</th>  <td>-1.763e-12</td> <td> 1.63e-12</td> <td>   -1.081</td> <td> 0.280</td> <td>-4.96e-12</td> <td> 1.43e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x16</th>  <td> -806.3990</td> <td> 1150.817</td> <td>   -0.701</td> <td> 0.484</td> <td>-3062.380</td> <td> 1449.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x17</th>  <td>-4.334e-12</td> <td> 3.18e-12</td> <td>   -1.362</td> <td> 0.173</td> <td>-1.06e-11</td> <td>  1.9e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x18</th>  <td> -384.0031</td> <td>  829.058</td> <td>   -0.463</td> <td> 0.643</td> <td>-2009.231</td> <td> 1241.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x19</th>  <td>-4.074e-12</td> <td>  1.2e-12</td> <td>   -3.393</td> <td> 0.001</td> <td>-6.43e-12</td> <td>-1.72e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x20</th>  <td> 2.371e-12</td> <td> 2.07e-12</td> <td>    1.143</td> <td> 0.253</td> <td> -1.7e-12</td> <td> 6.44e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x21</th>  <td>  509.2743</td> <td> 1153.641</td> <td>    0.441</td> <td> 0.659</td> <td>-1752.243</td> <td> 2770.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x22</th>  <td> 1099.9941</td> <td> 1157.414</td> <td>    0.950</td> <td> 0.342</td> <td>-1168.919</td> <td> 3368.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x23</th>  <td> -519.9135</td> <td>  295.026</td> <td>   -1.762</td> <td> 0.078</td> <td>-1098.262</td> <td>   58.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x24</th>  <td> -118.8622</td> <td>  299.770</td> <td>   -0.397</td> <td> 0.692</td> <td> -706.510</td> <td>  468.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x25</th>  <td>  -12.1353</td> <td>  512.367</td> <td>   -0.024</td> <td> 0.981</td> <td>-1016.544</td> <td>  992.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x26</th>  <td> -296.4437</td> <td>  355.135</td> <td>   -0.835</td> <td> 0.404</td> <td> -992.626</td> <td>  399.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x27</th>  <td> -271.2725</td> <td>  454.849</td> <td>   -0.596</td> <td> 0.551</td> <td>-1162.926</td> <td>  620.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x28</th>  <td>  920.4159</td> <td>  440.126</td> <td>    2.091</td> <td> 0.037</td> <td>   57.623</td> <td> 1783.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x29</th>  <td>  578.3524</td> <td>  409.248</td> <td>    1.413</td> <td> 0.158</td> <td> -223.910</td> <td> 1380.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x30</th>  <td> -391.1287</td> <td>  392.262</td> <td>   -0.997</td> <td> 0.319</td> <td>-1160.092</td> <td>  377.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x31</th>  <td>  -82.6554</td> <td>  544.409</td> <td>   -0.152</td> <td> 0.879</td> <td>-1149.876</td> <td>  984.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x32</th>  <td>  208.6270</td> <td>  267.744</td> <td>    0.779</td> <td> 0.436</td> <td> -316.241</td> <td>  733.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x33</th>  <td>  -94.8834</td> <td>  210.241</td> <td>   -0.451</td> <td> 0.652</td> <td> -507.025</td> <td>  317.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x34</th>  <td> -143.0788</td> <td>  329.037</td> <td>   -0.435</td> <td> 0.664</td> <td> -788.099</td> <td>  501.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x35</th>  <td>  258.0147</td> <td>  272.132</td> <td>    0.948</td> <td> 0.343</td> <td> -275.453</td> <td>  791.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x36</th>  <td> -169.4264</td> <td>  311.269</td> <td>   -0.544</td> <td> 0.586</td> <td> -779.616</td> <td>  440.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x37</th>  <td>  105.8689</td> <td>  364.222</td> <td>    0.291</td> <td> 0.771</td> <td> -608.126</td> <td>  819.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x38</th>  <td> -519.9135</td> <td>  295.026</td> <td>   -1.762</td> <td> 0.078</td> <td>-1098.262</td> <td>   58.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x9</th>   <td>-6.254e-13</td> <td>  5.5e-13</td> <td>   -1.137</td> <td> 0.256</td> <td> -1.7e-12</td> <td> 4.53e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x10</th>  <td> 2.733e-13</td> <td> 3.99e-13</td> <td>    0.685</td> <td> 0.494</td> <td>-5.09e-13</td> <td> 1.06e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x11</th>  <td>-1.155e-12</td> <td> 7.34e-13</td> <td>   -1.573</td> <td> 0.116</td> <td>-2.59e-12</td> <td> 2.84e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x12</th>  <td> 2.315e-13</td> <td> 8.17e-13</td> <td>    0.283</td> <td> 0.777</td> <td>-1.37e-12</td> <td> 1.83e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x13</th>  <td> 2.451e-13</td> <td> 3.99e-13</td> <td>    0.614</td> <td> 0.539</td> <td>-5.38e-13</td> <td> 1.03e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x14</th>  <td>-2.664e-12</td> <td> 9.58e-13</td> <td>   -2.780</td> <td> 0.005</td> <td>-4.54e-12</td> <td>-7.85e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x15</th>  <td> 1.036e-12</td> <td> 4.96e-13</td> <td>    2.089</td> <td> 0.037</td> <td> 6.38e-14</td> <td> 2.01e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x16</th>  <td>-3.983e-12</td> <td> 1.55e-12</td> <td>   -2.562</td> <td> 0.010</td> <td>-7.03e-12</td> <td>-9.36e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x17</th>  <td> 8.575e-13</td> <td> 6.31e-13</td> <td>    1.360</td> <td> 0.174</td> <td>-3.79e-13</td> <td> 2.09e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x18</th>  <td>-8.907e-13</td> <td> 5.74e-13</td> <td>   -1.552</td> <td> 0.121</td> <td>-2.02e-12</td> <td> 2.34e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x19</th>  <td> 1.126e-12</td> <td>  6.4e-13</td> <td>    1.758</td> <td> 0.079</td> <td> -1.3e-13</td> <td> 2.38e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x20</th>  <td> -6.75e-13</td> <td> 5.44e-13</td> <td>   -1.240</td> <td> 0.215</td> <td>-1.74e-12</td> <td> 3.92e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x21</th>  <td>-1.164e-14</td> <td> 3.15e-13</td> <td>   -0.037</td> <td> 0.970</td> <td>-6.29e-13</td> <td> 6.05e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x22</th>  <td> -1.96e-12</td> <td> 9.23e-13</td> <td>   -2.124</td> <td> 0.034</td> <td>-3.77e-12</td> <td>-1.51e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x23</th>  <td>  486.8156</td> <td>  234.405</td> <td>    2.077</td> <td> 0.038</td> <td>   27.304</td> <td>  946.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x24</th>  <td>  793.9208</td> <td>  340.142</td> <td>    2.334</td> <td> 0.020</td> <td>  127.131</td> <td> 1460.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x25</th>  <td>-1360.0992</td> <td>  433.896</td> <td>   -3.135</td> <td> 0.002</td> <td>-2210.679</td> <td> -509.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x26</th>  <td>  667.9523</td> <td>  363.310</td> <td>    1.839</td> <td> 0.066</td> <td>  -44.255</td> <td> 1380.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x27</th>  <td> -294.5133</td> <td>  359.005</td> <td>   -0.820</td> <td> 0.412</td> <td> -998.281</td> <td>  409.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x28</th>  <td> -490.7699</td> <td>  391.619</td> <td>   -1.253</td> <td> 0.210</td> <td>-1258.473</td> <td>  276.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x29</th>  <td> -848.4931</td> <td>  434.721</td> <td>   -1.952</td> <td> 0.051</td> <td>-1700.689</td> <td>    3.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x30</th>  <td>  660.1354</td> <td>  417.918</td> <td>    1.580</td> <td> 0.114</td> <td> -159.122</td> <td> 1479.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x31</th>  <td> -669.5368</td> <td>  556.628</td> <td>   -1.203</td> <td> 0.229</td> <td>-1760.711</td> <td>  421.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x32</th>  <td> -193.8965</td> <td>  273.821</td> <td>   -0.708</td> <td> 0.479</td> <td> -730.675</td> <td>  342.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x33</th>  <td> -582.9636</td> <td>  190.686</td> <td>   -3.057</td> <td> 0.002</td> <td> -956.771</td> <td> -209.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x34</th>  <td> -237.2936</td> <td>  328.856</td> <td>   -0.722</td> <td> 0.471</td> <td> -881.959</td> <td>  407.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x35</th>  <td> -125.1478</td> <td>  245.514</td> <td>   -0.510</td> <td> 0.610</td> <td> -606.437</td> <td>  356.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x36</th>  <td>  -23.3739</td> <td>  266.556</td> <td>   -0.088</td> <td> 0.930</td> <td> -545.912</td> <td>  499.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x37</th>  <td>  402.1121</td> <td>  328.159</td> <td>    1.225</td> <td> 0.220</td> <td> -241.188</td> <td> 1045.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x38</th>  <td>  486.8156</td> <td>  234.405</td> <td>    2.077</td> <td> 0.038</td> <td>   27.304</td> <td>  946.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x10</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x11</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x12</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x13</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x14</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x15</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x16</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x17</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x18</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x19</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x20</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x21</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x22</th>  <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x23</th>  <td>  313.7290</td> <td>  234.356</td> <td>    1.339</td> <td> 0.181</td> <td> -145.686</td> <td>  773.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x24</th>  <td>  845.3347</td> <td>  340.745</td> <td>    2.481</td> <td> 0.013</td> <td>  177.362</td> <td> 1513.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x25</th>  <td>-1416.3159</td> <td>  434.841</td> <td>   -3.257</td> <td> 0.001</td> <td>-2268.748</td> <td> -563.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x26</th>  <td>  748.4595</td> <td>  362.801</td> <td>    2.063</td> <td> 0.039</td> <td>   37.250</td> <td> 1459.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x27</th>  <td> -209.8557</td> <td>  357.814</td> <td>   -0.586</td> <td> 0.558</td> <td> -911.289</td> <td>  491.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x28</th>  <td> -616.4942</td> <td>  391.427</td> <td>   -1.575</td> <td> 0.115</td> <td>-1383.820</td> <td>  150.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x29</th>  <td> -792.8596</td> <td>  435.433</td> <td>   -1.821</td> <td> 0.069</td> <td>-1646.453</td> <td>   60.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x30</th>  <td>  686.3787</td> <td>  417.336</td> <td>    1.645</td> <td> 0.100</td> <td> -131.737</td> <td> 1504.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x31</th>  <td> -610.3439</td> <td>  556.496</td> <td>   -1.097</td> <td> 0.273</td> <td>-1701.260</td> <td>  480.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x32</th>  <td> -271.1305</td> <td>  273.884</td> <td>   -0.990</td> <td> 0.322</td> <td> -808.034</td> <td>  265.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x33</th>  <td> -558.5081</td> <td>  190.739</td> <td>   -2.928</td> <td> 0.003</td> <td> -932.420</td> <td> -184.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x34</th>  <td> -244.1398</td> <td>  328.669</td> <td>   -0.743</td> <td> 0.458</td> <td> -888.440</td> <td>  400.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x35</th>  <td> -139.9712</td> <td>  245.171</td> <td>   -0.571</td> <td> 0.568</td> <td> -620.586</td> <td>  340.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x36</th>  <td>   37.5070</td> <td>  266.483</td> <td>    0.141</td> <td> 0.888</td> <td> -484.888</td> <td>  559.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x37</th>  <td>  457.3197</td> <td>  327.970</td> <td>    1.394</td> <td> 0.163</td> <td> -185.610</td> <td> 1100.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x38</th>  <td>  313.7290</td> <td>  234.356</td> <td>    1.339</td> <td> 0.181</td> <td> -145.686</td> <td>  773.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x11</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x12</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x13</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x14</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x15</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x16</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x23</th> <td>  341.3716</td> <td>  236.968</td> <td>    1.441</td> <td> 0.150</td> <td> -123.163</td> <td>  805.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x24</th> <td>  818.8950</td> <td>  342.560</td> <td>    2.391</td> <td> 0.017</td> <td>  147.365</td> <td> 1490.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x25</th> <td>-1603.2770</td> <td>  438.575</td> <td>   -3.656</td> <td> 0.000</td> <td>-2463.029</td> <td> -743.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x26</th> <td>  930.6231</td> <td>  366.283</td> <td>    2.541</td> <td> 0.011</td> <td>  212.587</td> <td> 1648.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x27</th> <td> -177.6196</td> <td>  361.374</td> <td>   -0.492</td> <td> 0.623</td> <td> -886.031</td> <td>  530.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x28</th> <td> -538.9796</td> <td>  395.065</td> <td>   -1.364</td> <td> 0.173</td> <td>-1313.438</td> <td>  235.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x29</th> <td> -817.1112</td> <td>  439.663</td> <td>   -1.858</td> <td> 0.063</td> <td>-1678.997</td> <td>   44.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x30</th> <td>  543.2138</td> <td>  422.288</td> <td>    1.286</td> <td> 0.198</td> <td> -284.609</td> <td> 1371.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x31</th> <td> -657.9775</td> <td>  559.462</td> <td>   -1.176</td> <td> 0.240</td> <td>-1754.708</td> <td>  438.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x32</th> <td> -198.8598</td> <td>  275.949</td> <td>   -0.721</td> <td> 0.471</td> <td> -739.811</td> <td>  342.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x33</th> <td> -603.2474</td> <td>  192.634</td> <td>   -3.132</td> <td> 0.002</td> <td> -980.873</td> <td> -225.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x34</th> <td> -314.8221</td> <td>  331.053</td> <td>   -0.951</td> <td> 0.342</td> <td> -963.795</td> <td>  334.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x35</th> <td> -173.3855</td> <td>  247.498</td> <td>   -0.701</td> <td> 0.484</td> <td> -658.563</td> <td>  311.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x36</th> <td>  -27.1443</td> <td>  270.001</td> <td>   -0.101</td> <td> 0.920</td> <td> -556.435</td> <td>  502.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x37</th> <td>  519.6716</td> <td>  331.709</td> <td>    1.567</td> <td> 0.117</td> <td> -130.587</td> <td> 1169.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x38</th> <td>  341.3716</td> <td>  236.968</td> <td>    1.441</td> <td> 0.150</td> <td> -123.163</td> <td>  805.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x12</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x13</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x14</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x15</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x16</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x23</th> <td>  342.4753</td> <td>  237.011</td> <td>    1.445</td> <td> 0.149</td> <td> -122.145</td> <td>  807.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x24</th> <td>  807.2273</td> <td>  342.472</td> <td>    2.357</td> <td> 0.018</td> <td>  135.869</td> <td> 1478.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x25</th> <td>-1280.1717</td> <td>  436.794</td> <td>   -2.931</td> <td> 0.003</td> <td>-2136.431</td> <td> -423.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x26</th> <td>  681.5827</td> <td>  365.599</td> <td>    1.864</td> <td> 0.062</td> <td>  -35.112</td> <td> 1398.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x27</th> <td> -384.4082</td> <td>  362.386</td> <td>   -1.061</td> <td> 0.289</td> <td>-1094.805</td> <td>  325.989</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x28</th> <td> -548.1579</td> <td>  395.432</td> <td>   -1.386</td> <td> 0.166</td> <td>-1323.336</td> <td>  227.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x29</th> <td> -845.8099</td> <td>  437.956</td> <td>   -1.931</td> <td> 0.053</td> <td>-1704.347</td> <td>   12.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x30</th> <td>  741.8920</td> <td>  419.933</td> <td>    1.767</td> <td> 0.077</td> <td>  -81.316</td> <td> 1565.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x31</th> <td> -590.3124</td> <td>  559.712</td> <td>   -1.055</td> <td> 0.292</td> <td>-1687.534</td> <td>  506.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x32</th> <td> -218.3302</td> <td>  275.872</td> <td>   -0.791</td> <td> 0.429</td> <td> -759.131</td> <td>  322.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x33</th> <td> -572.5347</td> <td>  192.224</td> <td>   -2.978</td> <td> 0.003</td> <td> -949.356</td> <td> -195.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x34</th> <td> -286.4198</td> <td>  331.106</td> <td>   -0.865</td> <td> 0.387</td> <td> -935.497</td> <td>  362.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x35</th> <td> -190.6740</td> <td>  247.240</td> <td>   -0.771</td> <td> 0.441</td> <td> -675.346</td> <td>  293.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x36</th> <td>   17.9643</td> <td>  269.122</td> <td>    0.067</td> <td> 0.947</td> <td> -509.603</td> <td>  545.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x37</th> <td>  501.7327</td> <td>  330.962</td> <td>    1.516</td> <td> 0.130</td> <td> -147.062</td> <td> 1150.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x38</th> <td>  342.4753</td> <td>  237.011</td> <td>    1.445</td> <td> 0.149</td> <td> -122.145</td> <td>  807.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x13</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x14</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x15</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x16</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x23</th> <td>  383.2502</td> <td>  239.028</td> <td>    1.603</td> <td> 0.109</td> <td>  -85.323</td> <td>  851.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x24</th> <td>  827.0959</td> <td>  343.547</td> <td>    2.408</td> <td> 0.016</td> <td>  153.630</td> <td> 1500.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x25</th> <td>-1412.6437</td> <td>  440.633</td> <td>   -3.206</td> <td> 0.001</td> <td>-2276.429</td> <td> -548.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x26</th> <td>  641.8454</td> <td>  367.618</td> <td>    1.746</td> <td> 0.081</td> <td>  -78.807</td> <td> 1362.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x27</th> <td> -333.7367</td> <td>  365.742</td> <td>   -0.912</td> <td> 0.362</td> <td>-1050.711</td> <td>  383.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x28</th> <td> -618.6952</td> <td>  399.974</td> <td>   -1.547</td> <td> 0.122</td> <td>-1402.777</td> <td>  165.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x29</th> <td> -796.7613</td> <td>  440.483</td> <td>   -1.809</td> <td> 0.071</td> <td>-1660.252</td> <td>   66.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x30</th> <td>  841.1081</td> <td>  425.612</td> <td>    1.976</td> <td> 0.048</td> <td>    6.768</td> <td> 1675.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x31</th> <td> -688.5451</td> <td>  564.289</td> <td>   -1.220</td> <td> 0.222</td> <td>-1794.738</td> <td>  417.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x32</th> <td> -237.7979</td> <td>  276.847</td> <td>   -0.859</td> <td> 0.390</td> <td> -780.509</td> <td>  304.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x33</th> <td> -572.8046</td> <td>  193.493</td> <td>   -2.960</td> <td> 0.003</td> <td> -952.114</td> <td> -193.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x34</th> <td> -274.9603</td> <td>  332.332</td> <td>   -0.827</td> <td> 0.408</td> <td> -926.441</td> <td>  376.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x35</th> <td> -111.3238</td> <td>  249.324</td> <td>   -0.447</td> <td> 0.655</td> <td> -600.082</td> <td>  377.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x36</th> <td>  -55.0263</td> <td>  269.806</td> <td>   -0.204</td> <td> 0.838</td> <td> -583.934</td> <td>  473.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x37</th> <td>  485.0307</td> <td>  332.479</td> <td>    1.459</td> <td> 0.145</td> <td> -166.738</td> <td> 1136.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x38</th> <td>  383.2502</td> <td>  239.028</td> <td>    1.603</td> <td> 0.109</td> <td>  -85.323</td> <td>  851.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x14</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x15</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x16</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x23</th> <td>  366.0434</td> <td>  239.708</td> <td>    1.527</td> <td> 0.127</td> <td> -103.862</td> <td>  835.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x24</th> <td>  756.7745</td> <td>  344.210</td> <td>    2.199</td> <td> 0.028</td> <td>   82.010</td> <td> 1431.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x25</th> <td>-1180.0175</td> <td>  441.775</td> <td>   -2.671</td> <td> 0.008</td> <td>-2046.043</td> <td> -313.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x26</th> <td>  752.7183</td> <td>  370.402</td> <td>    2.032</td> <td> 0.042</td> <td>   26.608</td> <td> 1478.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x27</th> <td> -427.9046</td> <td>  366.640</td> <td>   -1.167</td> <td> 0.243</td> <td>-1146.639</td> <td>  290.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x28</th> <td> -472.1082</td> <td>  399.358</td> <td>   -1.182</td> <td> 0.237</td> <td>-1254.982</td> <td>  310.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x29</th> <td> -793.5539</td> <td>  440.071</td> <td>   -1.803</td> <td> 0.071</td> <td>-1656.239</td> <td>   69.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x30</th> <td>  593.2777</td> <td>  424.772</td> <td>    1.397</td> <td> 0.163</td> <td> -239.416</td> <td> 1425.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x31</th> <td> -661.1949</td> <td>  565.727</td> <td>   -1.169</td> <td> 0.243</td> <td>-1770.206</td> <td>  447.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x32</th> <td> -214.8176</td> <td>  277.956</td> <td>   -0.773</td> <td> 0.440</td> <td> -759.703</td> <td>  330.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x33</th> <td> -525.4062</td> <td>  194.111</td> <td>   -2.707</td> <td> 0.007</td> <td> -905.929</td> <td> -144.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x34</th> <td> -331.9309</td> <td>  333.889</td> <td>   -0.994</td> <td> 0.320</td> <td> -986.464</td> <td>  322.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x35</th> <td> -306.7352</td> <td>  249.837</td> <td>   -1.228</td> <td> 0.220</td> <td> -796.498</td> <td>  183.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x36</th> <td>   22.7402</td> <td>  271.826</td> <td>    0.084</td> <td> 0.933</td> <td> -510.129</td> <td>  555.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x37</th> <td>  421.3210</td> <td>  334.577</td> <td>    1.259</td> <td> 0.208</td> <td> -234.561</td> <td> 1077.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x38</th> <td>  366.0434</td> <td>  239.708</td> <td>    1.527</td> <td> 0.127</td> <td> -103.862</td> <td>  835.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x15</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x16</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x23</th> <td>  408.8971</td> <td>  238.358</td> <td>    1.715</td> <td> 0.086</td> <td>  -58.363</td> <td>  876.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x24</th> <td>  789.4937</td> <td>  345.100</td> <td>    2.288</td> <td> 0.022</td> <td>  112.984</td> <td> 1466.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x25</th> <td>-1214.3040</td> <td>  443.066</td> <td>   -2.741</td> <td> 0.006</td> <td>-2082.860</td> <td> -345.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x26</th> <td>  553.1497</td> <td>  369.093</td> <td>    1.499</td> <td> 0.134</td> <td> -170.394</td> <td> 1276.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x27</th> <td> -406.1475</td> <td>  366.400</td> <td>   -1.108</td> <td> 0.268</td> <td>-1124.413</td> <td>  312.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x28</th> <td> -613.7194</td> <td>  398.527</td> <td>   -1.540</td> <td> 0.124</td> <td>-1394.964</td> <td>  167.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x29</th> <td> -850.8059</td> <td>  438.922</td> <td>   -1.938</td> <td> 0.053</td> <td>-1711.239</td> <td>    9.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x30</th> <td>  904.2289</td> <td>  423.906</td> <td>    2.133</td> <td> 0.033</td> <td>   73.234</td> <td> 1735.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x31</th> <td> -636.5693</td> <td>  567.824</td> <td>   -1.121</td> <td> 0.262</td> <td>-1749.692</td> <td>  476.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x32</th> <td> -234.8189</td> <td>  279.005</td> <td>   -0.842</td> <td> 0.400</td> <td> -781.762</td> <td>  312.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x33</th> <td> -538.4532</td> <td>  194.382</td> <td>   -2.770</td> <td> 0.006</td> <td> -919.506</td> <td> -157.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x34</th> <td> -288.9844</td> <td>  335.145</td> <td>   -0.862</td> <td> 0.389</td> <td> -945.980</td> <td>  368.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x35</th> <td> -115.6380</td> <td>  249.499</td> <td>   -0.463</td> <td> 0.643</td> <td> -604.738</td> <td>  373.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x36</th> <td>   12.7014</td> <td>  272.618</td> <td>    0.047</td> <td> 0.963</td> <td> -521.720</td> <td>  547.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x37</th> <td>  445.4291</td> <td>  334.742</td> <td>    1.331</td> <td> 0.183</td> <td> -210.776</td> <td> 1101.635</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x38</th> <td>  408.8971</td> <td>  238.358</td> <td>    1.715</td> <td> 0.086</td> <td>  -58.363</td> <td>  876.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x16</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x23</th> <td>  334.8764</td> <td>  241.791</td> <td>    1.385</td> <td> 0.166</td> <td> -139.114</td> <td>  808.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x24</th> <td>  633.3754</td> <td>  345.917</td> <td>    1.831</td> <td> 0.067</td> <td>  -44.737</td> <td> 1311.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x25</th> <td>-1222.9016</td> <td>  449.165</td> <td>   -2.723</td> <td> 0.006</td> <td>-2103.414</td> <td> -342.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x26</th> <td>  690.7526</td> <td>  374.352</td> <td>    1.845</td> <td> 0.065</td> <td>  -43.100</td> <td> 1424.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x27</th> <td> -138.5387</td> <td>  369.378</td> <td>   -0.375</td> <td> 0.708</td> <td> -862.641</td> <td>  585.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x28</th> <td> -569.9463</td> <td>  403.366</td> <td>   -1.413</td> <td> 0.158</td> <td>-1360.676</td> <td>  220.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x29</th> <td> -702.3306</td> <td>  448.524</td> <td>   -1.566</td> <td> 0.117</td> <td>-1581.585</td> <td>  176.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x30</th> <td>  563.9244</td> <td>  428.483</td> <td>    1.316</td> <td> 0.188</td> <td> -276.043</td> <td> 1403.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x31</th> <td> -493.7240</td> <td>  567.899</td> <td>   -0.869</td> <td> 0.385</td> <td>-1606.993</td> <td>  619.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x32</th> <td> -176.4475</td> <td>  279.575</td> <td>   -0.631</td> <td> 0.528</td> <td> -724.506</td> <td>  371.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x33</th> <td> -443.3629</td> <td>  196.091</td> <td>   -2.261</td> <td> 0.024</td> <td> -827.767</td> <td>  -58.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x34</th> <td> -227.8028</td> <td>  335.921</td> <td>   -0.678</td> <td> 0.498</td> <td> -886.319</td> <td>  430.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x35</th> <td> -144.5605</td> <td>  252.466</td> <td>   -0.573</td> <td> 0.567</td> <td> -639.477</td> <td>  350.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x36</th> <td>  -43.3342</td> <td>  275.555</td> <td>   -0.157</td> <td> 0.875</td> <td> -583.514</td> <td>  496.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x37</th> <td>  424.3533</td> <td>  337.790</td> <td>    1.256</td> <td> 0.209</td> <td> -237.827</td> <td> 1086.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x38</th> <td>  334.8764</td> <td>  241.791</td> <td>    1.385</td> <td> 0.166</td> <td> -139.114</td> <td>  808.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x17</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x23</th> <td>  338.7732</td> <td>  242.588</td> <td>    1.396</td> <td> 0.163</td> <td> -136.780</td> <td>  814.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x24</th> <td>  917.0770</td> <td>  350.062</td> <td>    2.620</td> <td> 0.009</td> <td>  230.839</td> <td> 1603.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x25</th> <td>-1505.3008</td> <td>  450.907</td> <td>   -3.338</td> <td> 0.001</td> <td>-2389.226</td> <td> -621.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x26</th> <td>  754.3447</td> <td>  377.274</td> <td>    1.999</td> <td> 0.046</td> <td>   14.764</td> <td> 1493.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x27</th> <td> -276.1056</td> <td>  374.014</td> <td>   -0.738</td> <td> 0.460</td> <td>-1009.296</td> <td>  457.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x28</th> <td> -593.1253</td> <td>  412.222</td> <td>   -1.439</td> <td> 0.150</td> <td>-1401.217</td> <td>  214.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x29</th> <td> -771.4892</td> <td>  444.656</td> <td>   -1.735</td> <td> 0.083</td> <td>-1643.161</td> <td>  100.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x30</th> <td>  663.5577</td> <td>  435.127</td> <td>    1.525</td> <td> 0.127</td> <td> -189.435</td> <td> 1516.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x31</th> <td> -680.2514</td> <td>  569.186</td> <td>   -1.195</td> <td> 0.232</td> <td>-1796.044</td> <td>  435.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x32</th> <td> -288.1903</td> <td>  282.309</td> <td>   -1.021</td> <td> 0.307</td> <td> -841.610</td> <td>  265.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x33</th> <td> -611.8798</td> <td>  198.207</td> <td>   -3.087</td> <td> 0.002</td> <td>-1000.431</td> <td> -223.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x34</th> <td> -195.8904</td> <td>  338.227</td> <td>   -0.579</td> <td> 0.562</td> <td> -858.926</td> <td>  467.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x35</th> <td> -205.6731</td> <td>  255.649</td> <td>   -0.805</td> <td> 0.421</td> <td> -706.829</td> <td>  295.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x36</th> <td>  -39.5522</td> <td>  276.470</td> <td>   -0.143</td> <td> 0.886</td> <td> -581.525</td> <td>  502.421</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x37</th> <td>  489.2752</td> <td>  337.112</td> <td>    1.451</td> <td> 0.147</td> <td> -171.575</td> <td> 1150.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x38</th> <td>  338.7732</td> <td>  242.588</td> <td>    1.396</td> <td> 0.163</td> <td> -136.780</td> <td>  814.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x18</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x23</th> <td>  301.1147</td> <td>  246.287</td> <td>    1.223</td> <td> 0.222</td> <td> -181.690</td> <td>  783.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x24</th> <td>  913.6741</td> <td>  349.067</td> <td>    2.617</td> <td> 0.009</td> <td>  229.388</td> <td> 1597.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x25</th> <td>-1547.7726</td> <td>  452.411</td> <td>   -3.421</td> <td> 0.001</td> <td>-2434.647</td> <td> -660.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x26</th> <td>  739.1453</td> <td>  374.883</td> <td>    1.972</td> <td> 0.049</td> <td>    4.250</td> <td> 1474.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x27</th> <td> -310.3582</td> <td>  372.550</td> <td>   -0.833</td> <td> 0.405</td> <td>-1040.679</td> <td>  419.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x28</th> <td> -513.4702</td> <td>  404.103</td> <td>   -1.271</td> <td> 0.204</td> <td>-1305.645</td> <td>  278.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x29</th> <td> -713.0296</td> <td>  448.575</td> <td>   -1.590</td> <td> 0.112</td> <td>-1592.384</td> <td>  166.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x30</th> <td>  675.7948</td> <td>  429.110</td> <td>    1.575</td> <td> 0.115</td> <td> -165.402</td> <td> 1516.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x31</th> <td> -743.1725</td> <td>  570.800</td> <td>   -1.302</td> <td> 0.193</td> <td>-1862.128</td> <td>  375.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x32</th> <td> -253.6175</td> <td>  282.269</td> <td>   -0.898</td> <td> 0.369</td> <td> -806.959</td> <td>  299.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x33</th> <td> -643.4673</td> <td>  197.977</td> <td>   -3.250</td> <td> 0.001</td> <td>-1031.567</td> <td> -255.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x34</th> <td> -241.4132</td> <td>  338.955</td> <td>   -0.712</td> <td> 0.476</td> <td> -905.877</td> <td>  423.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x35</th> <td> -148.0336</td> <td>  253.381</td> <td>   -0.584</td> <td> 0.559</td> <td> -644.745</td> <td>  348.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x36</th> <td>  -42.9867</td> <td>  279.431</td> <td>   -0.154</td> <td> 0.878</td> <td> -590.763</td> <td>  504.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x37</th> <td>  471.4909</td> <td>  341.096</td> <td>    1.382</td> <td> 0.167</td> <td> -197.170</td> <td> 1140.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x38</th> <td>  301.1147</td> <td>  246.287</td> <td>    1.223</td> <td> 0.222</td> <td> -181.690</td> <td>  783.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x19</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x23</th> <td>  183.4778</td> <td>  251.702</td> <td>    0.729</td> <td> 0.466</td> <td> -309.942</td> <td>  676.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x24</th> <td>  619.4883</td> <td>  359.441</td> <td>    1.723</td> <td> 0.085</td> <td>  -85.134</td> <td> 1324.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x25</th> <td>-1204.0176</td> <td>  468.315</td> <td>   -2.571</td> <td> 0.010</td> <td>-2122.069</td> <td> -285.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x26</th> <td>  823.0020</td> <td>  394.686</td> <td>    2.085</td> <td> 0.037</td> <td>   49.286</td> <td> 1596.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x27</th> <td> -182.7354</td> <td>  388.636</td> <td>   -0.470</td> <td> 0.638</td> <td> -944.590</td> <td>  579.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x28</th> <td> -488.5731</td> <td>  421.549</td> <td>   -1.159</td> <td> 0.247</td> <td>-1314.948</td> <td>  337.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x29</th> <td> -627.6303</td> <td>  457.556</td> <td>   -1.372</td> <td> 0.170</td> <td>-1524.592</td> <td>  269.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x30</th> <td>  461.6023</td> <td>  449.748</td> <td>    1.026</td> <td> 0.305</td> <td> -420.052</td> <td> 1343.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x31</th> <td> -470.5813</td> <td>  583.151</td> <td>   -0.807</td> <td> 0.420</td> <td>-1613.750</td> <td>  672.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x32</th> <td> -118.7026</td> <td>  291.360</td> <td>   -0.407</td> <td> 0.684</td> <td> -689.863</td> <td>  452.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x33</th> <td> -488.4481</td> <td>  205.013</td> <td>   -2.383</td> <td> 0.017</td> <td> -890.341</td> <td>  -86.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x34</th> <td> -295.2455</td> <td>  349.013</td> <td>   -0.846</td> <td> 0.398</td> <td> -979.427</td> <td>  388.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x35</th> <td> -209.7063</td> <td>  264.863</td> <td>   -0.792</td> <td> 0.429</td> <td> -728.925</td> <td>  309.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x36</th> <td>   28.7665</td> <td>  288.728</td> <td>    0.100</td> <td> 0.921</td> <td> -537.236</td> <td>  594.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x37</th> <td>  427.7237</td> <td>  350.345</td> <td>    1.221</td> <td> 0.222</td> <td> -259.068</td> <td> 1114.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x38</th> <td>  183.4778</td> <td>  251.702</td> <td>    0.729</td> <td> 0.466</td> <td> -309.942</td> <td>  676.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x20</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x23</th> <td>  249.8106</td> <td>  256.537</td> <td>    0.974</td> <td> 0.330</td> <td> -253.086</td> <td>  752.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x24</th> <td> 1043.0448</td> <td>  367.159</td> <td>    2.841</td> <td> 0.005</td> <td>  323.293</td> <td> 1762.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x25</th> <td>-1319.0629</td> <td>  489.401</td> <td>   -2.695</td> <td> 0.007</td> <td>-2278.451</td> <td> -359.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x26</th> <td>  614.6036</td> <td>  391.791</td> <td>    1.569</td> <td> 0.117</td> <td> -153.436</td> <td> 1382.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x27</th> <td> -424.1569</td> <td>  406.933</td> <td>   -1.042</td> <td> 0.297</td> <td>-1221.881</td> <td>  373.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x28</th> <td> -635.2968</td> <td>  430.149</td> <td>   -1.477</td> <td> 0.140</td> <td>-1478.531</td> <td>  207.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x29</th> <td> -874.1726</td> <td>  467.689</td> <td>   -1.869</td> <td> 0.062</td> <td>-1790.997</td> <td>   42.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x30</th> <td>  870.1385</td> <td>  452.384</td> <td>    1.923</td> <td> 0.054</td> <td>  -16.683</td> <td> 1756.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x31</th> <td> -624.7497</td> <td>  605.390</td> <td>   -1.032</td> <td> 0.302</td> <td>-1811.514</td> <td>  562.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x32</th> <td> -399.6663</td> <td>  303.403</td> <td>   -1.317</td> <td> 0.188</td> <td> -994.436</td> <td>  195.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x33</th> <td> -626.2723</td> <td>  213.049</td> <td>   -2.940</td> <td> 0.003</td> <td>-1043.919</td> <td> -208.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x34</th> <td> -206.0668</td> <td>  365.698</td> <td>   -0.563</td> <td> 0.573</td> <td> -922.956</td> <td>  510.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x35</th> <td> -189.3152</td> <td>  269.190</td> <td>   -0.703</td> <td> 0.482</td> <td> -717.016</td> <td>  338.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x36</th> <td>  149.2703</td> <td>  309.207</td> <td>    0.483</td> <td> 0.629</td> <td> -456.878</td> <td>  755.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x37</th> <td>  492.1978</td> <td>  372.324</td> <td>    1.322</td> <td> 0.186</td> <td> -237.680</td> <td> 1222.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x38</th> <td>  249.8106</td> <td>  256.537</td> <td>    0.974</td> <td> 0.330</td> <td> -253.086</td> <td>  752.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x21</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x23</th> <td>  203.5391</td> <td>  273.015</td> <td>    0.746</td> <td> 0.456</td> <td> -331.661</td> <td>  738.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x24</th> <td>  853.6468</td> <td>  368.503</td> <td>    2.317</td> <td> 0.021</td> <td>  131.258</td> <td> 1576.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x25</th> <td>-1729.1695</td> <td>  491.340</td> <td>   -3.519</td> <td> 0.000</td> <td>-2692.357</td> <td> -765.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x26</th> <td> 1117.6105</td> <td>  411.500</td> <td>    2.716</td> <td> 0.007</td> <td>  310.935</td> <td> 1924.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x27</th> <td>    1.8612</td> <td>  407.558</td> <td>    0.005</td> <td> 0.996</td> <td> -797.086</td> <td>  800.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x28</th> <td> -660.7723</td> <td>  433.789</td> <td>   -1.523</td> <td> 0.128</td> <td>-1511.141</td> <td>  189.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x29</th> <td> -753.7424</td> <td>  470.292</td> <td>   -1.603</td> <td> 0.109</td> <td>-1675.670</td> <td>  168.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x30</th> <td>  512.8443</td> <td>  468.786</td> <td>    1.094</td> <td> 0.274</td> <td> -406.131</td> <td> 1431.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x31</th> <td> -589.1986</td> <td>  613.197</td> <td>   -0.961</td> <td> 0.337</td> <td>-1791.267</td> <td>  612.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x32</th> <td> -169.7193</td> <td>  299.062</td> <td>   -0.568</td> <td> 0.570</td> <td> -755.980</td> <td>  416.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x33</th> <td> -669.2872</td> <td>  213.337</td> <td>   -3.137</td> <td> 0.002</td> <td>-1087.498</td> <td> -251.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x34</th> <td> -285.7551</td> <td>  357.907</td> <td>   -0.798</td> <td> 0.425</td> <td> -987.371</td> <td>  415.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x35</th> <td> -146.0667</td> <td>  275.984</td> <td>   -0.529</td> <td> 0.597</td> <td> -687.087</td> <td>  394.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x36</th> <td>   96.0211</td> <td>  295.660</td> <td>    0.325</td> <td> 0.745</td> <td> -483.569</td> <td>  675.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x37</th> <td>  468.8223</td> <td>  361.698</td> <td>    1.296</td> <td> 0.195</td> <td> -240.225</td> <td> 1177.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x38</th> <td>  203.5391</td> <td>  273.015</td> <td>    0.746</td> <td> 0.456</td> <td> -331.661</td> <td>  738.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x23</th> <td>  342.6487</td> <td>  284.955</td> <td>    1.202</td> <td> 0.229</td> <td> -215.956</td> <td>  901.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x24</th> <td>  767.1216</td> <td>  377.660</td> <td>    2.031</td> <td> 0.042</td> <td>   26.783</td> <td> 1507.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x25</th> <td>-1505.3526</td> <td>  542.388</td> <td>   -2.775</td> <td> 0.006</td> <td>-2568.611</td> <td> -442.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x26</th> <td>  877.5553</td> <td>  410.451</td> <td>    2.138</td> <td> 0.033</td> <td>   72.936</td> <td> 1682.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x27</th> <td>  105.0241</td> <td>  436.030</td> <td>    0.241</td> <td> 0.810</td> <td> -749.739</td> <td>  959.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x28</th> <td> -669.3362</td> <td>  453.195</td> <td>   -1.477</td> <td> 0.140</td> <td>-1557.748</td> <td>  219.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x29</th> <td> -928.0325</td> <td>  492.100</td> <td>   -1.886</td> <td> 0.059</td> <td>-1892.711</td> <td>   36.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x30</th> <td>  582.8877</td> <td>  477.482</td> <td>    1.221</td> <td> 0.222</td> <td> -353.135</td> <td> 1518.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x31</th> <td> -433.9746</td> <td>  735.830</td> <td>   -0.590</td> <td> 0.555</td> <td>-1876.445</td> <td> 1008.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x32</th> <td> -228.2516</td> <td>  334.104</td> <td>   -0.683</td> <td> 0.495</td> <td> -883.206</td> <td>  426.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x33</th> <td> -524.4026</td> <td>  229.473</td> <td>   -2.285</td> <td> 0.022</td> <td> -974.245</td> <td>  -74.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x34</th> <td> -252.2368</td> <td>  418.562</td> <td>   -0.603</td> <td> 0.547</td> <td>-1072.756</td> <td>  568.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x35</th> <td>   18.5756</td> <td>  280.360</td> <td>    0.066</td> <td> 0.947</td> <td> -531.023</td> <td>  568.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x36</th> <td>  157.8998</td> <td>  351.159</td> <td>    0.450</td> <td> 0.653</td> <td> -530.488</td> <td>  846.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x37</th> <td>  441.9513</td> <td>  430.434</td> <td>    1.027</td> <td> 0.305</td> <td> -401.842</td> <td> 1285.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x38</th> <td>  342.6487</td> <td>  284.955</td> <td>    1.202</td> <td> 0.229</td> <td> -215.956</td> <td>  901.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x23</th> <td>  577.5348</td> <td>  283.619</td> <td>    2.036</td> <td> 0.042</td> <td>   21.548</td> <td> 1133.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x24</th> <td>  704.8307</td> <td>  381.323</td> <td>    1.848</td> <td> 0.065</td> <td>  -42.688</td> <td> 1452.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x25</th> <td>-2020.1988</td> <td>  540.384</td> <td>   -3.738</td> <td> 0.000</td> <td>-3079.530</td> <td> -960.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x26</th> <td> 1324.2792</td> <td>  419.305</td> <td>    3.158</td> <td> 0.002</td> <td>  502.304</td> <td> 2146.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x27</th> <td>  541.7313</td> <td>  433.746</td> <td>    1.249</td> <td> 0.212</td> <td> -308.554</td> <td> 1392.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x28</th> <td> -792.5134</td> <td>  472.139</td> <td>   -1.679</td> <td> 0.093</td> <td>-1718.061</td> <td>  133.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x29</th> <td> -461.5687</td> <td>  496.134</td> <td>   -0.930</td> <td> 0.352</td> <td>-1434.155</td> <td>  511.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x30</th> <td>   39.5505</td> <td>  488.549</td> <td>    0.081</td> <td> 0.935</td> <td> -918.167</td> <td>  997.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x31</th> <td> -905.7425</td> <td>  622.168</td> <td>   -1.456</td> <td> 0.146</td> <td>-2125.396</td> <td>  313.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x32</th> <td> -218.4600</td> <td>  309.544</td> <td>   -0.706</td> <td> 0.480</td> <td> -825.269</td> <td>  388.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x33</th> <td> -471.5323</td> <td>  225.417</td> <td>   -2.092</td> <td> 0.036</td> <td> -913.423</td> <td>  -29.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x34</th> <td>  -84.9457</td> <td>  373.184</td> <td>   -0.228</td> <td> 0.820</td> <td> -816.510</td> <td>  646.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x35</th> <td> -211.2316</td> <td>  288.714</td> <td>   -0.732</td> <td> 0.464</td> <td> -777.207</td> <td>  354.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x36</th> <td> -202.3205</td> <td>  320.192</td> <td>   -0.632</td> <td> 0.527</td> <td> -830.003</td> <td>  425.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x37</th> <td>  101.1927</td> <td>  385.567</td> <td>    0.262</td> <td> 0.793</td> <td> -654.646</td> <td>  857.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x38</th> <td>  577.5348</td> <td>  283.619</td> <td>    2.036</td> <td> 0.042</td> <td>   21.548</td> <td> 1133.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x24</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x25</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x26</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x32</th> <td>-2.761e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x34</th> <td>-2.761e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x36</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x38</th> <td>-2.761e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x25</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x26</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x32</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x34</th> <td>   -0.0002</td> <td>    0.000</td> <td>   -1.965</td> <td> 0.050</td> <td>   -0.000</td> <td>-4.43e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x36</th> <td>   -0.0002</td> <td>    0.000</td> <td>   -1.965</td> <td> 0.050</td> <td>   -0.000</td> <td>-4.43e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x26</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x32</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x33</th> <td>    0.0005</td> <td>    0.000</td> <td>    3.687</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x36</th> <td>    0.0005</td> <td>    0.000</td> <td>    3.687</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x32</th> <td>   -0.0002</td> <td>    0.000</td> <td>   -1.255</td> <td> 0.210</td> <td>   -0.000</td> <td> 8.85e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x36</th> <td>   -0.0002</td> <td>    0.000</td> <td>   -1.255</td> <td> 0.210</td> <td>   -0.000</td> <td> 8.85e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x32</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x33</th> <td> 7.987e-05</td> <td>    0.000</td> <td>    0.674</td> <td> 0.500</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x35</th> <td> 7.987e-05</td> <td>    0.000</td> <td>    0.674</td> <td> 0.500</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x36</th> <td> 7.987e-05</td> <td>    0.000</td> <td>    0.674</td> <td> 0.500</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x32</th> <td>-2.744e-05</td> <td>    0.000</td> <td>   -0.219</td> <td> 0.826</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x35</th> <td>-2.744e-05</td> <td>    0.000</td> <td>   -0.219</td> <td> 0.826</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x36</th> <td>-2.744e-05</td> <td>    0.000</td> <td>   -0.219</td> <td> 0.826</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x32</th> <td> 9.152e-05</td> <td>    0.000</td> <td>    0.602</td> <td> 0.547</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x34</th> <td> 9.152e-05</td> <td>    0.000</td> <td>    0.602</td> <td> 0.547</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x36</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x32</th> <td>   -0.0001</td> <td>    0.000</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x35</th> <td>   -0.0001</td> <td>    0.000</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x36</th> <td>   -0.0001</td> <td>    0.000</td> <td>   -0.837</td> <td> 0.403</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x32</th> <td>    0.0002</td> <td>    0.000</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x34</th> <td>    0.0002</td> <td>    0.000</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x36</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x37</th> <td>    0.0002</td> <td>    0.000</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x34</th> <td>    0.0003</td> <td>    0.000</td> <td>    2.072</td> <td> 0.038</td> <td> 1.52e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x35</th> <td>   -0.0001</td> <td>    0.000</td> <td>   -1.166</td> <td> 0.244</td> <td>   -0.000</td> <td> 9.32e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x36</th> <td>   -0.0003</td> <td>    0.000</td> <td>   -2.521</td> <td> 0.012</td> <td>   -0.001</td> <td>-6.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x37</th> <td>    0.0002</td> <td>    0.000</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x38</th> <td>-2.761e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x35</th> <td> 7.987e-05</td> <td>    0.000</td> <td>    0.674</td> <td> 0.500</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x36</th> <td>    0.0006</td> <td>    0.000</td> <td>    3.351</td> <td> 0.001</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x37</th> <td>   -0.0004</td> <td>    0.000</td> <td>   -1.666</td> <td> 0.096</td> <td>   -0.001</td> <td> 6.55e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34 x36</th> <td>   -0.0002</td> <td>    0.000</td> <td>   -1.965</td> <td> 0.050</td> <td>   -0.000</td> <td>-4.43e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34 x37</th> <td>    0.0002</td> <td>    0.000</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34 x38</th> <td>-2.761e-05</td> <td> 7.67e-05</td> <td>   -0.360</td> <td> 0.719</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35 x36</th> <td>-5.693e-05</td> <td>  7.4e-05</td> <td>   -0.769</td> <td> 0.442</td> <td>   -0.000</td> <td> 8.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>621.905</td> <th>  Durbin-Watson:     </th> <td>   1.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2206.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.428</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.652</td>  <th>  Cond. No.          </th> <td>8.56e+20</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.88e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.628\n",
       "Model:                            OLS   Adj. R-squared:                  0.609\n",
       "Method:                 Least Squares   F-statistic:                     32.61\n",
       "Date:                Fri, 29 May 2020   Prob (F-statistic):               0.00\n",
       "Time:                        13:19:01   Log-Likelihood:                -56988.\n",
       "No. Observations:                6818   AIC:                         1.146e+05\n",
       "Df Residuals:                    6481   BIC:                         1.170e+05\n",
       "Df Model:                         336                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0002      0.000      0.426      0.670      -0.001       0.001\n",
       "x0            -0.0102      0.046     -0.220      0.826      -0.101       0.081\n",
       "x1            -1.9517      8.470     -0.230      0.818     -18.556      14.652\n",
       "x2            -0.0018      0.007     -0.244      0.807      -0.016       0.012\n",
       "x3             0.0124      0.472      0.026      0.979      -0.912       0.937\n",
       "x4            -0.2229      4.120     -0.054      0.957      -8.299       7.853\n",
       "x5            -0.4894      4.176     -0.117      0.907      -8.677       7.698\n",
       "x6            -2.1798      4.691     -0.465      0.642     -11.377       7.017\n",
       "x7            -5.1187      6.515     -0.786      0.432     -17.890       7.653\n",
       "x8            17.0606      6.179      2.761      0.006       4.948      29.173\n",
       "x9            15.6961      6.179      2.540      0.011       3.583      27.809\n",
       "x10           16.7878      6.238      2.691      0.007       4.558      29.017\n",
       "x11           16.3624      6.228      2.627      0.009       4.153      28.571\n",
       "x12           16.4933      6.253      2.638      0.008       4.235      28.752\n",
       "x13           16.5507      6.271      2.639      0.008       4.258      28.844\n",
       "x14           16.2217      6.281      2.583      0.010       3.910      28.534\n",
       "x15           13.5650      6.341      2.139      0.032       1.135      25.995\n",
       "x16           17.0070      6.353      2.677      0.007       4.553      29.461\n",
       "x17           16.5893      6.398      2.593      0.010       4.047      29.132\n",
       "x18           12.3376      6.558      1.881      0.060      -0.518      25.193\n",
       "x19           17.1061      6.893      2.482      0.013       3.594      30.618\n",
       "x20           14.6402      6.742      2.171      0.030       1.423      27.857\n",
       "x21           14.4674      7.547      1.917      0.055      -0.328      29.263\n",
       "x22           14.8383      7.103      2.089      0.037       0.915      28.762\n",
       "x23        -2.761e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x24           -0.0002      0.000     -1.965      0.050      -0.000   -4.46e-07\n",
       "x25            0.0005      0.000      3.687      0.000       0.000       0.001\n",
       "x26           -0.0002      0.000     -1.255      0.210      -0.000    8.85e-05\n",
       "x27         7.988e-05      0.000      0.675      0.500      -0.000       0.000\n",
       "x28        -2.742e-05      0.000     -0.219      0.826      -0.000       0.000\n",
       "x29         9.149e-05      0.000      0.602      0.547      -0.000       0.000\n",
       "x30           -0.0001      0.000     -0.837      0.403      -0.000       0.000\n",
       "x31            0.0002      0.000      1.187      0.235      -0.000       0.001\n",
       "x32        -1.248e-05      0.000     -0.112      0.911      -0.000       0.000\n",
       "x33            0.0002      0.000      1.653      0.098   -4.13e-05       0.000\n",
       "x34         7.457e-05      0.000      0.653      0.514      -0.000       0.000\n",
       "x35        -5.692e-05    7.4e-05     -0.769      0.442      -0.000    8.82e-05\n",
       "x36          9.11e-05      0.000      0.869      0.385      -0.000       0.000\n",
       "x37           -0.0002      0.000     -1.177      0.239      -0.000       0.000\n",
       "x38         -2.76e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x0 x1        -74.9030     68.059     -1.101      0.271    -208.321      58.514\n",
       "x0 x2         -0.0359      0.052     -0.686      0.492      -0.138       0.067\n",
       "x0 x3          0.0122      0.027      0.450      0.653      -0.041       0.065\n",
       "x0 x4          5.9784     34.830      0.172      0.864     -62.300      74.257\n",
       "x0 x5         10.9082     35.234      0.310      0.757     -58.162      79.978\n",
       "x0 x6         11.1929     38.358      0.292      0.770     -64.002      86.388\n",
       "x0 x7          9.9093     46.299      0.214      0.831     -80.851     100.670\n",
       "x0 x8        -19.5457     40.615     -0.481      0.630     -99.165      60.074\n",
       "x0 x9        -22.1785     40.651     -0.546      0.585    -101.867      57.510\n",
       "x0 x10       -25.7740     40.993     -0.629      0.530    -106.134      54.586\n",
       "x0 x11       -28.1223     40.974     -0.686      0.493    -108.445      52.200\n",
       "x0 x12       -31.2814     41.311     -0.757      0.449    -112.264      49.701\n",
       "x0 x13       -47.3909     41.291     -1.148      0.251    -128.335      33.553\n",
       "x0 x14       -24.8104     41.263     -0.601      0.548    -105.699      56.078\n",
       "x0 x15       -28.1669     42.108     -0.669      0.504    -110.713      54.379\n",
       "x0 x16       -49.4119     42.212     -1.171      0.242    -132.161      33.337\n",
       "x0 x17       -25.6995     42.247     -0.608      0.543    -108.517      57.118\n",
       "x0 x18       -21.0954     44.293     -0.476      0.634    -107.925      65.734\n",
       "x0 x19       -12.2303     45.396     -0.269      0.788    -101.221      76.760\n",
       "x0 x20       -54.8174     47.219     -1.161      0.246    -147.381      37.746\n",
       "x0 x21       -36.3092     49.278     -0.737      0.461    -132.911      60.292\n",
       "x0 x22        18.9482     48.002      0.395      0.693     -75.152     113.048\n",
       "x0 x23        -0.0003      0.001     -0.360      0.719      -0.002       0.002\n",
       "x0 x24         1.0525      4.182      0.252      0.801      -7.146       9.251\n",
       "x0 x25        -3.8102      5.238     -0.727      0.467     -14.079       6.459\n",
       "x0 x26        -4.3864      5.875     -0.747      0.455     -15.903       7.130\n",
       "x0 x27         1.3298      5.219      0.255      0.799      -8.901      11.561\n",
       "x0 x28        -1.4689      6.691     -0.220      0.826     -14.585      11.647\n",
       "x0 x29        -2.2691      5.413     -0.419      0.675     -12.881       8.343\n",
       "x0 x30         6.1461      6.660      0.923      0.356      -6.910      19.202\n",
       "x0 x31         3.4009      4.896      0.695      0.487      -6.197      12.999\n",
       "x0 x32         1.4223      3.339      0.426      0.670      -5.123       7.968\n",
       "x0 x33        -2.4850      3.384     -0.734      0.463      -9.118       4.148\n",
       "x0 x34         2.1840      3.376      0.647      0.518      -4.434       8.802\n",
       "x0 x35         6.0071      4.018      1.495      0.135      -1.869      13.884\n",
       "x0 x36        -1.1370      3.500     -0.325      0.745      -7.999       5.725\n",
       "x0 x37         3.3962      4.896      0.694      0.488      -6.201      12.994\n",
       "x0 x38        -0.0003      0.001     -0.360      0.719      -0.002       0.002\n",
       "x1 x2         -4.9901      4.450     -1.121      0.262     -13.714       3.734\n",
       "x1 x3         -1.1436      2.505     -0.457      0.648      -6.054       3.767\n",
       "x1 x4       -714.5455   2314.058     -0.309      0.757   -5250.863    3821.772\n",
       "x1 x5      -1692.6360   2338.753     -0.724      0.469   -6277.363    2892.091\n",
       "x1 x6       -377.4756   2579.616     -0.146      0.884   -5434.375    4679.423\n",
       "x1 x7       5632.6797   4052.966      1.390      0.165   -2312.471    1.36e+04\n",
       "x1 x8       5692.7091   4354.494      1.307      0.191   -2843.537    1.42e+04\n",
       "x1 x9       5122.5571   4356.726      1.176      0.240   -3418.063    1.37e+04\n",
       "x1 x10      3997.6939   4399.923      0.909      0.364   -4627.607    1.26e+04\n",
       "x1 x11      4275.6296   4382.346      0.976      0.329   -4315.214    1.29e+04\n",
       "x1 x12      4728.9001   4396.906      1.076      0.282   -3890.486    1.33e+04\n",
       "x1 x13      5208.1116   4420.892      1.178      0.239   -3458.295    1.39e+04\n",
       "x1 x14      4527.4955   4395.656      1.030      0.303   -4089.441    1.31e+04\n",
       "x1 x15      4186.3614   4515.533      0.927      0.354   -4665.574     1.3e+04\n",
       "x1 x16      5656.8845   4439.743      1.274      0.203   -3046.477    1.44e+04\n",
       "x1 x17      4387.3428   4481.893      0.979      0.328   -4398.647    1.32e+04\n",
       "x1 x18      3607.6941   4587.607      0.786      0.432   -5385.531    1.26e+04\n",
       "x1 x19      4929.3000   4704.930      1.048      0.295   -4293.916    1.42e+04\n",
       "x1 x20      5334.7011   4711.768      1.132      0.258   -3901.919    1.46e+04\n",
       "x1 x21      4642.1774   4901.392      0.947      0.344   -4966.169    1.43e+04\n",
       "x1 x22      1.106e+04   4989.919      2.216      0.027    1274.752    2.08e+04\n",
       "x1 x23      -169.2660    418.641     -0.404      0.686    -989.940     651.408\n",
       "x1 x24      -145.7273    476.239     -0.306      0.760   -1079.312     787.857\n",
       "x1 x25       402.6318    697.300      0.577      0.564    -964.306    1769.570\n",
       "x1 x26       -43.7494    594.641     -0.074      0.941   -1209.443    1121.944\n",
       "x1 x27      -372.5389    629.259     -0.592      0.554   -1606.094     861.016\n",
       "x1 x28       437.3160    694.044      0.630      0.529    -923.240    1797.872\n",
       "x1 x29       511.2789    599.547      0.853      0.394    -664.032    1686.590\n",
       "x1 x30      -558.3147    694.231     -0.804      0.421   -1919.236     802.606\n",
       "x1 x31       -30.6531    578.141     -0.053      0.958   -1164.000    1102.694\n",
       "x1 x32       146.6116    368.593      0.398      0.691    -575.952     869.175\n",
       "x1 x33        -2.8361    309.138     -0.009      0.993    -608.850     603.177\n",
       "x1 x34       165.6325    410.980      0.403      0.687    -640.024     971.289\n",
       "x1 x35      -493.5376    412.279     -1.197      0.231   -1301.740     314.665\n",
       "x1 x36      -280.3825    395.083     -0.710      0.478   -1054.876     494.112\n",
       "x1 x37       -63.5821    401.883     -0.158      0.874    -851.405     724.241\n",
       "x1 x38      -169.2660    418.641     -0.404      0.686    -989.940     651.408\n",
       "x2 x3          0.0074      0.002      3.510      0.000       0.003       0.012\n",
       "x2 x4         -1.6828      1.916     -0.878      0.380      -5.440       2.074\n",
       "x2 x5         -2.1254      1.945     -1.093      0.275      -5.939       1.688\n",
       "x2 x6         -4.5859      2.245     -2.042      0.041      -8.987      -0.184\n",
       "x2 x7         -1.5126      2.846     -0.531      0.595      -7.092       4.067\n",
       "x2 x8          0.8951      3.662      0.244      0.807      -6.283       8.074\n",
       "x2 x9         -0.4435      3.666     -0.121      0.904      -7.630       6.743\n",
       "x2 x10        -1.1536      3.669     -0.314      0.753      -8.347       6.040\n",
       "x2 x11         0.1745      3.666      0.048      0.962      -7.013       7.362\n",
       "x2 x12         0.3918      3.673      0.107      0.915      -6.809       7.593\n",
       "x2 x13        -0.2009      3.716     -0.054      0.957      -7.486       7.084\n",
       "x2 x14         0.3103      3.702      0.084      0.933      -6.947       7.568\n",
       "x2 x15        -1.4772      3.724     -0.397      0.692      -8.778       5.824\n",
       "x2 x16        -0.0537      3.766     -0.014      0.989      -7.436       7.329\n",
       "x2 x17         1.0089      3.742      0.270      0.787      -6.328       8.345\n",
       "x2 x18        -0.9906      3.818     -0.259      0.795      -8.476       6.495\n",
       "x2 x19        -0.7903      3.862     -0.205      0.838      -8.361       6.780\n",
       "x2 x20        -0.3798      3.958     -0.096      0.924      -8.138       7.378\n",
       "x2 x21        -1.4123      3.932     -0.359      0.719      -9.120       6.296\n",
       "x2 x22         5.7702      4.230      1.364      0.173      -2.522      14.063\n",
       "x2 x23         4.9266      0.299     16.496      0.000       4.341       5.512\n",
       "x2 x24         0.4197      0.345      1.217      0.224      -0.256       1.096\n",
       "x2 x25         1.1376      0.561      2.028      0.043       0.038       2.237\n",
       "x2 x26         0.9126      0.436      2.091      0.037       0.057       1.768\n",
       "x2 x27         2.4170      0.497      4.862      0.000       1.442       3.392\n",
       "x2 x28        -1.5185      0.512     -2.965      0.003      -2.523      -0.515\n",
       "x2 x29         0.1141      0.448      0.255      0.799      -0.763       0.991\n",
       "x2 x30        -0.0098      0.504     -0.019      0.985      -0.999       0.979\n",
       "x2 x31        -3.5666      0.625     -5.706      0.000      -4.792      -2.341\n",
       "x2 x32         0.8585      0.318      2.698      0.007       0.235       1.482\n",
       "x2 x33        -1.2800      0.240     -5.326      0.000      -1.751      -0.809\n",
       "x2 x34         1.8939      0.388      4.887      0.000       1.134       2.654\n",
       "x2 x35         0.8887      0.305      2.917      0.004       0.291       1.486\n",
       "x2 x36         3.3587      0.366      9.188      0.000       2.642       4.075\n",
       "x2 x37        -8.4012      0.421    -19.944      0.000      -9.227      -7.575\n",
       "x2 x38         4.9266      0.299     16.496      0.000       4.341       5.512\n",
       "x3 x4         -0.2539      0.745     -0.341      0.733      -1.714       1.206\n",
       "x3 x5         -0.0963      0.785     -0.123      0.902      -1.635       1.443\n",
       "x3 x6         -0.4062      0.844     -0.482      0.630      -2.060       1.248\n",
       "x3 x7         -0.1489      0.470     -0.317      0.751      -1.070       0.772\n",
       "x3 x8         -0.3283      0.812     -0.405      0.686      -1.919       1.263\n",
       "x3 x9         -0.2791      0.823     -0.339      0.735      -1.893       1.335\n",
       "x3 x10        -0.2044      0.818     -0.250      0.803      -1.807       1.398\n",
       "x3 x11        -0.4896      0.859     -0.570      0.569      -2.173       1.194\n",
       "x3 x12        -0.2974      0.824     -0.361      0.718      -1.912       1.317\n",
       "x3 x13        -0.1856      0.833     -0.223      0.824      -1.818       1.447\n",
       "x3 x14        -0.1640      0.833     -0.197      0.844      -1.798       1.470\n",
       "x3 x15        -0.3898      0.836     -0.466      0.641      -2.028       1.249\n",
       "x3 x16         0.3455      0.970      0.356      0.722      -1.556       2.247\n",
       "x3 x17        -0.3265      0.864     -0.378      0.706      -2.020       1.367\n",
       "x3 x18        -0.3039      0.839     -0.362      0.717      -1.949       1.341\n",
       "x3 x19        -0.3760      0.868     -0.433      0.665      -2.078       1.326\n",
       "x3 x20         0.0903      0.924      0.098      0.922      -1.722       1.902\n",
       "x3 x21        -0.5579      1.023     -0.545      0.586      -2.563       1.448\n",
       "x3 x22        -0.8306      0.520     -1.598      0.110      -1.849       0.188\n",
       "x3 x23        -0.0548      0.152     -0.360      0.719      -0.353       0.244\n",
       "x3 x24        -0.4116      0.210     -1.965      0.050      -0.822      -0.001\n",
       "x3 x25         1.0236      0.278      3.687      0.000       0.479       1.568\n",
       "x3 x26        -0.3146      0.251     -1.255      0.210      -0.806       0.177\n",
       "x3 x27         0.1601      0.237      0.674      0.500      -0.305       0.625\n",
       "x3 x28        -0.0549      0.250     -0.219      0.826      -0.546       0.436\n",
       "x3 x29         0.1839      0.305      0.602      0.547      -0.415       0.783\n",
       "x3 x30        -0.2195      0.262     -0.837      0.403      -0.734       0.295\n",
       "x3 x31         0.4352      0.367      1.187      0.235      -0.284       1.154\n",
       "x3 x32        -0.0248      0.223     -0.111      0.911      -0.462       0.413\n",
       "x3 x33         0.4488      0.267      1.682      0.093      -0.074       0.972\n",
       "x3 x34         0.1526      0.228      0.668      0.504      -0.295       0.601\n",
       "x3 x35        -0.1144      0.148     -0.771      0.441      -0.405       0.177\n",
       "x3 x36         0.1830      0.209      0.875      0.381      -0.227       0.593\n",
       "x3 x37        -0.2997      0.257     -1.165      0.244      -0.804       0.204\n",
       "x3 x38        -0.0548      0.152     -0.360      0.719      -0.353       0.244\n",
       "x4 x5      -3.683e-11   2.99e-11     -1.230      0.219   -9.55e-11    2.19e-11\n",
       "x4 x6      -1.331e-11   1.02e-11     -1.306      0.192   -3.33e-11    6.67e-12\n",
       "x4 x7      -5.106e-11   3.77e-11     -1.355      0.176   -1.25e-10    2.28e-11\n",
       "x4 x8        675.7900   1365.800      0.495      0.621   -2001.630    3353.210\n",
       "x4 x9        790.0492   1390.862      0.568      0.570   -1936.500    3516.598\n",
       "x4 x10       883.0607   1373.556      0.643      0.520   -1809.563    3575.684\n",
       "x4 x11      1235.8337   1474.487      0.838      0.402   -1654.647    4126.314\n",
       "x4 x12       836.6824   1390.273      0.602      0.547   -1888.712    3562.077\n",
       "x4 x13       878.7741   1414.626      0.621      0.534   -1894.359    3651.907\n",
       "x4 x14       581.8373   1413.647      0.412      0.681   -2189.378    3353.052\n",
       "x4 x15      1203.7921   1410.379      0.854      0.393   -1561.016    3968.601\n",
       "x4 x16      -145.7449   1708.641     -0.085      0.932   -3495.245    3203.755\n",
       "x4 x17       878.3658   1465.434      0.599      0.549   -1994.369    3751.101\n",
       "x4 x18      1140.7606   1419.388      0.804      0.422   -1641.708    3923.230\n",
       "x4 x19       944.5852   1454.255      0.650      0.516   -1906.236    3795.406\n",
       "x4 x20       449.6460   1589.511      0.283      0.777   -2666.321    3565.613\n",
       "x4 x21      1464.0109   1769.997      0.827      0.408   -2005.767    4933.788\n",
       "x4 x22       168.8212    515.355      0.328      0.743    -841.444    1179.086\n",
       "x4 x23       -88.4169    173.784     -0.509      0.611    -429.090     252.257\n",
       "x4 x24       -57.9089    185.353     -0.312      0.755    -421.262     305.444\n",
       "x4 x25      -590.9026    340.505     -1.735      0.083   -1258.406      76.600\n",
       "x4 x26       -45.1385    267.486     -0.169      0.866    -569.499     479.222\n",
       "x4 x27       -55.3437    306.780     -0.180      0.857    -656.734     546.047\n",
       "x4 x28       691.0469    332.414      2.079      0.038      39.406    1342.688\n",
       "x4 x29       349.6586    325.442      1.074      0.283    -288.315     987.633\n",
       "x4 x30      -307.1614    290.377     -1.058      0.290    -876.396     262.073\n",
       "x4 x31      -311.5204    406.966     -0.765      0.444   -1109.308     486.268\n",
       "x4 x32       288.4684    167.159      1.726      0.084     -39.219     616.155\n",
       "x4 x33      -230.7824    135.645     -1.701      0.089    -496.691      35.126\n",
       "x4 x34      -108.1875    213.226     -0.507      0.612    -526.180     309.805\n",
       "x4 x35       328.5418    190.031      1.729      0.084     -43.982     701.066\n",
       "x4 x36      -365.4081    184.198     -1.984      0.047    -726.498      -4.318\n",
       "x4 x37       103.9435    241.823      0.430      0.667    -370.109     577.996\n",
       "x4 x38       -88.4169    173.784     -0.509      0.611    -429.090     252.257\n",
       "x5 x6      -4.595e-11   3.47e-11     -1.324      0.185   -1.14e-10    2.21e-11\n",
       "x5 x7      -3.333e-11   2.89e-11     -1.153      0.249      -9e-11    2.33e-11\n",
       "x5 x8        360.6412   1446.380      0.249      0.803   -2474.741    3196.023\n",
       "x5 x9        559.3092   1470.533      0.380      0.704   -2323.420    3442.039\n",
       "x5 x10      1.789e-11   1.09e-11      1.641      0.101   -3.49e-12    3.93e-11\n",
       "x5 x11       987.1139   1549.591      0.637      0.524   -2050.596    4024.824\n",
       "x5 x12       671.8208   1470.005      0.457      0.648   -2209.874    3553.516\n",
       "x5 x13       744.5291   1492.766      0.499      0.618   -2181.784    3670.843\n",
       "x5 x14       267.0731   1492.053      0.179      0.858   -2657.843    3191.989\n",
       "x5 x15     -1.058e-12   9.99e-12     -0.106      0.916   -2.06e-11    1.85e-11\n",
       "x5 x16      -403.4995   1772.153     -0.228      0.820   -3877.504    3070.505\n",
       "x5 x17       652.2994   1546.692      0.422      0.673   -2379.727    3684.326\n",
       "x5 x18       619.4016   1497.047      0.414      0.679   -2315.305    3554.108\n",
       "x5 x19     -3.022e-11   2.13e-11     -1.422      0.155   -7.19e-11    1.14e-11\n",
       "x5 x20      8.895e-11   6.89e-11      1.292      0.196    -4.6e-11    2.24e-10\n",
       "x5 x21      1323.6751   1836.452      0.721      0.471   -2276.377    4923.727\n",
       "x5 x22      -215.5788    601.390     -0.358      0.720   -1394.501     963.343\n",
       "x5 x23       -98.2874    175.574     -0.560      0.576    -442.470     245.896\n",
       "x5 x24       -98.8199    187.934     -0.526      0.599    -467.232     269.592\n",
       "x5 x25      -488.6764    344.396     -1.419      0.156   -1163.807     186.454\n",
       "x5 x26      -143.7574    271.155     -0.530      0.596    -675.310     387.795\n",
       "x5 x27      -152.6385    311.381     -0.490      0.624    -763.048     457.771\n",
       "x5 x28       708.5112    335.912      2.109      0.035      50.012    1367.010\n",
       "x5 x29       330.3825    328.412      1.006      0.314    -313.414     974.178\n",
       "x5 x30      -197.3877    293.350     -0.673      0.501    -772.450     377.675\n",
       "x5 x31      -283.4977    410.995     -0.690      0.490   -1089.183     522.187\n",
       "x5 x32       315.9634    169.615      1.863      0.063     -16.538     648.464\n",
       "x5 x33      -217.6329    137.472     -1.583      0.113    -487.123      51.858\n",
       "x5 x34      -150.2225    215.863     -0.696      0.487    -573.385     272.939\n",
       "x5 x35       358.4849    192.493      1.862      0.063     -18.864     735.834\n",
       "x5 x36      -372.7689    187.183     -1.991      0.046    -739.710      -5.828\n",
       "x5 x37       140.1844    244.232      0.574      0.566    -338.590     618.959\n",
       "x5 x38       -98.2874    175.574     -0.560      0.576    -442.470     245.896\n",
       "x6 x7       6.854e-12   9.74e-12      0.704      0.482   -1.22e-11    2.59e-11\n",
       "x6 x8       1230.4936   1562.275      0.788      0.431   -1832.080    4293.068\n",
       "x6 x9       1273.2990   1589.030      0.801      0.423   -1841.725    4388.323\n",
       "x6 x10      1947.0731   1566.281      1.243      0.214   -1123.354    5017.500\n",
       "x6 x11      2362.7951   1666.725      1.418      0.156    -904.535    5630.125\n",
       "x6 x12      1208.4026   1591.331      0.759      0.448   -1911.131    4327.936\n",
       "x6 x13      1314.7808   1612.863      0.815      0.415   -1846.963    4476.525\n",
       "x6 x14      1012.2367   1618.363      0.625      0.532   -2160.289    4184.762\n",
       "x6 x15      1813.7381   1606.000      1.129      0.259   -1334.551    4962.027\n",
       "x6 x16       683.4545   1900.943      0.360      0.719   -3043.020    4409.929\n",
       "x6 x17      1552.2205   1653.341      0.939      0.348   -1688.873    4793.314\n",
       "x6 x18      1315.7333   1661.983      0.792      0.429   -1942.301    4573.768\n",
       "x6 x19      2239.4629   1690.387      1.325      0.185   -1074.253    5553.179\n",
       "x6 x20      1464.1010   1788.486      0.819      0.413   -2041.922    4970.124\n",
       "x6 x21      2138.4033   1957.383      1.092      0.275   -1698.713    5975.520\n",
       "x6 x22     -1038.3982    910.362     -1.141      0.254   -2823.009     746.213\n",
       "x6 x23      -254.8304    197.468     -1.290      0.197    -641.932     132.271\n",
       "x6 x24      -111.0048    216.643     -0.512      0.608    -535.696     313.686\n",
       "x6 x25      -629.9375    380.907     -1.654      0.098   -1376.641     116.766\n",
       "x6 x26       135.8814    310.561      0.438      0.662    -472.922     744.684\n",
       "x6 x27      -171.4240    341.276     -0.502      0.615    -840.437     497.589\n",
       "x6 x28       535.9523    381.436      1.405      0.160    -211.789    1283.694\n",
       "x6 x29       542.7481    354.782      1.530      0.126    -152.742    1238.238\n",
       "x6 x30      -163.6655    341.036     -0.480      0.631    -832.208     504.877\n",
       "x6 x31      -390.3099    448.200     -0.871      0.384   -1268.931     488.311\n",
       "x6 x32       405.7759    195.468      2.076      0.038      22.594     788.958\n",
       "x6 x33      -296.9509    155.538     -1.909      0.056    -601.856       7.955\n",
       "x6 x34      -213.3970    246.426     -0.866      0.387    -696.473     269.679\n",
       "x6 x35       200.8627    218.172      0.921      0.357    -226.827     628.552\n",
       "x6 x36      -404.1982    217.531     -1.858      0.063    -830.631      22.235\n",
       "x6 x37       114.1007    276.099      0.413      0.679    -427.145     655.346\n",
       "x6 x38      -254.8304    197.468     -1.290      0.197    -641.932     132.271\n",
       "x7 x8       -488.4796    491.273     -0.994      0.320   -1451.537     474.578\n",
       "x7 x9       -292.0720    488.206     -0.598      0.550   -1249.117     664.973\n",
       "x7 x10      -7.61e-12   4.34e-12     -1.755      0.079   -1.61e-11     8.9e-13\n",
       "x7 x11       695.8052    640.771      1.086      0.278    -560.318    1951.929\n",
       "x7 x12      -446.6573    692.522     -0.645      0.519   -1804.230     910.915\n",
       "x7 x13       184.7067    599.307      0.308      0.758    -990.133    1359.547\n",
       "x7 x14       -77.2879    577.712     -0.134      0.894   -1209.795    1055.219\n",
       "x7 x15     -1.763e-12   1.63e-12     -1.081      0.280   -4.96e-12    1.43e-12\n",
       "x7 x16      -806.3990   1150.817     -0.701      0.484   -3062.380    1449.582\n",
       "x7 x17     -4.334e-12   3.18e-12     -1.362      0.173   -1.06e-11     1.9e-12\n",
       "x7 x18      -384.0031    829.058     -0.463      0.643   -2009.231    1241.225\n",
       "x7 x19     -4.074e-12    1.2e-12     -3.393      0.001   -6.43e-12   -1.72e-12\n",
       "x7 x20      2.371e-12   2.07e-12      1.143      0.253    -1.7e-12    6.44e-12\n",
       "x7 x21       509.2743   1153.641      0.441      0.659   -1752.243    2770.791\n",
       "x7 x22      1099.9941   1157.414      0.950      0.342   -1168.919    3368.907\n",
       "x7 x23      -519.9135    295.026     -1.762      0.078   -1098.262      58.435\n",
       "x7 x24      -118.8622    299.770     -0.397      0.692    -706.510     468.786\n",
       "x7 x25       -12.1353    512.367     -0.024      0.981   -1016.544     992.274\n",
       "x7 x26      -296.4437    355.135     -0.835      0.404    -992.626     399.739\n",
       "x7 x27      -271.2725    454.849     -0.596      0.551   -1162.926     620.381\n",
       "x7 x28       920.4159    440.126      2.091      0.037      57.623    1783.209\n",
       "x7 x29       578.3524    409.248      1.413      0.158    -223.910    1380.615\n",
       "x7 x30      -391.1287    392.262     -0.997      0.319   -1160.092     377.835\n",
       "x7 x31       -82.6554    544.409     -0.152      0.879   -1149.876     984.565\n",
       "x7 x32       208.6270    267.744      0.779      0.436    -316.241     733.495\n",
       "x7 x33       -94.8834    210.241     -0.451      0.652    -507.025     317.258\n",
       "x7 x34      -143.0788    329.037     -0.435      0.664    -788.099     501.942\n",
       "x7 x35       258.0147    272.132      0.948      0.343    -275.453     791.483\n",
       "x7 x36      -169.4264    311.269     -0.544      0.586    -779.616     440.763\n",
       "x7 x37       105.8689    364.222      0.291      0.771    -608.126     819.864\n",
       "x7 x38      -519.9135    295.026     -1.762      0.078   -1098.262      58.435\n",
       "x8 x9      -6.254e-13    5.5e-13     -1.137      0.256    -1.7e-12    4.53e-13\n",
       "x8 x10      2.733e-13   3.99e-13      0.685      0.494   -5.09e-13    1.06e-12\n",
       "x8 x11     -1.155e-12   7.34e-13     -1.573      0.116   -2.59e-12    2.84e-13\n",
       "x8 x12      2.315e-13   8.17e-13      0.283      0.777   -1.37e-12    1.83e-12\n",
       "x8 x13      2.451e-13   3.99e-13      0.614      0.539   -5.38e-13    1.03e-12\n",
       "x8 x14     -2.664e-12   9.58e-13     -2.780      0.005   -4.54e-12   -7.85e-13\n",
       "x8 x15      1.036e-12   4.96e-13      2.089      0.037    6.38e-14    2.01e-12\n",
       "x8 x16     -3.983e-12   1.55e-12     -2.562      0.010   -7.03e-12   -9.36e-13\n",
       "x8 x17      8.575e-13   6.31e-13      1.360      0.174   -3.79e-13    2.09e-12\n",
       "x8 x18     -8.907e-13   5.74e-13     -1.552      0.121   -2.02e-12    2.34e-13\n",
       "x8 x19      1.126e-12    6.4e-13      1.758      0.079    -1.3e-13    2.38e-12\n",
       "x8 x20      -6.75e-13   5.44e-13     -1.240      0.215   -1.74e-12    3.92e-13\n",
       "x8 x21     -1.164e-14   3.15e-13     -0.037      0.970   -6.29e-13    6.05e-13\n",
       "x8 x22      -1.96e-12   9.23e-13     -2.124      0.034   -3.77e-12   -1.51e-13\n",
       "x8 x23       486.8156    234.405      2.077      0.038      27.304     946.327\n",
       "x8 x24       793.9208    340.142      2.334      0.020     127.131    1460.711\n",
       "x8 x25     -1360.0992    433.896     -3.135      0.002   -2210.679    -509.519\n",
       "x8 x26       667.9523    363.310      1.839      0.066     -44.255    1380.160\n",
       "x8 x27      -294.5133    359.005     -0.820      0.412    -998.281     409.254\n",
       "x8 x28      -490.7699    391.619     -1.253      0.210   -1258.473     276.934\n",
       "x8 x29      -848.4931    434.721     -1.952      0.051   -1700.689       3.703\n",
       "x8 x30       660.1354    417.918      1.580      0.114    -159.122    1479.393\n",
       "x8 x31      -669.5368    556.628     -1.203      0.229   -1760.711     421.637\n",
       "x8 x32      -193.8965    273.821     -0.708      0.479    -730.675     342.882\n",
       "x8 x33      -582.9636    190.686     -3.057      0.002    -956.771    -209.156\n",
       "x8 x34      -237.2936    328.856     -0.722      0.471    -881.959     407.372\n",
       "x8 x35      -125.1478    245.514     -0.510      0.610    -606.437     356.141\n",
       "x8 x36       -23.3739    266.556     -0.088      0.930    -545.912     499.164\n",
       "x8 x37       402.1121    328.159      1.225      0.220    -241.188    1045.412\n",
       "x8 x38       486.8156    234.405      2.077      0.038      27.304     946.327\n",
       "x9 x10              0          0        nan        nan           0           0\n",
       "x9 x11              0          0        nan        nan           0           0\n",
       "x9 x12              0          0        nan        nan           0           0\n",
       "x9 x13              0          0        nan        nan           0           0\n",
       "x9 x14              0          0        nan        nan           0           0\n",
       "x9 x15              0          0        nan        nan           0           0\n",
       "x9 x16              0          0        nan        nan           0           0\n",
       "x9 x17              0          0        nan        nan           0           0\n",
       "x9 x18              0          0        nan        nan           0           0\n",
       "x9 x19              0          0        nan        nan           0           0\n",
       "x9 x20              0          0        nan        nan           0           0\n",
       "x9 x21              0          0        nan        nan           0           0\n",
       "x9 x22              0          0        nan        nan           0           0\n",
       "x9 x23       313.7290    234.356      1.339      0.181    -145.686     773.144\n",
       "x9 x24       845.3347    340.745      2.481      0.013     177.362    1513.307\n",
       "x9 x25     -1416.3159    434.841     -3.257      0.001   -2268.748    -563.884\n",
       "x9 x26       748.4595    362.801      2.063      0.039      37.250    1459.669\n",
       "x9 x27      -209.8557    357.814     -0.586      0.558    -911.289     491.578\n",
       "x9 x28      -616.4942    391.427     -1.575      0.115   -1383.820     150.832\n",
       "x9 x29      -792.8596    435.433     -1.821      0.069   -1646.453      60.734\n",
       "x9 x30       686.3787    417.336      1.645      0.100    -131.737    1504.494\n",
       "x9 x31      -610.3439    556.496     -1.097      0.273   -1701.260     480.572\n",
       "x9 x32      -271.1305    273.884     -0.990      0.322    -808.034     265.773\n",
       "x9 x33      -558.5081    190.739     -2.928      0.003    -932.420    -184.596\n",
       "x9 x34      -244.1398    328.669     -0.743      0.458    -888.440     400.160\n",
       "x9 x35      -139.9712    245.171     -0.571      0.568    -620.586     340.644\n",
       "x9 x36        37.5070    266.483      0.141      0.888    -484.888     559.902\n",
       "x9 x37       457.3197    327.970      1.394      0.163    -185.610    1100.249\n",
       "x9 x38       313.7290    234.356      1.339      0.181    -145.686     773.144\n",
       "x10 x11             0          0        nan        nan           0           0\n",
       "x10 x12             0          0        nan        nan           0           0\n",
       "x10 x13             0          0        nan        nan           0           0\n",
       "x10 x14             0          0        nan        nan           0           0\n",
       "x10 x15             0          0        nan        nan           0           0\n",
       "x10 x16             0          0        nan        nan           0           0\n",
       "x10 x17             0          0        nan        nan           0           0\n",
       "x10 x18             0          0        nan        nan           0           0\n",
       "x10 x19             0          0        nan        nan           0           0\n",
       "x10 x20             0          0        nan        nan           0           0\n",
       "x10 x21             0          0        nan        nan           0           0\n",
       "x10 x22             0          0        nan        nan           0           0\n",
       "x10 x23      341.3716    236.968      1.441      0.150    -123.163     805.906\n",
       "x10 x24      818.8950    342.560      2.391      0.017     147.365    1490.425\n",
       "x10 x25    -1603.2770    438.575     -3.656      0.000   -2463.029    -743.525\n",
       "x10 x26      930.6231    366.283      2.541      0.011     212.587    1648.659\n",
       "x10 x27     -177.6196    361.374     -0.492      0.623    -886.031     530.792\n",
       "x10 x28     -538.9796    395.065     -1.364      0.173   -1313.438     235.479\n",
       "x10 x29     -817.1112    439.663     -1.858      0.063   -1678.997      44.774\n",
       "x10 x30      543.2138    422.288      1.286      0.198    -284.609    1371.037\n",
       "x10 x31     -657.9775    559.462     -1.176      0.240   -1754.708     438.753\n",
       "x10 x32     -198.8598    275.949     -0.721      0.471    -739.811     342.091\n",
       "x10 x33     -603.2474    192.634     -3.132      0.002    -980.873    -225.622\n",
       "x10 x34     -314.8221    331.053     -0.951      0.342    -963.795     334.151\n",
       "x10 x35     -173.3855    247.498     -0.701      0.484    -658.563     311.792\n",
       "x10 x36      -27.1443    270.001     -0.101      0.920    -556.435     502.147\n",
       "x10 x37      519.6716    331.709      1.567      0.117    -130.587    1169.930\n",
       "x10 x38      341.3716    236.968      1.441      0.150    -123.163     805.906\n",
       "x11 x12             0          0        nan        nan           0           0\n",
       "x11 x13             0          0        nan        nan           0           0\n",
       "x11 x14             0          0        nan        nan           0           0\n",
       "x11 x15             0          0        nan        nan           0           0\n",
       "x11 x16             0          0        nan        nan           0           0\n",
       "x11 x17             0          0        nan        nan           0           0\n",
       "x11 x18             0          0        nan        nan           0           0\n",
       "x11 x19             0          0        nan        nan           0           0\n",
       "x11 x20             0          0        nan        nan           0           0\n",
       "x11 x21             0          0        nan        nan           0           0\n",
       "x11 x22             0          0        nan        nan           0           0\n",
       "x11 x23      342.4753    237.011      1.445      0.149    -122.145     807.096\n",
       "x11 x24      807.2273    342.472      2.357      0.018     135.869    1478.586\n",
       "x11 x25    -1280.1717    436.794     -2.931      0.003   -2136.431    -423.912\n",
       "x11 x26      681.5827    365.599      1.864      0.062     -35.112    1398.277\n",
       "x11 x27     -384.4082    362.386     -1.061      0.289   -1094.805     325.989\n",
       "x11 x28     -548.1579    395.432     -1.386      0.166   -1323.336     227.020\n",
       "x11 x29     -845.8099    437.956     -1.931      0.053   -1704.347      12.728\n",
       "x11 x30      741.8920    419.933      1.767      0.077     -81.316    1565.100\n",
       "x11 x31     -590.3124    559.712     -1.055      0.292   -1687.534     506.909\n",
       "x11 x32     -218.3302    275.872     -0.791      0.429    -759.131     322.471\n",
       "x11 x33     -572.5347    192.224     -2.978      0.003    -949.356    -195.713\n",
       "x11 x34     -286.4198    331.106     -0.865      0.387    -935.497     362.657\n",
       "x11 x35     -190.6740    247.240     -0.771      0.441    -675.346     293.998\n",
       "x11 x36       17.9643    269.122      0.067      0.947    -509.603     545.532\n",
       "x11 x37      501.7327    330.962      1.516      0.130    -147.062    1150.528\n",
       "x11 x38      342.4753    237.011      1.445      0.149    -122.145     807.096\n",
       "x12 x13             0          0        nan        nan           0           0\n",
       "x12 x14             0          0        nan        nan           0           0\n",
       "x12 x15             0          0        nan        nan           0           0\n",
       "x12 x16             0          0        nan        nan           0           0\n",
       "x12 x17             0          0        nan        nan           0           0\n",
       "x12 x18             0          0        nan        nan           0           0\n",
       "x12 x19             0          0        nan        nan           0           0\n",
       "x12 x20             0          0        nan        nan           0           0\n",
       "x12 x21             0          0        nan        nan           0           0\n",
       "x12 x22             0          0        nan        nan           0           0\n",
       "x12 x23      383.2502    239.028      1.603      0.109     -85.323     851.823\n",
       "x12 x24      827.0959    343.547      2.408      0.016     153.630    1500.561\n",
       "x12 x25    -1412.6437    440.633     -3.206      0.001   -2276.429    -548.859\n",
       "x12 x26      641.8454    367.618      1.746      0.081     -78.807    1362.497\n",
       "x12 x27     -333.7367    365.742     -0.912      0.362   -1050.711     383.238\n",
       "x12 x28     -618.6952    399.974     -1.547      0.122   -1402.777     165.386\n",
       "x12 x29     -796.7613    440.483     -1.809      0.071   -1660.252      66.730\n",
       "x12 x30      841.1081    425.612      1.976      0.048       6.768    1675.448\n",
       "x12 x31     -688.5451    564.289     -1.220      0.222   -1794.738     417.648\n",
       "x12 x32     -237.7979    276.847     -0.859      0.390    -780.509     304.913\n",
       "x12 x33     -572.8046    193.493     -2.960      0.003    -952.114    -193.495\n",
       "x12 x34     -274.9603    332.332     -0.827      0.408    -926.441     376.521\n",
       "x12 x35     -111.3238    249.324     -0.447      0.655    -600.082     377.434\n",
       "x12 x36      -55.0263    269.806     -0.204      0.838    -583.934     473.882\n",
       "x12 x37      485.0307    332.479      1.459      0.145    -166.738    1136.799\n",
       "x12 x38      383.2502    239.028      1.603      0.109     -85.323     851.823\n",
       "x13 x14             0          0        nan        nan           0           0\n",
       "x13 x15             0          0        nan        nan           0           0\n",
       "x13 x16             0          0        nan        nan           0           0\n",
       "x13 x17             0          0        nan        nan           0           0\n",
       "x13 x18             0          0        nan        nan           0           0\n",
       "x13 x19             0          0        nan        nan           0           0\n",
       "x13 x20             0          0        nan        nan           0           0\n",
       "x13 x21             0          0        nan        nan           0           0\n",
       "x13 x22             0          0        nan        nan           0           0\n",
       "x13 x23      366.0434    239.708      1.527      0.127    -103.862     835.949\n",
       "x13 x24      756.7745    344.210      2.199      0.028      82.010    1431.539\n",
       "x13 x25    -1180.0175    441.775     -2.671      0.008   -2046.043    -313.992\n",
       "x13 x26      752.7183    370.402      2.032      0.042      26.608    1478.828\n",
       "x13 x27     -427.9046    366.640     -1.167      0.243   -1146.639     290.830\n",
       "x13 x28     -472.1082    399.358     -1.182      0.237   -1254.982     310.766\n",
       "x13 x29     -793.5539    440.071     -1.803      0.071   -1656.239      69.131\n",
       "x13 x30      593.2777    424.772      1.397      0.163    -239.416    1425.971\n",
       "x13 x31     -661.1949    565.727     -1.169      0.243   -1770.206     447.816\n",
       "x13 x32     -214.8176    277.956     -0.773      0.440    -759.703     330.068\n",
       "x13 x33     -525.4062    194.111     -2.707      0.007    -905.929    -144.884\n",
       "x13 x34     -331.9309    333.889     -0.994      0.320    -986.464     322.602\n",
       "x13 x35     -306.7352    249.837     -1.228      0.220    -796.498     183.028\n",
       "x13 x36       22.7402    271.826      0.084      0.933    -510.129     555.609\n",
       "x13 x37      421.3210    334.577      1.259      0.208    -234.561    1077.203\n",
       "x13 x38      366.0434    239.708      1.527      0.127    -103.862     835.949\n",
       "x14 x15             0          0        nan        nan           0           0\n",
       "x14 x16             0          0        nan        nan           0           0\n",
       "x14 x17             0          0        nan        nan           0           0\n",
       "x14 x18             0          0        nan        nan           0           0\n",
       "x14 x19             0          0        nan        nan           0           0\n",
       "x14 x20             0          0        nan        nan           0           0\n",
       "x14 x21             0          0        nan        nan           0           0\n",
       "x14 x22             0          0        nan        nan           0           0\n",
       "x14 x23      408.8971    238.358      1.715      0.086     -58.363     876.157\n",
       "x14 x24      789.4937    345.100      2.288      0.022     112.984    1466.003\n",
       "x14 x25    -1214.3040    443.066     -2.741      0.006   -2082.860    -345.748\n",
       "x14 x26      553.1497    369.093      1.499      0.134    -170.394    1276.694\n",
       "x14 x27     -406.1475    366.400     -1.108      0.268   -1124.413     312.118\n",
       "x14 x28     -613.7194    398.527     -1.540      0.124   -1394.964     167.525\n",
       "x14 x29     -850.8059    438.922     -1.938      0.053   -1711.239       9.627\n",
       "x14 x30      904.2289    423.906      2.133      0.033      73.234    1735.224\n",
       "x14 x31     -636.5693    567.824     -1.121      0.262   -1749.692     476.554\n",
       "x14 x32     -234.8189    279.005     -0.842      0.400    -781.762     312.124\n",
       "x14 x33     -538.4532    194.382     -2.770      0.006    -919.506    -157.400\n",
       "x14 x34     -288.9844    335.145     -0.862      0.389    -945.980     368.011\n",
       "x14 x35     -115.6380    249.499     -0.463      0.643    -604.738     373.462\n",
       "x14 x36       12.7014    272.618      0.047      0.963    -521.720     547.123\n",
       "x14 x37      445.4291    334.742      1.331      0.183    -210.776    1101.635\n",
       "x14 x38      408.8971    238.358      1.715      0.086     -58.363     876.157\n",
       "x15 x16             0          0        nan        nan           0           0\n",
       "x15 x17             0          0        nan        nan           0           0\n",
       "x15 x18             0          0        nan        nan           0           0\n",
       "x15 x19             0          0        nan        nan           0           0\n",
       "x15 x20             0          0        nan        nan           0           0\n",
       "x15 x21             0          0        nan        nan           0           0\n",
       "x15 x22             0          0        nan        nan           0           0\n",
       "x15 x23      334.8764    241.791      1.385      0.166    -139.114     808.867\n",
       "x15 x24      633.3754    345.917      1.831      0.067     -44.737    1311.487\n",
       "x15 x25    -1222.9016    449.165     -2.723      0.006   -2103.414    -342.389\n",
       "x15 x26      690.7526    374.352      1.845      0.065     -43.100    1424.606\n",
       "x15 x27     -138.5387    369.378     -0.375      0.708    -862.641     585.564\n",
       "x15 x28     -569.9463    403.366     -1.413      0.158   -1360.676     220.784\n",
       "x15 x29     -702.3306    448.524     -1.566      0.117   -1581.585     176.924\n",
       "x15 x30      563.9244    428.483      1.316      0.188    -276.043    1403.892\n",
       "x15 x31     -493.7240    567.899     -0.869      0.385   -1606.993     619.545\n",
       "x15 x32     -176.4475    279.575     -0.631      0.528    -724.506     371.611\n",
       "x15 x33     -443.3629    196.091     -2.261      0.024    -827.767     -58.959\n",
       "x15 x34     -227.8028    335.921     -0.678      0.498    -886.319     430.713\n",
       "x15 x35     -144.5605    252.466     -0.573      0.567    -639.477     350.356\n",
       "x15 x36      -43.3342    275.555     -0.157      0.875    -583.514     496.845\n",
       "x15 x37      424.3533    337.790      1.256      0.209    -237.827    1086.533\n",
       "x15 x38      334.8764    241.791      1.385      0.166    -139.114     808.867\n",
       "x16 x17             0          0        nan        nan           0           0\n",
       "x16 x18             0          0        nan        nan           0           0\n",
       "x16 x19             0          0        nan        nan           0           0\n",
       "x16 x20             0          0        nan        nan           0           0\n",
       "x16 x21             0          0        nan        nan           0           0\n",
       "x16 x22             0          0        nan        nan           0           0\n",
       "x16 x23      338.7732    242.588      1.396      0.163    -136.780     814.327\n",
       "x16 x24      917.0770    350.062      2.620      0.009     230.839    1603.315\n",
       "x16 x25    -1505.3008    450.907     -3.338      0.001   -2389.226    -621.375\n",
       "x16 x26      754.3447    377.274      1.999      0.046      14.764    1493.926\n",
       "x16 x27     -276.1056    374.014     -0.738      0.460   -1009.296     457.085\n",
       "x16 x28     -593.1253    412.222     -1.439      0.150   -1401.217     214.966\n",
       "x16 x29     -771.4892    444.656     -1.735      0.083   -1643.161     100.182\n",
       "x16 x30      663.5577    435.127      1.525      0.127    -189.435    1516.551\n",
       "x16 x31     -680.2514    569.186     -1.195      0.232   -1796.044     435.542\n",
       "x16 x32     -288.1903    282.309     -1.021      0.307    -841.610     265.229\n",
       "x16 x33     -611.8798    198.207     -3.087      0.002   -1000.431    -223.328\n",
       "x16 x34     -195.8904    338.227     -0.579      0.562    -858.926     467.145\n",
       "x16 x35     -205.6731    255.649     -0.805      0.421    -706.829     295.482\n",
       "x16 x36      -39.5522    276.470     -0.143      0.886    -581.525     502.421\n",
       "x16 x37      489.2752    337.112      1.451      0.147    -171.575    1150.126\n",
       "x16 x38      338.7732    242.588      1.396      0.163    -136.780     814.327\n",
       "x17 x18             0          0        nan        nan           0           0\n",
       "x17 x19             0          0        nan        nan           0           0\n",
       "x17 x20             0          0        nan        nan           0           0\n",
       "x17 x21             0          0        nan        nan           0           0\n",
       "x17 x22             0          0        nan        nan           0           0\n",
       "x17 x23      301.1147    246.287      1.223      0.222    -181.690     783.920\n",
       "x17 x24      913.6741    349.067      2.617      0.009     229.388    1597.960\n",
       "x17 x25    -1547.7726    452.411     -3.421      0.001   -2434.647    -660.898\n",
       "x17 x26      739.1453    374.883      1.972      0.049       4.250    1474.040\n",
       "x17 x27     -310.3582    372.550     -0.833      0.405   -1040.679     419.962\n",
       "x17 x28     -513.4702    404.103     -1.271      0.204   -1305.645     278.705\n",
       "x17 x29     -713.0296    448.575     -1.590      0.112   -1592.384     166.325\n",
       "x17 x30      675.7948    429.110      1.575      0.115    -165.402    1516.992\n",
       "x17 x31     -743.1725    570.800     -1.302      0.193   -1862.128     375.783\n",
       "x17 x32     -253.6175    282.269     -0.898      0.369    -806.959     299.724\n",
       "x17 x33     -643.4673    197.977     -3.250      0.001   -1031.567    -255.368\n",
       "x17 x34     -241.4132    338.955     -0.712      0.476    -905.877     423.051\n",
       "x17 x35     -148.0336    253.381     -0.584      0.559    -644.745     348.678\n",
       "x17 x36      -42.9867    279.431     -0.154      0.878    -590.763     504.790\n",
       "x17 x37      471.4909    341.096      1.382      0.167    -197.170    1140.152\n",
       "x17 x38      301.1147    246.287      1.223      0.222    -181.690     783.920\n",
       "x18 x19             0          0        nan        nan           0           0\n",
       "x18 x20             0          0        nan        nan           0           0\n",
       "x18 x21             0          0        nan        nan           0           0\n",
       "x18 x22             0          0        nan        nan           0           0\n",
       "x18 x23      183.4778    251.702      0.729      0.466    -309.942     676.897\n",
       "x18 x24      619.4883    359.441      1.723      0.085     -85.134    1324.111\n",
       "x18 x25    -1204.0176    468.315     -2.571      0.010   -2122.069    -285.967\n",
       "x18 x26      823.0020    394.686      2.085      0.037      49.286    1596.718\n",
       "x18 x27     -182.7354    388.636     -0.470      0.638    -944.590     579.119\n",
       "x18 x28     -488.5731    421.549     -1.159      0.247   -1314.948     337.802\n",
       "x18 x29     -627.6303    457.556     -1.372      0.170   -1524.592     269.331\n",
       "x18 x30      461.6023    449.748      1.026      0.305    -420.052    1343.256\n",
       "x18 x31     -470.5813    583.151     -0.807      0.420   -1613.750     672.588\n",
       "x18 x32     -118.7026    291.360     -0.407      0.684    -689.863     452.458\n",
       "x18 x33     -488.4481    205.013     -2.383      0.017    -890.341     -86.555\n",
       "x18 x34     -295.2455    349.013     -0.846      0.398    -979.427     388.936\n",
       "x18 x35     -209.7063    264.863     -0.792      0.429    -728.925     309.513\n",
       "x18 x36       28.7665    288.728      0.100      0.921    -537.236     594.769\n",
       "x18 x37      427.7237    350.345      1.221      0.222    -259.068    1114.516\n",
       "x18 x38      183.4778    251.702      0.729      0.466    -309.942     676.897\n",
       "x19 x20             0          0        nan        nan           0           0\n",
       "x19 x21             0          0        nan        nan           0           0\n",
       "x19 x22             0          0        nan        nan           0           0\n",
       "x19 x23      249.8106    256.537      0.974      0.330    -253.086     752.708\n",
       "x19 x24     1043.0448    367.159      2.841      0.005     323.293    1762.797\n",
       "x19 x25    -1319.0629    489.401     -2.695      0.007   -2278.451    -359.675\n",
       "x19 x26      614.6036    391.791      1.569      0.117    -153.436    1382.644\n",
       "x19 x27     -424.1569    406.933     -1.042      0.297   -1221.881     373.567\n",
       "x19 x28     -635.2968    430.149     -1.477      0.140   -1478.531     207.938\n",
       "x19 x29     -874.1726    467.689     -1.869      0.062   -1790.997      42.651\n",
       "x19 x30      870.1385    452.384      1.923      0.054     -16.683    1756.961\n",
       "x19 x31     -624.7497    605.390     -1.032      0.302   -1811.514     562.015\n",
       "x19 x32     -399.6663    303.403     -1.317      0.188    -994.436     195.103\n",
       "x19 x33     -626.2723    213.049     -2.940      0.003   -1043.919    -208.625\n",
       "x19 x34     -206.0668    365.698     -0.563      0.573    -922.956     510.822\n",
       "x19 x35     -189.3152    269.190     -0.703      0.482    -717.016     338.385\n",
       "x19 x36      149.2703    309.207      0.483      0.629    -456.878     755.419\n",
       "x19 x37      492.1978    372.324      1.322      0.186    -237.680    1222.075\n",
       "x19 x38      249.8106    256.537      0.974      0.330    -253.086     752.708\n",
       "x20 x21             0          0        nan        nan           0           0\n",
       "x20 x22             0          0        nan        nan           0           0\n",
       "x20 x23      203.5391    273.015      0.746      0.456    -331.661     738.739\n",
       "x20 x24      853.6468    368.503      2.317      0.021     131.258    1576.035\n",
       "x20 x25    -1729.1695    491.340     -3.519      0.000   -2692.357    -765.982\n",
       "x20 x26     1117.6105    411.500      2.716      0.007     310.935    1924.287\n",
       "x20 x27        1.8612    407.558      0.005      0.996    -797.086     800.809\n",
       "x20 x28     -660.7723    433.789     -1.523      0.128   -1511.141     189.597\n",
       "x20 x29     -753.7424    470.292     -1.603      0.109   -1675.670     168.186\n",
       "x20 x30      512.8443    468.786      1.094      0.274    -406.131    1431.820\n",
       "x20 x31     -589.1986    613.197     -0.961      0.337   -1791.267     612.870\n",
       "x20 x32     -169.7193    299.062     -0.568      0.570    -755.980     416.541\n",
       "x20 x33     -669.2872    213.337     -3.137      0.002   -1087.498    -251.076\n",
       "x20 x34     -285.7551    357.907     -0.798      0.425    -987.371     415.861\n",
       "x20 x35     -146.0667    275.984     -0.529      0.597    -687.087     394.954\n",
       "x20 x36       96.0211    295.660      0.325      0.745    -483.569     675.612\n",
       "x20 x37      468.8223    361.698      1.296      0.195    -240.225    1177.870\n",
       "x20 x38      203.5391    273.015      0.746      0.456    -331.661     738.739\n",
       "x21 x22             0          0        nan        nan           0           0\n",
       "x21 x23      342.6487    284.955      1.202      0.229    -215.956     901.254\n",
       "x21 x24      767.1216    377.660      2.031      0.042      26.783    1507.460\n",
       "x21 x25    -1505.3526    542.388     -2.775      0.006   -2568.611    -442.094\n",
       "x21 x26      877.5553    410.451      2.138      0.033      72.936    1682.175\n",
       "x21 x27      105.0241    436.030      0.241      0.810    -749.739     959.787\n",
       "x21 x28     -669.3362    453.195     -1.477      0.140   -1557.748     219.076\n",
       "x21 x29     -928.0325    492.100     -1.886      0.059   -1892.711      36.646\n",
       "x21 x30      582.8877    477.482      1.221      0.222    -353.135    1518.910\n",
       "x21 x31     -433.9746    735.830     -0.590      0.555   -1876.445    1008.496\n",
       "x21 x32     -228.2516    334.104     -0.683      0.495    -883.206     426.703\n",
       "x21 x33     -524.4026    229.473     -2.285      0.022    -974.245     -74.560\n",
       "x21 x34     -252.2368    418.562     -0.603      0.547   -1072.756     568.283\n",
       "x21 x35       18.5756    280.360      0.066      0.947    -531.023     568.174\n",
       "x21 x36      157.8998    351.159      0.450      0.653    -530.488     846.288\n",
       "x21 x37      441.9513    430.434      1.027      0.305    -401.842    1285.745\n",
       "x21 x38      342.6487    284.955      1.202      0.229    -215.956     901.254\n",
       "x22 x23      577.5348    283.619      2.036      0.042      21.548    1133.521\n",
       "x22 x24      704.8307    381.323      1.848      0.065     -42.688    1452.349\n",
       "x22 x25    -2020.1988    540.384     -3.738      0.000   -3079.530    -960.868\n",
       "x22 x26     1324.2792    419.305      3.158      0.002     502.304    2146.255\n",
       "x22 x27      541.7313    433.746      1.249      0.212    -308.554    1392.016\n",
       "x22 x28     -792.5134    472.139     -1.679      0.093   -1718.061     133.035\n",
       "x22 x29     -461.5687    496.134     -0.930      0.352   -1434.155     511.017\n",
       "x22 x30       39.5505    488.549      0.081      0.935    -918.167     997.268\n",
       "x22 x31     -905.7425    622.168     -1.456      0.146   -2125.396     313.911\n",
       "x22 x32     -218.4600    309.544     -0.706      0.480    -825.269     388.349\n",
       "x22 x33     -471.5323    225.417     -2.092      0.036    -913.423     -29.641\n",
       "x22 x34      -84.9457    373.184     -0.228      0.820    -816.510     646.619\n",
       "x22 x35     -211.2316    288.714     -0.732      0.464    -777.207     354.743\n",
       "x22 x36     -202.3205    320.192     -0.632      0.527    -830.003     425.362\n",
       "x22 x37      101.1927    385.567      0.262      0.793    -654.646     857.031\n",
       "x22 x38      577.5348    283.619      2.036      0.042      21.548    1133.521\n",
       "x23 x24             0          0        nan        nan           0           0\n",
       "x23 x25             0          0        nan        nan           0           0\n",
       "x23 x26             0          0        nan        nan           0           0\n",
       "x23 x27             0          0        nan        nan           0           0\n",
       "x23 x28             0          0        nan        nan           0           0\n",
       "x23 x29             0          0        nan        nan           0           0\n",
       "x23 x30             0          0        nan        nan           0           0\n",
       "x23 x31             0          0        nan        nan           0           0\n",
       "x23 x32    -2.761e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x23 x33             0          0        nan        nan           0           0\n",
       "x23 x34    -2.761e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x23 x35             0          0        nan        nan           0           0\n",
       "x23 x36             0          0        nan        nan           0           0\n",
       "x23 x37             0          0        nan        nan           0           0\n",
       "x23 x38    -2.761e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x24 x25             0          0        nan        nan           0           0\n",
       "x24 x26             0          0        nan        nan           0           0\n",
       "x24 x27             0          0        nan        nan           0           0\n",
       "x24 x28             0          0        nan        nan           0           0\n",
       "x24 x29             0          0        nan        nan           0           0\n",
       "x24 x30             0          0        nan        nan           0           0\n",
       "x24 x31             0          0        nan        nan           0           0\n",
       "x24 x32             0          0        nan        nan           0           0\n",
       "x24 x33             0          0        nan        nan           0           0\n",
       "x24 x34       -0.0002      0.000     -1.965      0.050      -0.000   -4.43e-07\n",
       "x24 x35             0          0        nan        nan           0           0\n",
       "x24 x36       -0.0002      0.000     -1.965      0.050      -0.000   -4.43e-07\n",
       "x24 x37             0          0        nan        nan           0           0\n",
       "x24 x38             0          0        nan        nan           0           0\n",
       "x25 x26             0          0        nan        nan           0           0\n",
       "x25 x27             0          0        nan        nan           0           0\n",
       "x25 x28             0          0        nan        nan           0           0\n",
       "x25 x29             0          0        nan        nan           0           0\n",
       "x25 x30             0          0        nan        nan           0           0\n",
       "x25 x31             0          0        nan        nan           0           0\n",
       "x25 x32             0          0        nan        nan           0           0\n",
       "x25 x33        0.0005      0.000      3.687      0.000       0.000       0.001\n",
       "x25 x34             0          0        nan        nan           0           0\n",
       "x25 x35             0          0        nan        nan           0           0\n",
       "x25 x36        0.0005      0.000      3.687      0.000       0.000       0.001\n",
       "x25 x37             0          0        nan        nan           0           0\n",
       "x25 x38             0          0        nan        nan           0           0\n",
       "x26 x27             0          0        nan        nan           0           0\n",
       "x26 x28             0          0        nan        nan           0           0\n",
       "x26 x29             0          0        nan        nan           0           0\n",
       "x26 x30             0          0        nan        nan           0           0\n",
       "x26 x31             0          0        nan        nan           0           0\n",
       "x26 x32       -0.0002      0.000     -1.255      0.210      -0.000    8.85e-05\n",
       "x26 x33             0          0        nan        nan           0           0\n",
       "x26 x34             0          0        nan        nan           0           0\n",
       "x26 x35             0          0        nan        nan           0           0\n",
       "x26 x36       -0.0002      0.000     -1.255      0.210      -0.000    8.85e-05\n",
       "x26 x37             0          0        nan        nan           0           0\n",
       "x26 x38             0          0        nan        nan           0           0\n",
       "x27 x28             0          0        nan        nan           0           0\n",
       "x27 x29             0          0        nan        nan           0           0\n",
       "x27 x30             0          0        nan        nan           0           0\n",
       "x27 x31             0          0        nan        nan           0           0\n",
       "x27 x32             0          0        nan        nan           0           0\n",
       "x27 x33     7.987e-05      0.000      0.674      0.500      -0.000       0.000\n",
       "x27 x34             0          0        nan        nan           0           0\n",
       "x27 x35     7.987e-05      0.000      0.674      0.500      -0.000       0.000\n",
       "x27 x36     7.987e-05      0.000      0.674      0.500      -0.000       0.000\n",
       "x27 x37             0          0        nan        nan           0           0\n",
       "x27 x38             0          0        nan        nan           0           0\n",
       "x28 x29             0          0        nan        nan           0           0\n",
       "x28 x30             0          0        nan        nan           0           0\n",
       "x28 x31             0          0        nan        nan           0           0\n",
       "x28 x32    -2.744e-05      0.000     -0.219      0.826      -0.000       0.000\n",
       "x28 x33             0          0        nan        nan           0           0\n",
       "x28 x34             0          0        nan        nan           0           0\n",
       "x28 x35    -2.744e-05      0.000     -0.219      0.826      -0.000       0.000\n",
       "x28 x36    -2.744e-05      0.000     -0.219      0.826      -0.000       0.000\n",
       "x28 x37             0          0        nan        nan           0           0\n",
       "x28 x38             0          0        nan        nan           0           0\n",
       "x29 x30             0          0        nan        nan           0           0\n",
       "x29 x31             0          0        nan        nan           0           0\n",
       "x29 x32     9.152e-05      0.000      0.602      0.547      -0.000       0.000\n",
       "x29 x33             0          0        nan        nan           0           0\n",
       "x29 x34     9.152e-05      0.000      0.602      0.547      -0.000       0.000\n",
       "x29 x35             0          0        nan        nan           0           0\n",
       "x29 x36             0          0        nan        nan           0           0\n",
       "x29 x37             0          0        nan        nan           0           0\n",
       "x29 x38             0          0        nan        nan           0           0\n",
       "x30 x31             0          0        nan        nan           0           0\n",
       "x30 x32       -0.0001      0.000     -0.837      0.403      -0.000       0.000\n",
       "x30 x33             0          0        nan        nan           0           0\n",
       "x30 x34             0          0        nan        nan           0           0\n",
       "x30 x35       -0.0001      0.000     -0.837      0.403      -0.000       0.000\n",
       "x30 x36       -0.0001      0.000     -0.837      0.403      -0.000       0.000\n",
       "x30 x37             0          0        nan        nan           0           0\n",
       "x30 x38             0          0        nan        nan           0           0\n",
       "x31 x32        0.0002      0.000      1.187      0.235      -0.000       0.001\n",
       "x31 x33             0          0        nan        nan           0           0\n",
       "x31 x34        0.0002      0.000      1.187      0.235      -0.000       0.001\n",
       "x31 x35             0          0        nan        nan           0           0\n",
       "x31 x36             0          0        nan        nan           0           0\n",
       "x31 x37        0.0002      0.000      1.187      0.235      -0.000       0.001\n",
       "x31 x38             0          0        nan        nan           0           0\n",
       "x32 x33             0          0        nan        nan           0           0\n",
       "x32 x34        0.0003      0.000      2.072      0.038    1.52e-05       0.001\n",
       "x32 x35       -0.0001      0.000     -1.166      0.244      -0.000    9.32e-05\n",
       "x32 x36       -0.0003      0.000     -2.521      0.012      -0.001   -6.54e-05\n",
       "x32 x37        0.0002      0.000      1.187      0.235      -0.000       0.001\n",
       "x32 x38    -2.761e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x33 x34             0          0        nan        nan           0           0\n",
       "x33 x35     7.987e-05      0.000      0.674      0.500      -0.000       0.000\n",
       "x33 x36        0.0006      0.000      3.351      0.001       0.000       0.001\n",
       "x33 x37       -0.0004      0.000     -1.666      0.096      -0.001    6.55e-05\n",
       "x33 x38             0          0        nan        nan           0           0\n",
       "x34 x35             0          0        nan        nan           0           0\n",
       "x34 x36       -0.0002      0.000     -1.965      0.050      -0.000   -4.43e-07\n",
       "x34 x37        0.0002      0.000      1.187      0.235      -0.000       0.001\n",
       "x34 x38    -2.761e-05   7.67e-05     -0.360      0.719      -0.000       0.000\n",
       "x35 x36    -5.693e-05    7.4e-05     -0.769      0.442      -0.000    8.82e-05\n",
       "x35 x37             0          0        nan        nan           0           0\n",
       "x35 x38             0          0        nan        nan           0           0\n",
       "x36 x37             0          0        nan        nan           0           0\n",
       "x36 x38             0          0        nan        nan           0           0\n",
       "x37 x38             0          0        nan        nan           0           0\n",
       "==============================================================================\n",
       "Omnibus:                      621.905   Durbin-Watson:                   1.982\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2206.822\n",
       "Skew:                           0.428   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.652   Cond. No.                     8.56e+20\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.88e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_c=sm.add_constant(inp_pf)\n",
    "ols_pf=sm.OLS(np.asarray(out),inp_c)\n",
    "mod_pf=ols_pf.fit()\n",
    "mod_pf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1294: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final features trough backward eliminations are : Index(['x27', 'x0 x3', 'x0 x25', 'x0 x26', 'x0 x34', 'x0 x35', 'x1 x22',\n",
      "       'x2 x3', 'x2 x6', 'x2 x22',\n",
      "       ...\n",
      "       'x32 x33', 'x33 x34', 'x33 x35', 'x33 x38', 'x34 x35', 'x35 x37',\n",
      "       'x35 x38', 'x36 x37', 'x36 x38', 'x37 x38'],\n",
      "      dtype='object', length=142)\n"
     ]
    }
   ],
   "source": [
    "while(len(inp_pf.columns)>0):\n",
    "    inp_c=sm.add_constant(inp_pf)\n",
    "    ols_pf=sm.OLS(np.asarray(out),inp_c)\n",
    "    mod_pf=ols_pf.fit()\n",
    "    f=mod_pf.pvalues[1:].idxmax()\n",
    "    if mod_pf.pvalues[1:].max()>0.05:\n",
    "        inp_pf=inp_pf.drop(f,1)\n",
    "    else:\n",
    "        break\n",
    "print('The final features trough backward eliminations are :',inp_pf.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.615</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   232.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 May 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:28:25</td>     <th>  Log-Likelihood:    </th> <td> -57086.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6818</td>      <th>  AIC:               </th> <td>1.143e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6770</td>      <th>  BIC:               </th> <td>1.146e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    47</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>  -33.0762</td> <td>   56.266</td> <td>   -0.588</td> <td> 0.557</td> <td> -143.376</td> <td>   77.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>     <td>   -0.0007</td> <td>    0.000</td> <td>   -5.431</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x3</th>   <td>   -0.1165</td> <td>    0.021</td> <td>   -5.529</td> <td> 0.000</td> <td>   -0.158</td> <td>   -0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x25</th>  <td>  221.1866</td> <td>   41.241</td> <td>    5.363</td> <td> 0.000</td> <td>  140.341</td> <td>  302.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x26</th>  <td>  224.8823</td> <td>   42.630</td> <td>    5.275</td> <td> 0.000</td> <td>  141.314</td> <td>  308.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x34</th>  <td>  230.4870</td> <td>   42.295</td> <td>    5.450</td> <td> 0.000</td> <td>  147.576</td> <td>  313.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0 x35</th>  <td>  233.5677</td> <td>   42.467</td> <td>    5.500</td> <td> 0.000</td> <td>  150.319</td> <td>  316.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1 x22</th>  <td> 4354.1490</td> <td> 2213.655</td> <td>    1.967</td> <td> 0.049</td> <td>   14.690</td> <td> 8693.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x3</th>   <td>   -0.0876</td> <td>    0.016</td> <td>   -5.547</td> <td> 0.000</td> <td>   -0.119</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x6</th>   <td>   -2.2226</td> <td>    0.729</td> <td>   -3.049</td> <td> 0.002</td> <td>   -3.651</td> <td>   -0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x22</th>  <td>    4.3793</td> <td>    1.929</td> <td>    2.271</td> <td> 0.023</td> <td>    0.598</td> <td>    8.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x23</th>  <td>    4.4860</td> <td>    0.193</td> <td>   23.230</td> <td> 0.000</td> <td>    4.107</td> <td>    4.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x26</th>  <td>  192.2459</td> <td>   31.559</td> <td>    6.092</td> <td> 0.000</td> <td>  130.380</td> <td>  254.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x27</th>  <td> -189.2924</td> <td>   31.526</td> <td>   -6.004</td> <td> 0.000</td> <td> -251.094</td> <td> -127.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x28</th>  <td>   -1.6722</td> <td>    0.368</td> <td>   -4.545</td> <td> 0.000</td> <td>   -2.393</td> <td>   -0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x33</th>  <td>  189.6427</td> <td>   31.472</td> <td>    6.026</td> <td> 0.000</td> <td>  127.947</td> <td>  251.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x34</th>  <td>  190.5897</td> <td>   31.548</td> <td>    6.041</td> <td> 0.000</td> <td>  128.746</td> <td>  252.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x35</th>  <td>  192.6862</td> <td>   31.683</td> <td>    6.082</td> <td> 0.000</td> <td>  130.577</td> <td>  254.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x37</th>  <td>  -13.0188</td> <td>    0.351</td> <td>  -37.113</td> <td> 0.000</td> <td>  -13.706</td> <td>  -12.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2 x38</th>  <td>    4.4860</td> <td>    0.193</td> <td>   23.230</td> <td> 0.000</td> <td>    4.107</td> <td>    4.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x22</th>  <td>   -0.4835</td> <td>    0.203</td> <td>   -2.378</td> <td> 0.017</td> <td>   -0.882</td> <td>   -0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x27</th>  <td>   -1.4814</td> <td>    0.273</td> <td>   -5.430</td> <td> 0.000</td> <td>   -2.016</td> <td>   -0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3 x33</th>  <td>    1.4596</td> <td>    0.269</td> <td>    5.431</td> <td> 0.000</td> <td>    0.933</td> <td>    1.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4 x25</th>  <td> -972.4314</td> <td>  288.539</td> <td>   -3.370</td> <td> 0.001</td> <td>-1538.058</td> <td> -406.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5 x25</th>  <td> -856.3429</td> <td>  291.110</td> <td>   -2.942</td> <td> 0.003</td> <td>-1427.011</td> <td> -285.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x10</th>  <td>  427.5496</td> <td>  178.395</td> <td>    2.397</td> <td> 0.017</td> <td>   77.839</td> <td>  777.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x11</th>  <td>  593.5823</td> <td>  265.567</td> <td>    2.235</td> <td> 0.025</td> <td>   72.987</td> <td> 1114.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x25</th>  <td> -869.7098</td> <td>  354.006</td> <td>   -2.457</td> <td> 0.014</td> <td>-1563.673</td> <td> -175.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6 x32</th>  <td>  283.1968</td> <td>  128.727</td> <td>    2.200</td> <td> 0.028</td> <td>   30.851</td> <td>  535.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x23</th>  <td> -518.3083</td> <td>  235.795</td> <td>   -2.198</td> <td> 0.028</td> <td> -980.540</td> <td>  -56.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7 x38</th>  <td> -518.3083</td> <td>  235.795</td> <td>   -2.198</td> <td> 0.028</td> <td> -980.540</td> <td>  -56.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x23</th>  <td>  204.4283</td> <td>   55.061</td> <td>    3.713</td> <td> 0.000</td> <td>   96.491</td> <td>  312.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x25</th>  <td>-1668.3365</td> <td>  441.600</td> <td>   -3.778</td> <td> 0.000</td> <td>-2534.012</td> <td> -802.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8 x38</th>  <td>  204.4283</td> <td>   55.061</td> <td>    3.713</td> <td> 0.000</td> <td>   96.491</td> <td>  312.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9 x25</th>  <td>-1672.1293</td> <td>  444.312</td> <td>   -3.763</td> <td> 0.000</td> <td>-2543.120</td> <td> -801.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x25</th> <td>-1938.6397</td> <td>  448.075</td> <td>   -4.327</td> <td> 0.000</td> <td>-2817.007</td> <td>-1060.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10 x26</th> <td>  306.2891</td> <td>  127.490</td> <td>    2.402</td> <td> 0.016</td> <td>   56.369</td> <td>  556.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11 x25</th> <td>-1594.7837</td> <td>  444.573</td> <td>   -3.587</td> <td> 0.000</td> <td>-2466.286</td> <td> -723.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12 x25</th> <td>-1785.7743</td> <td>  451.979</td> <td>   -3.951</td> <td> 0.000</td> <td>-2671.795</td> <td> -899.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13 x25</th> <td>-1378.2419</td> <td>  450.442</td> <td>   -3.060</td> <td> 0.002</td> <td>-2261.251</td> <td> -495.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x25</th> <td>-1464.8639</td> <td>  451.986</td> <td>   -3.241</td> <td> 0.001</td> <td>-2350.898</td> <td> -578.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14 x30</th> <td>  309.2281</td> <td>  140.634</td> <td>    2.199</td> <td> 0.028</td> <td>   33.542</td> <td>  584.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15 x25</th> <td>-1531.6648</td> <td>  462.730</td> <td>   -3.310</td> <td> 0.001</td> <td>-2438.762</td> <td> -624.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16 x25</th> <td>-1823.3881</td> <td>  464.437</td> <td>   -3.926</td> <td> 0.000</td> <td>-2733.831</td> <td> -912.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17 x25</th> <td>-1885.4766</td> <td>  465.070</td> <td>   -4.054</td> <td> 0.000</td> <td>-2797.160</td> <td> -973.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18 x25</th> <td>-1445.5536</td> <td>  485.803</td> <td>   -2.976</td> <td> 0.003</td> <td>-2397.880</td> <td> -493.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19 x25</th> <td>-1536.2147</td> <td>  500.905</td> <td>   -3.067</td> <td> 0.002</td> <td>-2518.146</td> <td> -554.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x25</th> <td>-2077.5659</td> <td>  523.524</td> <td>   -3.968</td> <td> 0.000</td> <td>-3103.837</td> <td>-1051.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20 x26</th> <td>  616.3929</td> <td>  306.582</td> <td>    2.011</td> <td> 0.044</td> <td>   15.395</td> <td> 1217.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x22</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21 x25</th> <td>-1779.4304</td> <td>  533.718</td> <td>   -3.334</td> <td> 0.001</td> <td>-2825.686</td> <td> -733.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x23</th> <td>  377.8014</td> <td>  188.035</td> <td>    2.009</td> <td> 0.045</td> <td>    9.194</td> <td>  746.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x25</th> <td>-2044.0299</td> <td>  586.472</td> <td>   -3.485</td> <td> 0.000</td> <td>-3193.700</td> <td> -894.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22 x38</th> <td>  377.8014</td> <td>  188.035</td> <td>    2.009</td> <td> 0.045</td> <td>    9.194</td> <td>  746.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x24</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x25</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x26</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x36</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x25</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x26</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x32</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x26</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x32</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x27</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x28</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x32</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x33</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -5.430</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x35</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -5.430</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x36</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -5.430</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x29</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x30</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x36</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x31</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x36</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32 x33</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x34</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x35</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -5.430</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34 x35</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36 x37</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37 x38</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>650.723</td> <th>  Durbin-Watson:     </th> <td>   1.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2255.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.460</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.663</td>  <th>  Cond. No.          </th> <td>1.09e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.45e-18. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.617\n",
       "Model:                            OLS   Adj. R-squared:                  0.615\n",
       "Method:                 Least Squares   F-statistic:                     232.5\n",
       "Date:                Fri, 29 May 2020   Prob (F-statistic):               0.00\n",
       "Time:                        13:28:25   Log-Likelihood:                -57086.\n",
       "No. Observations:                6818   AIC:                         1.143e+05\n",
       "Df Residuals:                    6770   BIC:                         1.146e+05\n",
       "Df Model:                          47                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -33.0762     56.266     -0.588      0.557    -143.376      77.224\n",
       "x27           -0.0007      0.000     -5.431      0.000      -0.001      -0.000\n",
       "x0 x3         -0.1165      0.021     -5.529      0.000      -0.158      -0.075\n",
       "x0 x25       221.1866     41.241      5.363      0.000     140.341     302.032\n",
       "x0 x26       224.8823     42.630      5.275      0.000     141.314     308.450\n",
       "x0 x34       230.4870     42.295      5.450      0.000     147.576     313.398\n",
       "x0 x35       233.5677     42.467      5.500      0.000     150.319     316.816\n",
       "x1 x22      4354.1490   2213.655      1.967      0.049      14.690    8693.608\n",
       "x2 x3         -0.0876      0.016     -5.547      0.000      -0.119      -0.057\n",
       "x2 x6         -2.2226      0.729     -3.049      0.002      -3.651      -0.794\n",
       "x2 x22         4.3793      1.929      2.271      0.023       0.598       8.160\n",
       "x2 x23         4.4860      0.193     23.230      0.000       4.107       4.865\n",
       "x2 x26       192.2459     31.559      6.092      0.000     130.380     254.112\n",
       "x2 x27      -189.2924     31.526     -6.004      0.000    -251.094    -127.491\n",
       "x2 x28        -1.6722      0.368     -4.545      0.000      -2.393      -0.951\n",
       "x2 x33       189.6427     31.472      6.026      0.000     127.947     251.338\n",
       "x2 x34       190.5897     31.548      6.041      0.000     128.746     252.433\n",
       "x2 x35       192.6862     31.683      6.082      0.000     130.577     254.796\n",
       "x2 x37       -13.0188      0.351    -37.113      0.000     -13.706     -12.331\n",
       "x2 x38         4.4860      0.193     23.230      0.000       4.107       4.865\n",
       "x3 x22        -0.4835      0.203     -2.378      0.017      -0.882      -0.085\n",
       "x3 x27        -1.4814      0.273     -5.430      0.000      -2.016      -0.947\n",
       "x3 x33         1.4596      0.269      5.431      0.000       0.933       1.987\n",
       "x4 x25      -972.4314    288.539     -3.370      0.001   -1538.058    -406.805\n",
       "x5 x25      -856.3429    291.110     -2.942      0.003   -1427.011    -285.675\n",
       "x6 x10       427.5496    178.395      2.397      0.017      77.839     777.260\n",
       "x6 x11       593.5823    265.567      2.235      0.025      72.987    1114.177\n",
       "x6 x25      -869.7098    354.006     -2.457      0.014   -1563.673    -175.747\n",
       "x6 x32       283.1968    128.727      2.200      0.028      30.851     535.543\n",
       "x7 x23      -518.3083    235.795     -2.198      0.028    -980.540     -56.076\n",
       "x7 x38      -518.3083    235.795     -2.198      0.028    -980.540     -56.076\n",
       "x8 x23       204.4283     55.061      3.713      0.000      96.491     312.366\n",
       "x8 x25     -1668.3365    441.600     -3.778      0.000   -2534.012    -802.661\n",
       "x8 x38       204.4283     55.061      3.713      0.000      96.491     312.366\n",
       "x9 x25     -1672.1293    444.312     -3.763      0.000   -2543.120    -801.139\n",
       "x10 x25    -1938.6397    448.075     -4.327      0.000   -2817.007   -1060.272\n",
       "x10 x26      306.2891    127.490      2.402      0.016      56.369     556.209\n",
       "x11 x25    -1594.7837    444.573     -3.587      0.000   -2466.286    -723.281\n",
       "x12 x25    -1785.7743    451.979     -3.951      0.000   -2671.795    -899.754\n",
       "x13 x25    -1378.2419    450.442     -3.060      0.002   -2261.251    -495.233\n",
       "x14 x25    -1464.8639    451.986     -3.241      0.001   -2350.898    -578.830\n",
       "x14 x30      309.2281    140.634      2.199      0.028      33.542     584.914\n",
       "x15 x25    -1531.6648    462.730     -3.310      0.001   -2438.762    -624.568\n",
       "x16 x25    -1823.3881    464.437     -3.926      0.000   -2733.831    -912.945\n",
       "x17 x25    -1885.4766    465.070     -4.054      0.000   -2797.160    -973.793\n",
       "x18 x25    -1445.5536    485.803     -2.976      0.003   -2397.880    -493.227\n",
       "x19 x25    -1536.2147    500.905     -3.067      0.002   -2518.146    -554.283\n",
       "x20 x25    -2077.5659    523.524     -3.968      0.000   -3103.837   -1051.295\n",
       "x20 x26      616.3929    306.582      2.011      0.044      15.395    1217.391\n",
       "x21 x22             0          0        nan        nan           0           0\n",
       "x21 x25    -1779.4304    533.718     -3.334      0.001   -2825.686    -733.175\n",
       "x22 x23      377.8014    188.035      2.009      0.045       9.194     746.408\n",
       "x22 x25    -2044.0299    586.472     -3.485      0.000   -3193.700    -894.359\n",
       "x22 x38      377.8014    188.035      2.009      0.045       9.194     746.408\n",
       "x23 x24             0          0        nan        nan           0           0\n",
       "x23 x25             0          0        nan        nan           0           0\n",
       "x23 x26             0          0        nan        nan           0           0\n",
       "x23 x27             0          0        nan        nan           0           0\n",
       "x23 x28             0          0        nan        nan           0           0\n",
       "x23 x29             0          0        nan        nan           0           0\n",
       "x23 x30             0          0        nan        nan           0           0\n",
       "x23 x31             0          0        nan        nan           0           0\n",
       "x23 x33             0          0        nan        nan           0           0\n",
       "x23 x35             0          0        nan        nan           0           0\n",
       "x23 x36             0          0        nan        nan           0           0\n",
       "x23 x37             0          0        nan        nan           0           0\n",
       "x24 x25             0          0        nan        nan           0           0\n",
       "x24 x26             0          0        nan        nan           0           0\n",
       "x24 x27             0          0        nan        nan           0           0\n",
       "x24 x28             0          0        nan        nan           0           0\n",
       "x24 x29             0          0        nan        nan           0           0\n",
       "x24 x30             0          0        nan        nan           0           0\n",
       "x24 x31             0          0        nan        nan           0           0\n",
       "x24 x32             0          0        nan        nan           0           0\n",
       "x24 x33             0          0        nan        nan           0           0\n",
       "x24 x35             0          0        nan        nan           0           0\n",
       "x24 x37             0          0        nan        nan           0           0\n",
       "x24 x38             0          0        nan        nan           0           0\n",
       "x25 x26             0          0        nan        nan           0           0\n",
       "x25 x27             0          0        nan        nan           0           0\n",
       "x25 x28             0          0        nan        nan           0           0\n",
       "x25 x29             0          0        nan        nan           0           0\n",
       "x25 x30             0          0        nan        nan           0           0\n",
       "x25 x31             0          0        nan        nan           0           0\n",
       "x25 x32             0          0        nan        nan           0           0\n",
       "x25 x34             0          0        nan        nan           0           0\n",
       "x25 x35             0          0        nan        nan           0           0\n",
       "x25 x37             0          0        nan        nan           0           0\n",
       "x25 x38             0          0        nan        nan           0           0\n",
       "x26 x27             0          0        nan        nan           0           0\n",
       "x26 x28             0          0        nan        nan           0           0\n",
       "x26 x29             0          0        nan        nan           0           0\n",
       "x26 x30             0          0        nan        nan           0           0\n",
       "x26 x31             0          0        nan        nan           0           0\n",
       "x26 x33             0          0        nan        nan           0           0\n",
       "x26 x34             0          0        nan        nan           0           0\n",
       "x26 x35             0          0        nan        nan           0           0\n",
       "x26 x37             0          0        nan        nan           0           0\n",
       "x26 x38             0          0        nan        nan           0           0\n",
       "x27 x28             0          0        nan        nan           0           0\n",
       "x27 x29             0          0        nan        nan           0           0\n",
       "x27 x30             0          0        nan        nan           0           0\n",
       "x27 x31             0          0        nan        nan           0           0\n",
       "x27 x32             0          0        nan        nan           0           0\n",
       "x27 x33       -0.0007      0.000     -5.430      0.000      -0.001      -0.000\n",
       "x27 x34             0          0        nan        nan           0           0\n",
       "x27 x35       -0.0007      0.000     -5.430      0.000      -0.001      -0.000\n",
       "x27 x36       -0.0007      0.000     -5.430      0.000      -0.001      -0.000\n",
       "x27 x37             0          0        nan        nan           0           0\n",
       "x27 x38             0          0        nan        nan           0           0\n",
       "x28 x29             0          0        nan        nan           0           0\n",
       "x28 x30             0          0        nan        nan           0           0\n",
       "x28 x31             0          0        nan        nan           0           0\n",
       "x28 x33             0          0        nan        nan           0           0\n",
       "x28 x34             0          0        nan        nan           0           0\n",
       "x28 x37             0          0        nan        nan           0           0\n",
       "x28 x38             0          0        nan        nan           0           0\n",
       "x29 x30             0          0        nan        nan           0           0\n",
       "x29 x31             0          0        nan        nan           0           0\n",
       "x29 x33             0          0        nan        nan           0           0\n",
       "x29 x35             0          0        nan        nan           0           0\n",
       "x29 x36             0          0        nan        nan           0           0\n",
       "x29 x37             0          0        nan        nan           0           0\n",
       "x29 x38             0          0        nan        nan           0           0\n",
       "x30 x31             0          0        nan        nan           0           0\n",
       "x30 x33             0          0        nan        nan           0           0\n",
       "x30 x34             0          0        nan        nan           0           0\n",
       "x30 x37             0          0        nan        nan           0           0\n",
       "x30 x38             0          0        nan        nan           0           0\n",
       "x31 x33             0          0        nan        nan           0           0\n",
       "x31 x35             0          0        nan        nan           0           0\n",
       "x31 x36             0          0        nan        nan           0           0\n",
       "x31 x38             0          0        nan        nan           0           0\n",
       "x32 x33             0          0        nan        nan           0           0\n",
       "x33 x34             0          0        nan        nan           0           0\n",
       "x33 x35       -0.0007      0.000     -5.430      0.000      -0.001      -0.000\n",
       "x33 x38             0          0        nan        nan           0           0\n",
       "x34 x35             0          0        nan        nan           0           0\n",
       "x35 x37             0          0        nan        nan           0           0\n",
       "x35 x38             0          0        nan        nan           0           0\n",
       "x36 x37             0          0        nan        nan           0           0\n",
       "x36 x38             0          0        nan        nan           0           0\n",
       "x37 x38             0          0        nan        nan           0           0\n",
       "==============================================================================\n",
       "Omnibus:                      650.723   Durbin-Watson:                   1.985\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2255.171\n",
       "Skew:                           0.460   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.663   Cond. No.                     1.09e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.45e-18. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['x27', 'x0 x3', 'x0 x25', 'x0 x26', 'x0 x34', 'x0 x35', 'x1 x22',\\n       'x2 x3', 'x2 x6', 'x2 x22',\\n       ...\\n       'x32 x33', 'x33 x34', 'x33 x35', 'x33 x38', 'x34 x35', 'x35 x37',\\n       'x35 x38', 'x36 x37', 'x36 x38', 'x37 x38'],\\n      dtype='object', length=142)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-c3beba56728f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# To check rmse on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_train_c\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp_pf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod_pf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['x27', 'x0 x3', 'x0 x25', 'x0 x26', 'x0 x34', 'x0 x35', 'x1 x22',\\n       'x2 x3', 'x2 x6', 'x2 x22',\\n       ...\\n       'x32 x33', 'x33 x34', 'x33 x35', 'x33 x38', 'x34 x35', 'x35 x37',\\n       'x35 x38', 'x36 x37', 'x36 x38', 'x37 x38'],\\n      dtype='object', length=142)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# To check rmse on test data\n",
    "x_train_c=sm.add_constant(x_train2[inp_pf.columns])\n",
    "ypred = mod_pf.predict(x_train_c)\n",
    "mean_squared_error(y_train2,ypred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# higher the alpha value, more restriction on the coefficients; \n",
    "# low alpha > more generalization, coefficients are barely\n",
    "rr = Ridge(alpha=0.01) \n",
    "# restricted and in this case linear and ridge regression resembles\n",
    "rr.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr100 = Ridge(alpha=100) #  comparison with alpha value\n",
    "rr100.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=lr.score(x_train1, y_train1)\n",
    "test_score=lr.score(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_train_score = rr.score(x_train1, y_train1)\n",
    "Ridge_test_score = rr.score(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_train_score100 = rr100.score(x_train1, y_train1)\n",
    "Ridge_test_score100 = rr100.score(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression train score: 0.5683080727948946\n",
      "linear regression test score: 0.5447693452658702\n",
      "ridge regression train score low alpha: 0.5683080707512216\n",
      "ridge regression test score low alpha: 0.5447713567620348\n",
      "ridge regression train score high alpha: 0.5668216617164752\n",
      "ridge regression test score high alpha: 0.5422938036288523\n"
     ]
    }
   ],
   "source": [
    "print(\"linear regression train score:\", train_score)\n",
    "print(\"linear regression test score:\", test_score)\n",
    "print(\"ridge regression train score low alpha:\", Ridge_train_score)\n",
    "print(\"ridge regression test score low alpha:\", Ridge_test_score)\n",
    "print(\"ridge regression train score high alpha:\", Ridge_train_score100)\n",
    "print(\"ridge regression test score high alpha:\", Ridge_test_score100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(x_train1, y_train1)\n",
    "train_score=lasso.score(x_train1, y_train1)\n",
    "test_score=lasso.score(x_train2, y_train2)\n",
    "coeff_used = np.sum(lasso.coef_!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.567906615285484\n",
      "test score:  0.5455658874940501\n",
      "number of features used:  20\n"
     ]
    }
   ],
   "source": [
    "print(\"training score:\", train_score )\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000000.0,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n",
    "lasso001.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score001=lasso001.score(x_train1, y_train1)\n",
    "test_score001=lasso001.score(x_train2, y_train2)\n",
    "coeff_used001 = np.sum(lasso001.coef_!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score for alpha=0.01: 0.5683069059154374\n",
      "test score for alpha =0.01:  0.5448175308135375\n",
      "number of features used: for alpha =0.01: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"training score for alpha=0.01:\", train_score001 )\n",
    "print(\"test score for alpha =0.01: \", test_score001)\n",
    "print(\"number of features used: for alpha =0.01:\", coeff_used001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.25, copy_X=True, fit_intercept=True, max_iter=1000000.0,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso00001 = Lasso(alpha=0.25, max_iter=10e5)\n",
    "lasso00001.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score00001=lasso00001.score(x_train1, y_train1)\n",
    "test_score00001=lasso00001.score(x_train2, y_train2)\n",
    "coeff_used00001 = np.sum(lasso00001.coef_!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score for alpha=0.1: 0.5681165993540657\n",
      "test score for alpha =0.1:  0.5453006679212355\n",
      "number of features used: for alpha =0.1: 29\n"
     ]
    }
   ],
   "source": [
    "print(\"training score for alpha=0.1:\", train_score00001 )\n",
    "print(\"test score for alpha =0.1: \", test_score00001)\n",
    "print(\"number of features used: for alpha =0.1:\", coeff_used00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr_train_score=lr.score(x_train1, y_train1)\n",
    "lr_test_score=lr.score(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR training score: 0.5675558828047655\n",
      "LR test score:  0.5467392964904358\n"
     ]
    }
   ],
   "source": [
    "print(\"LR training score:\", lr_train_score )\n",
    "print(\"LR test score: \", lr_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(x_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1182.8988355104357"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train2,pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Item_Outlet_Sales'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = test.drop('Item_Outlet_Sales',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "v['Item_Outlet_Sales'] = lr.predict(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = v['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 40)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681,)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat((pd.DataFrame(data = test_data,columns=['Item_Identifier','Outlet_Identifier']),pd.DataFrame(np.abs(r),columns=['Item_Outlet_Sales'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1878.716483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1376.987527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1935.070923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2630.702334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5032.299581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676</td>\n",
       "      <td>FDB58</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>2339.897866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5677</td>\n",
       "      <td>FDD47</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2502.588371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5678</td>\n",
       "      <td>NCO17</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1833.085692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5679</td>\n",
       "      <td>FDJ26</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>3597.719164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>FDU37</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1347.428028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0              FDW58            OUT049        1878.716483\n",
       "1              FDW14            OUT017        1376.987527\n",
       "2              NCN55            OUT010        1935.070923\n",
       "3              FDQ58            OUT017        2630.702334\n",
       "4              FDY38            OUT027        5032.299581\n",
       "...              ...               ...                ...\n",
       "5676           FDB58            OUT046        2339.897866\n",
       "5677           FDD47            OUT018        2502.588371\n",
       "5678           NCO17            OUT045        1833.085692\n",
       "5679           FDJ26            OUT017        3597.719164\n",
       "5680           FDU37            OUT045        1347.428028\n",
       "\n",
       "[5681 rows x 3 columns]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('mysubmission4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicteing on test data set\n",
    "\n",
    "test_predicted = lm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 39)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['Item_Outlet_Sales'] = test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 40)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat((pd.DataFrame(data = test_data,columns=['Item_Identifier','Outlet_Identifier']),pd.DataFrame(np.abs(test_pred),columns=['Item_Outlet_Sales'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1840.961654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1427.391080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1884.143821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2579.663596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5138.677736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676</td>\n",
       "      <td>FDB58</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>2307.120765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5677</td>\n",
       "      <td>FDD47</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2460.335252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5678</td>\n",
       "      <td>NCO17</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1823.347825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5679</td>\n",
       "      <td>FDJ26</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>3592.481551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>FDU37</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1287.685025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0              FDW58            OUT049        1840.961654\n",
       "1              FDW14            OUT017        1427.391080\n",
       "2              NCN55            OUT010        1884.143821\n",
       "3              FDQ58            OUT017        2579.663596\n",
       "4              FDY38            OUT027        5138.677736\n",
       "...              ...               ...                ...\n",
       "5676           FDB58            OUT046        2307.120765\n",
       "5677           FDD47            OUT018        2460.335252\n",
       "5678           NCO17            OUT045        1823.347825\n",
       "5679           FDJ26            OUT017        3592.481551\n",
       "5680           FDU37            OUT045        1287.685025\n",
       "\n",
       "[5681 rows x 3 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('mysubmission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building on entire train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 40)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train = train.drop('Item_Outlet_Sales',axis=1)\n",
    "y = y_train = train['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 39)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 39)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lm.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['Item_Outlet_Sales'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5681, 40)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.Max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Fat_Content_LF</th>\n",
       "      <th>Item_Fat_Content_reg</th>\n",
       "      <th>Item_Type_Fruits and Vegetables</th>\n",
       "      <th>Item_Type_Snack Foods</th>\n",
       "      <th>Item_Type_Household</th>\n",
       "      <th>Item_Type_Frozen Foods</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Health and Hygiene</th>\n",
       "      <th>Item_Type_Meat</th>\n",
       "      <th>Item_Type_Soft Drinks</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Hard Drinks</th>\n",
       "      <th>Item_Type_Others</th>\n",
       "      <th>Item_Type_Starchy Foods</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Outlet_Identifier_OUT027</th>\n",
       "      <th>Outlet_Identifier_OUT013</th>\n",
       "      <th>Outlet_Identifier_OUT049</th>\n",
       "      <th>Outlet_Identifier_OUT046</th>\n",
       "      <th>Outlet_Identifier_OUT035</th>\n",
       "      <th>Outlet_Identifier_OUT045</th>\n",
       "      <th>Outlet_Identifier_OUT018</th>\n",
       "      <th>Outlet_Identifier_OUT017</th>\n",
       "      <th>Outlet_Identifier_OUT010</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.750</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>107.8622</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1837.126305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.300</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>87.3198</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1429.833913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.600</td>\n",
       "      <td>0.099575</td>\n",
       "      <td>241.7538</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1883.760849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.315</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>155.0340</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2582.585868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12.600</td>\n",
       "      <td>0.118599</td>\n",
       "      <td>234.2300</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5138.774970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
       "0       20.750         0.007565  107.8622                       1999   \n",
       "1        8.300         0.038428   87.3198                       2007   \n",
       "2       14.600         0.099575  241.7538                       1998   \n",
       "3        7.315         0.015388  155.0340                       2007   \n",
       "4       12.600         0.118599  234.2300                       1985   \n",
       "\n",
       "   Item_Fat_Content_Low Fat  Item_Fat_Content_Regular  Item_Fat_Content_LF  \\\n",
       "0                         1                         0                    0   \n",
       "1                         0                         0                    0   \n",
       "2                         1                         0                    0   \n",
       "3                         1                         0                    0   \n",
       "4                         0                         1                    0   \n",
       "\n",
       "   Item_Fat_Content_reg  Item_Type_Fruits and Vegetables  \\\n",
       "0                     0                                0   \n",
       "1                     1                                0   \n",
       "2                     0                                0   \n",
       "3                     0                                0   \n",
       "4                     0                                0   \n",
       "\n",
       "   Item_Type_Snack Foods  Item_Type_Household  Item_Type_Frozen Foods  \\\n",
       "0                      1                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      1                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   Item_Type_Dairy  Item_Type_Baking Goods  Item_Type_Canned  \\\n",
       "0                0                       0                 0   \n",
       "1                1                       0                 0   \n",
       "2                0                       0                 0   \n",
       "3                0                       0                 0   \n",
       "4                1                       0                 0   \n",
       "\n",
       "   Item_Type_Health and Hygiene  Item_Type_Meat  Item_Type_Soft Drinks  \\\n",
       "0                             0               0                      0   \n",
       "1                             0               0                      0   \n",
       "2                             0               0                      0   \n",
       "3                             0               0                      0   \n",
       "4                             0               0                      0   \n",
       "\n",
       "   Item_Type_Breads  Item_Type_Hard Drinks  Item_Type_Others  \\\n",
       "0                 0                      0                 0   \n",
       "1                 0                      0                 0   \n",
       "2                 0                      0                 1   \n",
       "3                 0                      0                 0   \n",
       "4                 0                      0                 0   \n",
       "\n",
       "   Item_Type_Starchy Foods  Item_Type_Breakfast  Outlet_Identifier_OUT027  \\\n",
       "0                        0                    0                         0   \n",
       "1                        0                    0                         0   \n",
       "2                        0                    0                         0   \n",
       "3                        0                    0                         0   \n",
       "4                        0                    0                         1   \n",
       "\n",
       "   Outlet_Identifier_OUT013  Outlet_Identifier_OUT049  \\\n",
       "0                         0                         1   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   Outlet_Identifier_OUT046  Outlet_Identifier_OUT035  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   Outlet_Identifier_OUT045  Outlet_Identifier_OUT018  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   Outlet_Identifier_OUT017  Outlet_Identifier_OUT010  Outlet_Size_Medium  \\\n",
       "0                         0                         0                   1   \n",
       "1                         1                         0                   1   \n",
       "2                         0                         1                   1   \n",
       "3                         1                         0                   1   \n",
       "4                         0                         0                   1   \n",
       "\n",
       "   Outlet_Size_Small  Outlet_Location_Type_Tier 3  \\\n",
       "0                  0                            0   \n",
       "1                  0                            0   \n",
       "2                  0                            1   \n",
       "3                  0                            0   \n",
       "4                  0                            1   \n",
       "\n",
       "   Outlet_Location_Type_Tier 2  Outlet_Type_Supermarket Type1  \\\n",
       "0                            0                              1   \n",
       "1                            1                              1   \n",
       "2                            0                              0   \n",
       "3                            1                              1   \n",
       "4                            0                              0   \n",
       "\n",
       "   Outlet_Type_Grocery Store  Outlet_Type_Supermarket Type3  Item_Outlet_Sales  \n",
       "0                          0                              0        1837.126305  \n",
       "1                          0                              0        1429.833913  \n",
       "2                          1                              0        1883.760849  \n",
       "3                          0                              0        2582.585868  \n",
       "4                          0                              1        5138.774970  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat((pd.DataFrame(data = test_data,columns=['Item_Identifier','Outlet_Identifier']),pd.DataFrame(np.abs(test_pred),columns=['Item_Outlet_Sales'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1837.126305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1429.833913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1883.760849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2582.585868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5138.774970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676</td>\n",
       "      <td>FDB58</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>2308.244149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5677</td>\n",
       "      <td>FDD47</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2463.213448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5678</td>\n",
       "      <td>NCO17</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1824.749487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5679</td>\n",
       "      <td>FDJ26</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>3590.933270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>FDU37</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1288.842940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0              FDW58            OUT049        1837.126305\n",
       "1              FDW14            OUT017        1429.833913\n",
       "2              NCN55            OUT010        1883.760849\n",
       "3              FDQ58            OUT017        2582.585868\n",
       "4              FDY38            OUT027        5138.774970\n",
       "...              ...               ...                ...\n",
       "5676           FDB58            OUT046        2308.244149\n",
       "5677           FDD47            OUT018        2463.213448\n",
       "5678           NCO17            OUT045        1824.749487\n",
       "5679           FDJ26            OUT017        3590.933270\n",
       "5680           FDU37            OUT045        1288.842940\n",
       "\n",
       "[5681 rows x 3 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('mysubmission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lm.predict(test)\n",
    "test['Item_Outlet_Sales'] = test_pred\n",
    "d = pd.concat((pd.DataFrame(data = test_data,columns=['Item_Identifier','Outlet_Identifier']),pd.DataFrame(np.abs(test_pred),columns=['Item_Outlet_Sales'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lm.predict(test)\n",
    "test['Item_Outlet_Sales'] = test_pred\n",
    "d.to_csv('mysubmission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 with rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 40)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 39)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523,)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 37\n",
      "Score with 37 features: 0.562341\n"
     ]
    }
   ],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,40)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year',\n",
      "       'Item_Fat_Content_Low Fat', 'Item_Fat_Content_LF',\n",
      "       'Item_Fat_Content_reg', 'Item_Type_Fruits and Vegetables',\n",
      "       'Item_Type_Snack Foods', 'Item_Type_Household',\n",
      "       'Item_Type_Frozen Foods', 'Item_Type_Dairy', 'Item_Type_Baking Goods',\n",
      "       'Item_Type_Canned', 'Item_Type_Health and Hygiene', 'Item_Type_Meat',\n",
      "       'Item_Type_Soft Drinks', 'Item_Type_Breads', 'Item_Type_Hard Drinks',\n",
      "       'Item_Type_Others', 'Item_Type_Starchy Foods', 'Item_Type_Breakfast',\n",
      "       'Outlet_Identifier_OUT027', 'Outlet_Identifier_OUT013',\n",
      "       'Outlet_Identifier_OUT049', 'Outlet_Identifier_OUT046',\n",
      "       'Outlet_Identifier_OUT035', 'Outlet_Identifier_OUT045',\n",
      "       'Outlet_Identifier_OUT018', 'Outlet_Identifier_OUT017',\n",
      "       'Outlet_Identifier_OUT010', 'Outlet_Size_Medium', 'Outlet_Size_Small',\n",
      "       'Outlet_Location_Type_Tier 3', 'Outlet_Location_Type_Tier 2',\n",
      "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Grocery Store',\n",
      "       'Outlet_Type_Supermarket Type3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "model = LinearRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 37)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year',\n",
       "       'Item_Fat_Content_Low Fat', 'Item_Fat_Content_LF',\n",
       "       'Item_Fat_Content_reg', 'Item_Type_Fruits and Vegetables',\n",
       "       'Item_Type_Snack Foods', 'Item_Type_Household',\n",
       "       'Item_Type_Frozen Foods', 'Item_Type_Dairy', 'Item_Type_Baking Goods',\n",
       "       'Item_Type_Canned', 'Item_Type_Health and Hygiene', 'Item_Type_Meat',\n",
       "       'Item_Type_Soft Drinks', 'Item_Type_Breads', 'Item_Type_Hard Drinks',\n",
       "       'Item_Type_Others', 'Item_Type_Starchy Foods', 'Item_Type_Breakfast',\n",
       "       'Outlet_Identifier_OUT027', 'Outlet_Identifier_OUT013',\n",
       "       'Outlet_Identifier_OUT049', 'Outlet_Identifier_OUT046',\n",
       "       'Outlet_Identifier_OUT035', 'Outlet_Identifier_OUT045',\n",
       "       'Outlet_Identifier_OUT018', 'Outlet_Identifier_OUT017',\n",
       "       'Outlet_Identifier_OUT010', 'Outlet_Size_Medium', 'Outlet_Size_Small',\n",
       "       'Outlet_Location_Type_Tier 3', 'Outlet_Location_Type_Tier 2',\n",
       "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Grocery Store',\n",
       "       'Outlet_Type_Supermarket Type3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 40)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[selected_features_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_LF</th>\n",
       "      <th>Item_Fat_Content_reg</th>\n",
       "      <th>Item_Type_Fruits and Vegetables</th>\n",
       "      <th>Item_Type_Snack Foods</th>\n",
       "      <th>Item_Type_Household</th>\n",
       "      <th>Item_Type_Frozen Foods</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Health and Hygiene</th>\n",
       "      <th>Item_Type_Meat</th>\n",
       "      <th>Item_Type_Soft Drinks</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Hard Drinks</th>\n",
       "      <th>Item_Type_Others</th>\n",
       "      <th>Item_Type_Starchy Foods</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Outlet_Identifier_OUT027</th>\n",
       "      <th>Outlet_Identifier_OUT013</th>\n",
       "      <th>Outlet_Identifier_OUT049</th>\n",
       "      <th>Outlet_Identifier_OUT046</th>\n",
       "      <th>Outlet_Identifier_OUT035</th>\n",
       "      <th>Outlet_Identifier_OUT045</th>\n",
       "      <th>Outlet_Identifier_OUT018</th>\n",
       "      <th>Outlet_Identifier_OUT017</th>\n",
       "      <th>Outlet_Identifier_OUT010</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8518</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>214.5218</td>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8519</td>\n",
       "      <td>0.046982</td>\n",
       "      <td>108.1570</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8520</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8521</td>\n",
       "      <td>0.145221</td>\n",
       "      <td>103.1332</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8522</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>75.4670</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Visibility  Item_MRP  Outlet_Establishment_Year  \\\n",
       "0            0.016047  249.8092                       1999   \n",
       "1            0.019278   48.2692                       2009   \n",
       "2            0.016760  141.6180                       1999   \n",
       "3            0.000000  182.0950                       1998   \n",
       "4            0.000000   53.8614                       1987   \n",
       "...               ...       ...                        ...   \n",
       "8518         0.056783  214.5218                       1987   \n",
       "8519         0.046982  108.1570                       2002   \n",
       "8520         0.035186   85.1224                       2004   \n",
       "8521         0.145221  103.1332                       2009   \n",
       "8522         0.044878   75.4670                       1997   \n",
       "\n",
       "      Item_Fat_Content_Low Fat  Item_Fat_Content_LF  Item_Fat_Content_reg  \\\n",
       "0                            1                    0                     0   \n",
       "1                            0                    0                     0   \n",
       "2                            1                    0                     0   \n",
       "3                            0                    0                     0   \n",
       "4                            1                    0                     0   \n",
       "...                        ...                  ...                   ...   \n",
       "8518                         1                    0                     0   \n",
       "8519                         0                    0                     0   \n",
       "8520                         1                    0                     0   \n",
       "8521                         0                    0                     0   \n",
       "8522                         1                    0                     0   \n",
       "\n",
       "      Item_Type_Fruits and Vegetables  Item_Type_Snack Foods  \\\n",
       "0                                   0                      0   \n",
       "1                                   0                      0   \n",
       "2                                   0                      0   \n",
       "3                                   1                      0   \n",
       "4                                   0                      0   \n",
       "...                               ...                    ...   \n",
       "8518                                0                      1   \n",
       "8519                                0                      0   \n",
       "8520                                0                      0   \n",
       "8521                                0                      1   \n",
       "8522                                0                      0   \n",
       "\n",
       "      Item_Type_Household  Item_Type_Frozen Foods  Item_Type_Dairy  \\\n",
       "0                       0                       0                1   \n",
       "1                       0                       0                0   \n",
       "2                       0                       0                0   \n",
       "3                       0                       0                0   \n",
       "4                       1                       0                0   \n",
       "...                   ...                     ...              ...   \n",
       "8518                    0                       0                0   \n",
       "8519                    0                       0                0   \n",
       "8520                    0                       0                0   \n",
       "8521                    0                       0                0   \n",
       "8522                    0                       0                0   \n",
       "\n",
       "      Item_Type_Baking Goods  Item_Type_Canned  Item_Type_Health and Hygiene  \\\n",
       "0                          0                 0                             0   \n",
       "1                          0                 0                             0   \n",
       "2                          0                 0                             0   \n",
       "3                          0                 0                             0   \n",
       "4                          0                 0                             0   \n",
       "...                      ...               ...                           ...   \n",
       "8518                       0                 0                             0   \n",
       "8519                       1                 0                             0   \n",
       "8520                       0                 0                             1   \n",
       "8521                       0                 0                             0   \n",
       "8522                       0                 0                             0   \n",
       "\n",
       "      Item_Type_Meat  Item_Type_Soft Drinks  Item_Type_Breads  \\\n",
       "0                  0                      0                 0   \n",
       "1                  0                      1                 0   \n",
       "2                  1                      0                 0   \n",
       "3                  0                      0                 0   \n",
       "4                  0                      0                 0   \n",
       "...              ...                    ...               ...   \n",
       "8518               0                      0                 0   \n",
       "8519               0                      0                 0   \n",
       "8520               0                      0                 0   \n",
       "8521               0                      0                 0   \n",
       "8522               0                      1                 0   \n",
       "\n",
       "      Item_Type_Hard Drinks  Item_Type_Others  Item_Type_Starchy Foods  \\\n",
       "0                         0                 0                        0   \n",
       "1                         0                 0                        0   \n",
       "2                         0                 0                        0   \n",
       "3                         0                 0                        0   \n",
       "4                         0                 0                        0   \n",
       "...                     ...               ...                      ...   \n",
       "8518                      0                 0                        0   \n",
       "8519                      0                 0                        0   \n",
       "8520                      0                 0                        0   \n",
       "8521                      0                 0                        0   \n",
       "8522                      0                 0                        0   \n",
       "\n",
       "      Item_Type_Breakfast  Outlet_Identifier_OUT027  Outlet_Identifier_OUT013  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         1   \n",
       "...                   ...                       ...                       ...   \n",
       "8518                    0                         0                         1   \n",
       "8519                    0                         0                         0   \n",
       "8520                    0                         0                         0   \n",
       "8521                    0                         0                         0   \n",
       "8522                    0                         0                         0   \n",
       "\n",
       "      Outlet_Identifier_OUT049  Outlet_Identifier_OUT046  \\\n",
       "0                            1                         0   \n",
       "1                            0                         0   \n",
       "2                            1                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "...                        ...                       ...   \n",
       "8518                         0                         0   \n",
       "8519                         0                         0   \n",
       "8520                         0                         0   \n",
       "8521                         0                         0   \n",
       "8522                         0                         1   \n",
       "\n",
       "      Outlet_Identifier_OUT035  Outlet_Identifier_OUT045  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "...                        ...                       ...   \n",
       "8518                         0                         0   \n",
       "8519                         0                         1   \n",
       "8520                         1                         0   \n",
       "8521                         0                         0   \n",
       "8522                         0                         0   \n",
       "\n",
       "      Outlet_Identifier_OUT018  Outlet_Identifier_OUT017  \\\n",
       "0                            0                         0   \n",
       "1                            1                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "...                        ...                       ...   \n",
       "8518                         0                         0   \n",
       "8519                         0                         0   \n",
       "8520                         0                         0   \n",
       "8521                         1                         0   \n",
       "8522                         0                         0   \n",
       "\n",
       "      Outlet_Identifier_OUT010  Outlet_Size_Medium  Outlet_Size_Small  \\\n",
       "0                            0                   1                  0   \n",
       "1                            0                   1                  0   \n",
       "2                            0                   1                  0   \n",
       "3                            1                   1                  0   \n",
       "4                            0                   0                  0   \n",
       "...                        ...                 ...                ...   \n",
       "8518                         0                   0                  0   \n",
       "8519                         0                   1                  0   \n",
       "8520                         0                   0                  1   \n",
       "8521                         0                   1                  0   \n",
       "8522                         0                   0                  1   \n",
       "\n",
       "      Outlet_Location_Type_Tier 3  Outlet_Location_Type_Tier 2  \\\n",
       "0                               0                            0   \n",
       "1                               1                            0   \n",
       "2                               0                            0   \n",
       "3                               1                            0   \n",
       "4                               1                            0   \n",
       "...                           ...                          ...   \n",
       "8518                            1                            0   \n",
       "8519                            0                            1   \n",
       "8520                            0                            1   \n",
       "8521                            1                            0   \n",
       "8522                            0                            0   \n",
       "\n",
       "      Outlet_Type_Supermarket Type1  Outlet_Type_Grocery Store  \\\n",
       "0                                 1                          0   \n",
       "1                                 0                          0   \n",
       "2                                 1                          0   \n",
       "3                                 0                          1   \n",
       "4                                 1                          0   \n",
       "...                             ...                        ...   \n",
       "8518                              1                          0   \n",
       "8519                              1                          0   \n",
       "8520                              1                          0   \n",
       "8521                              0                          0   \n",
       "8522                              1                          0   \n",
       "\n",
       "      Outlet_Type_Supermarket Type3  \n",
       "0                                 0  \n",
       "1                                 0  \n",
       "2                                 0  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "...                             ...  \n",
       "8518                              0  \n",
       "8519                              0  \n",
       "8520                              0  \n",
       "8521                              0  \n",
       "8522                              0  \n",
       "\n",
       "[8523 rows x 37 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = lm.predict(test[selected_features_rfe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Item_Outlet_Sales'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat((pd.DataFrame(data = test_data,columns=['Item_Identifier','Outlet_Identifier']),pd.DataFrame(np.abs(test_pred),columns=['Item_Outlet_Sales'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDW58</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1840.961654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FDW14</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>1427.391080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NCN55</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1884.143821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDQ58</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2579.663596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>FDY38</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>5138.677736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5676</td>\n",
       "      <td>FDB58</td>\n",
       "      <td>OUT046</td>\n",
       "      <td>2307.120765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5677</td>\n",
       "      <td>FDD47</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2460.335252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5678</td>\n",
       "      <td>NCO17</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1823.347825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5679</td>\n",
       "      <td>FDJ26</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>3592.481551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5680</td>\n",
       "      <td>FDU37</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>1287.685025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier Outlet_Identifier  Item_Outlet_Sales\n",
       "0              FDW58            OUT049        1840.961654\n",
       "1              FDW14            OUT017        1427.391080\n",
       "2              NCN55            OUT010        1884.143821\n",
       "3              FDQ58            OUT017        2579.663596\n",
       "4              FDY38            OUT027        5138.677736\n",
       "...              ...               ...                ...\n",
       "5676           FDB58            OUT046        2307.120765\n",
       "5677           FDD47            OUT018        2460.335252\n",
       "5678           NCO17            OUT045        1823.347825\n",
       "5679           FDJ26            OUT017        3592.481551\n",
       "5680           FDU37            OUT045        1287.685025\n",
       "\n",
       "[5681 rows x 3 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('mysubmission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pycaret (1.0.0)  - An open source, low-code machine learning library in Python\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip search pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret\n",
      "  Downloading https://files.pythonhosted.org/packages/c7/41/f7fa05b6ce3cb3096a35fb5ac6dc0f2bb23e8304f068618fb2501be0a562/pycaret-1.0.0-py3-none-any.whl (188kB)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (3.1.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (0.13.2)\n",
      "Collecting plotly==4.4.1 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/ce/6ea5683c47b682bffad39ad41d10913141b560b1b875a90dbc6abe3f4fa9/plotly-4.4.1-py2.py3-none-any.whl (7.3MB)\n",
      "Collecting scikit-learn==0.22 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/10/1dd2e3436e13402cc2b16c61b5f7407fb2e8057dcc18461db0d8e3523202/scikit_learn-0.22-cp37-cp37m-win_amd64.whl (6.2MB)\n",
      "Collecting wordcloud (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/41/abefdda082c7b211248e412fb2c7a8dc69d474f18ed61a5a784f20f73bb7/wordcloud-1.7.0-cp37-cp37m-win_amd64.whl (157kB)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (3.4.5)\n",
      "Collecting spacy (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/39/c9/6c6bbb563588cd9b5d155ebda200796911588fb46a85e5f4d21b7b2ab759/spacy-2.2.4-cp37-cp37m-win_amd64.whl (9.9MB)\n",
      "Collecting kmodes==0.10.1 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/79/c0/f7d8a0eb41ac6f302b4bc100f91b6e0f2558425ccfefaa0ec0430f77ee97/kmodes-0.10.1-py2.py3-none-any.whl\n",
      "Collecting yellowbrick==1.0.1 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/cf/6d6ab47c0759d246262f9bdb53e89be3814bf1774bc51fffff995f5859f9/yellowbrick-1.0.1-py3-none-any.whl (378kB)\n",
      "Requirement already satisfied: IPython in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (7.8.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (1.16.5)\n",
      "Collecting textblob (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "Collecting lightgbm==2.3.1 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/cb/a8ec24334c35a7d0c87b4e4e056bd2137573c7c1bd81c760b79a2f370254/lightgbm-2.3.1-py2.py3-none-win_amd64.whl (544kB)\n",
      "Requirement already satisfied: ipywidgets in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (7.5.1)\n",
      "Collecting datefinder==0.7.0 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/16/2b/af8efaee30c0ba4238cb4d0645a07100d33d11d20a8783c443ed8b813eb9/datefinder-0.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (0.25.1)\n",
      "Collecting datetime (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/22/a5297f3a1f92468cc737f8ce7ba6e5f245fcfafeae810ba37bd1039ea01c/DateTime-4.3-py2.py3-none-any.whl (60kB)\n",
      "Collecting shap==0.32.1 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/27/20/1101ac6c1c952aca8e2a7a22810fc707c31b155fe183dd338bfe86741f2c/shap-0.32.1-cp37-cp37m-win_amd64.whl (292kB)\n",
      "Collecting pandas-profiling==2.3.0 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
      "Collecting awscli (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/22/64/e5e2a1c8c277c99377e34943d802a389637a102cd3923bd6608b5ec220ea/awscli-1.18.66-py2.py3-none-any.whl (3.1MB)\n",
      "Requirement already satisfied: mlxtend in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (0.17.2)\n",
      "Collecting umap-learn (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/ac/838287c562b8f73448ea0d1a989e696d10ba401ce1eaeb64a227f2bca8c4/umap-learn-0.4.3.tar.gz (68kB)\n",
      "Collecting cufflinks==0.17.0 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/79/1b8673b2723e02919307d558896dbcedcb46807c4e29acd25cfe43a36c8b/cufflinks-0.17.0.tar.gz (81kB)\n",
      "Collecting gensim (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/66/04faeedb98bfa5f241d0399d0102456886179cabac0355475f23a2978847/gensim-3.8.3-cp37-cp37m-win_amd64.whl (24.2MB)\n",
      "Collecting xgboost==0.90 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/49/b95c037b717b4ceadc76b6e164603471225c27052d1611d5a2e832757945/xgboost-0.90-py2.py3-none-win_amd64.whl (18.3MB)\n",
      "Collecting pyod (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/68/99df05e5666248e9c10359457e2da1b89943f5ac96749ceb1c131001eb88/pyod-0.8.0.tar.gz (93kB)\n",
      "Collecting pyLDAvis (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
      "Collecting catboost==0.20.2 (from pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/b1/767ee13e26ffa437e11419620ef99edc0854496ba39f9a0b5fb1681a9f96/catboost-0.20.2-cp37-none-win_amd64.whl (63.1MB)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (from pycaret) (0.9.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->pycaret) (2.8.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly==4.4.1->pycaret) (1.12.0)\n",
      "Collecting retrying>=1.3.3 (from plotly==4.4.1->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==0.22->pycaret) (1.3.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud->pycaret) (6.2.0)\n",
      "Collecting srsly<1.1.0,>=1.0.2 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/31/edaf3cdb7fcb644a51c7a568bc62a8c8d7462e61fa79b090f4d12d73d39e/srsly-1.0.2-cp37-cp37m-win_amd64.whl (179kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/7b/d77bc9bb101e113884b2d70a118e7ec8dcc9846a35a0e10d47ca37acdcbf/murmurhash-1.0.2-cp37-cp37m-win_amd64.whl\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy->pycaret) (41.4.0)\n",
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/5a/0d1b575ed40989d74fab25723083837c220246b25f3582917135cb32453f/preshed-3.0.2-cp37-cp37m-win_amd64.whl (105kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/84/d1/35eab0c8cc9fd9432becaf3e90144762b3201a45079e62c47a8ae8739763/cymem-2.0.3-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy->pycaret) (2.22.0)\n",
      "Collecting blis<0.5.0,>=0.4.0 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/7e/1981d5389b75543f950026de40a9d346e2aec7e860b2800e54e65bd46c06/blis-0.4.1-cp37-cp37m-win_amd64.whl (5.0MB)\n",
      "Collecting thinc==7.4.0 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/5e/d7e297587f75f4932b57b47163fb92f7b479939327ca83badc0938194415/thinc-7.4.0-cp37-cp37m-win_amd64.whl (2.1MB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (4.4.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.15.1)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.1.0)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (2.4.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.4.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (2.0.10)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from IPython->pycaret) (0.7.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (5.1.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (4.4.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipywidgets->pycaret) (3.5.1)\n",
      "Collecting regex>=2017.02.08 (from datefinder==0.7.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/80/f3/20dc107ea9d1fe2b05b974729fffcbd77b34b26468154a8fcfe47a7aee6a/regex-2020.5.14-cp37-cp37m-win_amd64.whl (272kB)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from datefinder==0.7.0->pycaret) (2019.3)\n",
      "Collecting zope.interface (from datetime->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/f9/af181babed312b9e21271dbfd7ec0815f822a12aaa2fe472d98e62e5bac3/zope.interface-5.1.0-cp37-cp37m-win_amd64.whl (194kB)\n",
      "Requirement already satisfied: jinja2>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling==2.3.0->pycaret) (2.10.3)\n",
      "Collecting missingno>=0.4.2 (from pandas-profiling==2.3.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/de/6e4dd6d720c49939544352155dc06a08c9f7e4271aa631a559dfbeaaf9d4/missingno-0.4.2-py3-none-any.whl\n",
      "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
      "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/01/5a/7ef1c04ce62cd72f900c06298dc2385840550d5c653a0dbc19109a5477e6/phik-0.10.0-py3-none-any.whl (599kB)\n",
      "Collecting confuse>=1.0.0 (from pandas-profiling==2.3.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/64/85dbcea372efee5cba13eaa10a3bfa7019b8fe0c3c8314d8e189116e477a/confuse-1.1.0.tar.gz\n",
      "Requirement already satisfied: astropy in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas-profiling==2.3.0->pycaret) (3.2.1)\n",
      "Requirement already satisfied: PyYAML<5.4,>=3.10; python_version != \"3.4\" in c:\\programdata\\anaconda3\\lib\\site-packages (from awscli->pycaret) (5.1.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from awscli->pycaret) (0.15.2)\n",
      "Collecting rsa<=3.5.0,>=3.1.2 (from awscli->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from awscli->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "Collecting botocore==1.16.16 (from awscli->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/ac/b21f4aba98f239ee5341d79c64bb502a64ad8ac98331bf0d9568707c6576/botocore-1.16.16-py2.py3-none-any.whl (6.2MB)\n",
      "Collecting numba!=0.47,>=0.46 (from umap-learn->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/5e/56b3a9f54c55536ccd5b2c449dc0762477fcbd12e8315afa6ef7dd487235/numba-0.49.1-cp37-cp37m-win_amd64.whl (2.2MB)\n",
      "Collecting tbb (from umap-learn->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/94/66206cb915893196cb4e0db3aba3cc0504d1bb4739b0c2478371664dd8ea/tbb-2019.0-py3-none-win_amd64.whl (194kB)\n",
      "Collecting chart-studio>=1.0.0 (from cufflinks==0.17.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
      "Collecting colorlover>=0.2.1 (from cufflinks==0.17.0->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/53/f696e4480b1d1de3b1523991dea71cf417c8b19fe70c704da164f3f90972/colorlover-0.3.0-py3-none-any.whl\n",
      "Collecting Cython==0.29.14 (from gensim->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/be/b14be5c3ad1ff73096b518be1538282f053ec34faaca60a8753d975d7e93/Cython-0.29.14-cp37-cp37m-win_amd64.whl (1.7MB)\n",
      "Collecting smart-open>=1.8.1 (from gensim->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/74/77/744c79da6e66691e3500b6dffff29bdd787015eae817d594791edc7b719b/smart_open-2.0.0.tar.gz (103kB)\n",
      "Collecting combo (from pyod->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/52/e880bd923eba122515307d29ab43c1c356bad60610c27bed2cdec25d0240/combo-0.1.0.tar.gz\n",
      "Collecting suod (from pyod->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/87/9170cabe1b5e10a7d095c0e28f2e30e7c1886a13f063de85d3cfacc06f4b/suod-0.0.4.tar.gz (2.1MB)\n",
      "Requirement already satisfied: wheel>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis->pycaret) (0.33.6)\n",
      "Requirement already satisfied: numexpr in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis->pycaret) (2.7.0)\n",
      "Requirement already satisfied: pytest in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis->pycaret) (5.2.1)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis->pycaret) (0.17.1)\n",
      "Collecting funcy (from pyLDAvis->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
      "Collecting graphviz (from catboost==0.20.2->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/cc/c62100906d30f95d46451c15eb407da7db201e30f42008f3643945910373/graphviz-0.14-py2.py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pycaret) (2019.9.11)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.10->IPython->pycaret) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->pycaret) (0.1.7)\n",
      "Requirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from traitlets>=4.2->IPython->pycaret) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.3)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.0.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.5.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (3.0.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (6.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.8->pandas-profiling==2.3.0->pycaret) (1.1.1)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<=3.5.0,>=3.1.2->awscli->pycaret)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from botocore==1.16.16->awscli->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0 (from numba!=0.47,>=0.46->umap-learn->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/0d/616bfaf3830280b20f85db8e5deac2aac23153592a042796a8815b3a94e6/llvmlite-0.32.1-cp37-cp37m-win_amd64.whl (13.6MB)\n",
      "Requirement already satisfied: boto in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim->pycaret) (2.49.0)\n",
      "Collecting boto3 (from smart-open>=1.8.1->gensim->pycaret)\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/a9/1e321ad1a91355f91af9261e176c6aabf543019317a0e8c59dd2fd981c18/boto3-1.13.16-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis->pycaret) (1.8.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis->pycaret) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis->pycaret) (19.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis->pycaret) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis->pycaret) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis->pycaret) (0.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (0.6.0)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (18.1.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (223)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->pycaret) (0.15.4)\n",
      "Requirement already satisfied: Send2Trash in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.2)\n",
      "Requirement already satisfied: prometheus-client in c:\\programdata\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.3)\n",
      "Requirement already satisfied: defusedxml in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.2)\n",
      "Requirement already satisfied: bleach in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.1.0)\n",
      "Requirement already satisfied: testpath in c:\\programdata\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.2)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
      "Building wheels for collected packages: pandas-profiling, umap-learn, cufflinks, pyod, pyLDAvis, retrying, htmlmin, confuse, smart-open, combo, suod, funcy\n",
      "  Building wheel for pandas-profiling (setup.py): started\n",
      "  Building wheel for pandas-profiling (setup.py): finished with status 'done'\n",
      "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145045 sha256=6c4fa0d28e19049666e6d5d1e858b008c6daac92073ea26e1a9ffb534b4295a3\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\ce\\c7\\f1\\dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.4.3-cp37-none-any.whl size=66582 sha256=fb94ea6e7ba3037757d73dc0487738fa85a5cdaf3fa9a23d3a8d74c58a0d7acc\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\ca\\44\\8e\\64bda5354fbf7ecdedd8704ca948f4139ce9cf34f6d9667c9b\n",
      "  Building wheel for cufflinks (setup.py): started\n",
      "  Building wheel for cufflinks (setup.py): finished with status 'done'\n",
      "  Created wheel for cufflinks: filename=cufflinks-0.17.0-cp37-none-any.whl size=68551 sha256=adb3ba0497a845dd37bb01b282527b2108d64934aec4e2b5c38c7437d2a93a45\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\44\\d7\\dc\\e830ab00bc2dd3b2731295103baa070f8cbdda8891f71a7a8d\n",
      "  Building wheel for pyod (setup.py): started\n",
      "  Building wheel for pyod (setup.py): finished with status 'done'\n",
      "  Created wheel for pyod: filename=pyod-0.8.0-cp37-none-any.whl size=105569 sha256=d0db12f0ce5007e87757a466cb015df3f431e69f96b6487fde8cf1fb7c380924\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\ba\\a6\\81\\2dd042e240090f3603a686b897d03402219a86e3f61bc71184\n",
      "  Building wheel for pyLDAvis (setup.py): started\n",
      "  Building wheel for pyLDAvis (setup.py): finished with status 'done'\n",
      "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97715 sha256=f934dc1d0a3bfd6befd4112918b69b34700fb6424e1ec034c11e5b5cbc2e56bc\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\98\\71\\24\\513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-cp37-none-any.whl size=11435 sha256=1af6afc356e0acb3abdfb6c756727db7cdda93563ab6db3629aa9dcea390b67f\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\d7\\a9\\33\\acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp37-none-any.whl size=27090 sha256=f443c2955bfe1e864d9299c87d6b5c69d722d66fc713280e79eaec08e246ebb2\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\43\\07\\ac\\7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
      "  Building wheel for confuse (setup.py): started\n",
      "  Building wheel for confuse (setup.py): finished with status 'done'\n",
      "  Created wheel for confuse: filename=confuse-1.1.0-cp37-none-any.whl size=17577 sha256=f8259b1362ae1e5c0dc3a60f40412d1d7e776fcaaf02e0ab4b748ad9b69438d4\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\f6\\8b\\23\\41a1b516f6d8d4cc81f5bdb55394a47cdbe9659c53668d3c9e\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-2.0.0-cp37-none-any.whl size=101347 sha256=dbd8d2271b17b19de26ed27053e4517b7fdb55870a51808d08b6089880a3ec6f\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\27\\65\\38\\8d7f5fe8d7afb4e4566587b2d1933cec185fba19257836c943\n",
      "  Building wheel for combo (setup.py): started\n",
      "  Building wheel for combo (setup.py): finished with status 'done'\n",
      "  Created wheel for combo: filename=combo-0.1.0-cp37-none-any.whl size=42050 sha256=d520fc1de87e87c6ff84981c17425c000225ae6d84ceeadb12109a5f079902e6\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\00\\fd\\6c\\8da495ef08ce61844a646df2423c2b8ecda377a89c90ecd88e\n",
      "  Building wheel for suod (setup.py): started\n",
      "  Building wheel for suod (setup.py): finished with status 'done'\n",
      "  Created wheel for suod: filename=suod-0.0.4-cp37-none-any.whl size=2167164 sha256=8d73b1a0a8fcc5cb0778c569d43c37e2c16d34f97443b514d6758a7826400a3b\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\57\\55\\e5\\a4fca65bba231f6d0115059b589148774b41faea25b3f2aa27\n",
      "  Building wheel for funcy (setup.py): started\n",
      "  Building wheel for funcy (setup.py): finished with status 'done'\n",
      "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32045 sha256=2837febc5e4ab4c29fd12724b244fb9de217de615791a4f3e08c1aa87fdd7244\n",
      "  Stored in directory: C:\\Users\\Pavan\\AppData\\Local\\pip\\Cache\\wheels\\20\\5a\\d8\\1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
      "Successfully built pandas-profiling umap-learn cufflinks pyod pyLDAvis retrying htmlmin confuse smart-open combo suod funcy\n",
      "Installing collected packages: retrying, plotly, scikit-learn, wordcloud, srsly, murmurhash, plac, catalogue, cymem, preshed, blis, tqdm, wasabi, thinc, spacy, kmodes, yellowbrick, textblob, lightgbm, regex, datefinder, zope.interface, datetime, shap, missingno, htmlmin, llvmlite, numba, phik, confuse, pandas-profiling, pyasn1, rsa, jmespath, botocore, s3transfer, awscli, tbb, umap-learn, chart-studio, colorlover, cufflinks, Cython, boto3, smart-open, gensim, xgboost, combo, suod, pyod, funcy, pyLDAvis, graphviz, catboost, pycaret\n",
      "  Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: phik 0.10.0 has requirement joblib>=0.14.1, but you'll have joblib 0.13.2 which is incompatible.\n",
      "ERROR: umap-learn 0.4.3 has requirement numpy>=1.17, but you'll have numpy 1.16.5 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scikit_learn-0.21.3.dist-info\\\\COPYING'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 12 columns):\n",
      "Item_Identifier              8523 non-null object\n",
      "Item_Weight                  7060 non-null float64\n",
      "Item_Fat_Content             8523 non-null object\n",
      "Item_Visibility              8523 non-null float64\n",
      "Item_Type                    8523 non-null object\n",
      "Item_MRP                     8523 non-null float64\n",
      "Outlet_Identifier            8523 non-null object\n",
      "Outlet_Establishment_Year    8523 non-null int64\n",
      "Outlet_Size                  6113 non-null object\n",
      "Outlet_Location_Type         8523 non-null object\n",
      "Outlet_Type                  8523 non-null object\n",
      "Item_Outlet_Sales            8523 non-null float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 799.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycaret'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9026511f7d7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m r2 = setup(train_data, target = 'Item_Outlet_Sales', session_id = 123,\n\u001b[0;32m      4\u001b[0m            \u001b[0mnormalize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m            \u001b[0mpolynomial_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrigonometry_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *\n",
    "\n",
    "r2 = setup(train_data, target = 'Item_Outlet_Sales', session_id = 123,\n",
    "           normalize = True,\n",
    "           polynomial_features = True, trigonometry_features = True,\n",
    "           feature_interaction=True, \n",
    "           bin_numeric_features= ['Outlet_Establishment_Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycaret'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5a6cb2fbc9d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.csv' does not exist: b'C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-a19c829a9f5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrodeo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.csv' does not exist: b'C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.csv'"
     ]
    }
   ],
   "source": [
    "rodeo = pd.read_csv('C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodeo = pd.read_hdf('C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-climate_regions.H5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>climate_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>EF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>EF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>EF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>EF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>EF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lat    lon climate_region\n",
       "0 -90.0  180.0             EF\n",
       "2 -90.0  181.0             EF\n",
       "4 -90.0  182.0             EF\n",
       "6 -90.0  183.0             EF\n",
       "8 -90.0  184.0             EF"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rodeo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precip = pd.read_hdf('C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-contest_precip-14d-1948-2018.H5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>start_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">27.0</td>\n",
       "      <td rowspan=\"5\" valign=\"top\">261.0</td>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-03</td>\n",
       "      <td>0.097800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-04</td>\n",
       "      <td>0.100986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-05</td>\n",
       "      <td>0.100986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">49.0</td>\n",
       "      <td rowspan=\"5\" valign=\"top\">262.0</td>\n",
       "      <td>2018-05-19</td>\n",
       "      <td>25.996050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>28.150095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>28.428758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>28.338787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>28.687209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13215454 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          precip\n",
       "lat  lon   start_date           \n",
       "27.0 261.0 1948-01-01   0.000000\n",
       "           1948-01-02   0.000000\n",
       "           1948-01-03   0.097800\n",
       "           1948-01-04   0.100986\n",
       "           1948-01-05   0.100986\n",
       "...                          ...\n",
       "49.0 262.0 2018-05-19  25.996050\n",
       "           2018-05-20  28.150095\n",
       "           2018-05-21  28.428758\n",
       "           2018-05-22  28.338787\n",
       "           2018-05-23  28.687209\n",
       "\n",
       "[13215454 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(precip)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = temp.unstack(level='lat')\n",
    "df3.columns = df3.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = temp.unstack(level='lon')\n",
    "df3.columns = df3.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = temp.unstack(level=['lat','lon'])\n",
    "df3.columns = df3.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>lat</th>\n",
       "      <th colspan=\"2\" halign=\"left\">27.0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">28.0</th>\n",
       "      <th colspan=\"5\" halign=\"left\">29.0</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">49.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lon</th>\n",
       "      <th>261.0</th>\n",
       "      <th>262.0</th>\n",
       "      <th>261.0</th>\n",
       "      <th>262.0</th>\n",
       "      <th>263.0</th>\n",
       "      <th>260.0</th>\n",
       "      <th>261.0</th>\n",
       "      <th>262.0</th>\n",
       "      <th>263.0</th>\n",
       "      <th>264.0</th>\n",
       "      <th>...</th>\n",
       "      <th>253.0</th>\n",
       "      <th>254.0</th>\n",
       "      <th>255.0</th>\n",
       "      <th>256.0</th>\n",
       "      <th>257.0</th>\n",
       "      <th>258.0</th>\n",
       "      <th>259.0</th>\n",
       "      <th>260.0</th>\n",
       "      <th>261.0</th>\n",
       "      <th>262.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.319881</td>\n",
       "      <td>12.216187</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.096674</td>\n",
       "      <td>2.089301</td>\n",
       "      <td>9.464938</td>\n",
       "      <td>16.243572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565729</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>1.001567</td>\n",
       "      <td>0.579684</td>\n",
       "      <td>0.204861</td>\n",
       "      <td>1.353073</td>\n",
       "      <td>4.619862</td>\n",
       "      <td>4.576942</td>\n",
       "      <td>1.672628</td>\n",
       "      <td>0.899582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.318051</td>\n",
       "      <td>12.129895</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.077024</td>\n",
       "      <td>0.515708</td>\n",
       "      <td>9.435146</td>\n",
       "      <td>12.416258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565729</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>1.001567</td>\n",
       "      <td>0.579684</td>\n",
       "      <td>0.204861</td>\n",
       "      <td>1.541343</td>\n",
       "      <td>5.602958</td>\n",
       "      <td>6.649574</td>\n",
       "      <td>5.644654</td>\n",
       "      <td>6.320642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-03</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.846714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.370641</td>\n",
       "      <td>19.894092</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.983820</td>\n",
       "      <td>12.821439</td>\n",
       "      <td>25.258827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548814</td>\n",
       "      <td>1.063131</td>\n",
       "      <td>1.001567</td>\n",
       "      <td>0.579684</td>\n",
       "      <td>0.204861</td>\n",
       "      <td>1.541343</td>\n",
       "      <td>5.602958</td>\n",
       "      <td>6.649574</td>\n",
       "      <td>5.644654</td>\n",
       "      <td>6.320642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-04</td>\n",
       "      <td>0.100986</td>\n",
       "      <td>1.007105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.443940</td>\n",
       "      <td>21.873738</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>1.650893</td>\n",
       "      <td>17.220063</td>\n",
       "      <td>29.256202</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375385</td>\n",
       "      <td>2.040817</td>\n",
       "      <td>1.354214</td>\n",
       "      <td>1.159041</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>1.760146</td>\n",
       "      <td>5.680297</td>\n",
       "      <td>6.649574</td>\n",
       "      <td>5.644654</td>\n",
       "      <td>6.320642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1948-01-05</td>\n",
       "      <td>0.100986</td>\n",
       "      <td>2.153094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.286172</td>\n",
       "      <td>26.234650</td>\n",
       "      <td>0.029317</td>\n",
       "      <td>0.217706</td>\n",
       "      <td>1.688535</td>\n",
       "      <td>19.701528</td>\n",
       "      <td>32.069140</td>\n",
       "      <td>...</td>\n",
       "      <td>2.375385</td>\n",
       "      <td>2.324627</td>\n",
       "      <td>1.689813</td>\n",
       "      <td>1.159041</td>\n",
       "      <td>0.476498</td>\n",
       "      <td>1.843793</td>\n",
       "      <td>5.718560</td>\n",
       "      <td>6.649574</td>\n",
       "      <td>5.775335</td>\n",
       "      <td>6.658501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lat             27.0            28.0                           29.0            \\\n",
       "lon            261.0     262.0 261.0     262.0      263.0     260.0     261.0   \n",
       "start_date                                                                      \n",
       "1948-01-01  0.000000  0.224735   0.0  2.319881  12.216187  0.317365  0.096674   \n",
       "1948-01-02  0.000000  0.224735   0.0  2.318051  12.129895  0.018610  0.077024   \n",
       "1948-01-03  0.097800  0.846714   0.0  2.370641  19.894092  0.018610  0.169031   \n",
       "1948-01-04  0.100986  1.007105   0.0  2.443940  21.873738  0.018610  0.169031   \n",
       "1948-01-05  0.100986  2.153094   0.0  3.286172  26.234650  0.029317  0.217706   \n",
       "\n",
       "lat                                         ...      49.0                      \\\n",
       "lon            262.0      263.0      264.0  ...     253.0     254.0     255.0   \n",
       "start_date                                  ...                                 \n",
       "1948-01-01  2.089301   9.464938  16.243572  ...  0.565729  1.085714  1.001567   \n",
       "1948-01-02  0.515708   9.435146  12.416258  ...  0.565729  1.085714  1.001567   \n",
       "1948-01-03  0.983820  12.821439  25.258827  ...  0.548814  1.063131  1.001567   \n",
       "1948-01-04  1.650893  17.220063  29.256202  ...  2.375385  2.040817  1.354214   \n",
       "1948-01-05  1.688535  19.701528  32.069140  ...  2.375385  2.324627  1.689813   \n",
       "\n",
       "lat                                                                     \\\n",
       "lon            256.0     257.0     258.0     259.0     260.0     261.0   \n",
       "start_date                                                               \n",
       "1948-01-01  0.579684  0.204861  1.353073  4.619862  4.576942  1.672628   \n",
       "1948-01-02  0.579684  0.204861  1.541343  5.602958  6.649574  5.644654   \n",
       "1948-01-03  0.579684  0.204861  1.541343  5.602958  6.649574  5.644654   \n",
       "1948-01-04  1.159041  0.476498  1.760146  5.680297  6.649574  5.644654   \n",
       "1948-01-05  1.159041  0.476498  1.843793  5.718560  6.649574  5.775335   \n",
       "\n",
       "lat                   \n",
       "lon            262.0  \n",
       "start_date            \n",
       "1948-01-01  0.899582  \n",
       "1948-01-02  6.320642  \n",
       "1948-01-03  6.320642  \n",
       "1948-01-04  6.320642  \n",
       "1948-01-05  6.658501  \n",
       "\n",
       "[5 rows x 514 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = pd.read_hdf('C:/Users/Pavan/Desktop/Practice/Topgear/New folder/gt-contest_tmp2m-14d-1979-2018.H5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>start_date</th>\n",
       "      <th>tmp2m</th>\n",
       "      <th>tmp2m_sqd</th>\n",
       "      <th>tmp2m_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>283996800000000000</td>\n",
       "      <td>7.683595</td>\n",
       "      <td>71.787847</td>\n",
       "      <td>3.570744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>284083200000000000</td>\n",
       "      <td>7.283579</td>\n",
       "      <td>65.928690</td>\n",
       "      <td>3.588616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>284169600000000000</td>\n",
       "      <td>7.792389</td>\n",
       "      <td>73.418007</td>\n",
       "      <td>3.563239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>284256000000000000</td>\n",
       "      <td>8.906203</td>\n",
       "      <td>92.516513</td>\n",
       "      <td>3.632638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>284342400000000000</td>\n",
       "      <td>9.719387</td>\n",
       "      <td>117.258396</td>\n",
       "      <td>4.774088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7395427</td>\n",
       "      <td>49.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1526688000000000000</td>\n",
       "      <td>19.178859</td>\n",
       "      <td>380.733948</td>\n",
       "      <td>3.592397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7395428</td>\n",
       "      <td>49.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1526774400000000000</td>\n",
       "      <td>19.390201</td>\n",
       "      <td>385.906323</td>\n",
       "      <td>3.150625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7395429</td>\n",
       "      <td>49.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1526860800000000000</td>\n",
       "      <td>19.410713</td>\n",
       "      <td>386.525391</td>\n",
       "      <td>3.122436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7395430</td>\n",
       "      <td>49.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1526947200000000000</td>\n",
       "      <td>19.379901</td>\n",
       "      <td>385.586529</td>\n",
       "      <td>3.163223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7395431</td>\n",
       "      <td>49.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1527033600000000000</td>\n",
       "      <td>19.268811</td>\n",
       "      <td>381.428659</td>\n",
       "      <td>3.184586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7395432 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat    lon           start_date      tmp2m   tmp2m_sqd  tmp2m_std\n",
       "0        27.0  261.0   283996800000000000   7.683595   71.787847   3.570744\n",
       "1        27.0  261.0   284083200000000000   7.283579   65.928690   3.588616\n",
       "2        27.0  261.0   284169600000000000   7.792389   73.418007   3.563239\n",
       "3        27.0  261.0   284256000000000000   8.906203   92.516513   3.632638\n",
       "4        27.0  261.0   284342400000000000   9.719387  117.258396   4.774088\n",
       "...       ...    ...                  ...        ...         ...        ...\n",
       "7395427  49.0  262.0  1526688000000000000  19.178859  380.733948   3.592397\n",
       "7395428  49.0  262.0  1526774400000000000  19.390201  385.906323   3.150625\n",
       "7395429  49.0  262.0  1526860800000000000  19.410713  386.525391   3.122436\n",
       "7395430  49.0  262.0  1526947200000000000  19.379901  385.586529   3.163223\n",
       "7395431  49.0  262.0  1527033600000000000  19.268811  381.428659   3.184586\n",
       "\n",
       "[7395432 rows x 6 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tem['lat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tem['lon'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
